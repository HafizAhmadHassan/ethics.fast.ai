{
  "00:01": "okay six o'clock thanks for being so",
  "00:04": "functional punctual everyone and so",
  "00:07": "let's get started I also wanted to",
  "00:09": "highlight that on the forums I always",
  "00:12": "post after class with links to",
  "00:14": "additional papers that came up during",
  "00:16": "class so be sure to check that out so",
  "00:18": "even though it's on the so like for",
  "00:21": "fairness last week after class I kind of",
  "00:23": "added a post with even more more papers",
  "00:26": "that have been talked about and I think",
  "00:28": "we have many of them are interesting",
  "00:30": "piece so I wanted to start um with",
  "00:34": "talking about this article um so I don't",
  "00:37": "watch Game of Thrones or the wire but I",
  "00:39": "still really enjoyed it as an article",
  "00:41": "although first I was curious about",
  "00:43": "anyone who does watch the shows whether",
  "00:45": "it resonated thank you everyone",
  "01:07": "I'm glad it resonated with many and",
  "01:10": "since I liked her her kind of tie in",
  "01:12": "with the tech industry on how so many of",
  "01:17": "our narratives in the tech industry are",
  "01:19": "around these kind of you know seemingly",
  "01:21": "larger-than-life personalities and not",
  "01:24": "as much about necessarily kind of the",
  "01:26": "broader sociological forces that that",
  "01:30": "influence people and she lists when the",
  "01:34": "sociological influences are business",
  "01:37": "models the advances in technology the",
  "01:40": "political environment lack of meaningful",
  "01:42": "regulation wealth inequality lack of",
  "01:46": "accountability geopolitical dynamics",
  "01:49": "although I do you know there is",
  "01:50": "something I think human about liking",
  "01:53": "stories about people which can then make",
  "01:56": "communication hard I was she heard",
  "01:58": "people talking this this weekend about",
  "02:01": "kind of the issue with even in science",
  "02:04": "like a lot of kind of getting attention",
  "02:06": "to your science is about crafting it",
  "02:08": "into a good story but that isn't",
  "02:11": "necessarily kind of the most accurate",
  "02:12": "way",
  "02:13": "of doing science but that kind of",
  "02:16": "stories resonate with people although",
  "02:19": "this is I think a kind of neat",
  "02:20": "perspective on how you can make stories",
  "02:22": "more about kind of broader forces any",
  "02:26": "other final final thoughts and this set",
  "02:30": "what kind of return to this way of",
  "02:33": "thinking of it in week five when we talk",
  "02:35": "about our kind of broader ecosystem that",
  "02:36": "we're in I'll have to I like to the line",
  "02:41": "about well-run societies not needing",
  "02:43": "heroes so this evening I'm gonna be",
  "02:49": "drawing very heavily on resources from",
  "02:51": "the Markkula center for applied ethics",
  "02:53": "at Santa Clara University and this is",
  "02:56": "work done by Shannon Valerie Naraku and",
  "02:58": "Brian Greene and I definitely recommend",
  "03:01": "their website as kind of having lots of",
  "03:03": "articles and resources which included",
  "03:06": "several on the syllabus so you've",
  "03:07": "probably noticed and so first I want to",
  "03:10": "kind of talk about so you know in weeks",
  "03:13": "one and two we were looking at these",
  "03:14": "very kind of specific areas of",
  "03:15": "disinformation and bias and fairness and",
  "03:19": "now in a kind of step back a little bit",
  "03:21": "and talk about kind of like the",
  "03:22": "underlying kind of what's the foundation",
  "03:25": "for even asking ethical questions and so",
  "03:28": "there were kind of this is the article",
  "03:32": "by Shannon Fowler there were three",
  "03:33": "different kind of schools of ethics that",
  "03:36": "she that she shared and these kind of go",
  "03:39": "back quite a ways so one is",
  "03:41": "deontological ethics which focuses on",
  "03:44": "rights principles and duties these",
  "03:47": "principles can include autonomy dignity",
  "03:49": "justice fairness transparency",
  "03:52": "consistency and more they may also",
  "03:54": "conflict with one another so in think of",
  "03:58": "situations where I don't like",
  "04:03": "consistency conflicts with with justice",
  "04:05": "or with these other principles a few",
  "04:08": "examples are the Golden Rule not",
  "04:12": "treating people as ends or sorry not",
  "04:15": "treating people as means to an end but",
  "04:17": "considering the mends to themselves the",
  "04:20": "rights approach which is when",
  "04:22": "considering options kind of what what",
  "04:24": "best respects everyone's rights or the",
  "04:27": "prose approach which option best",
  "04:30": "represents people equally or",
  "04:32": "proportionally and so the the reading",
  "04:36": "gave some different questions that you",
  "04:38": "can ask you know what rights of others",
  "04:40": "and duties to others must be respect how",
  "04:43": "might the dignity and autonomy of each",
  "04:45": "stakeholder be impacted what",
  "04:48": "considerations of trust and of justice",
  "04:50": "are relevant does this project involve",
  "04:53": "any conflicting moral duties or",
  "04:54": "conflicting stakeholder rights how do we",
  "04:56": "prioritize these so then I was gonna",
  "05:00": "kind of think about a specific example",
  "05:03": "that maybe we can kind of consider so do",
  "05:06": "you remember the unroll me backlash in",
  "05:08": "2017 so enroll me as a service that",
  "05:12": "would it's that you know if you sign up",
  "05:16": "for us will unsubscribe you from all the",
  "05:18": "kind of annoying email lists you're on",
  "05:20": "and it would give you these summaries of",
  "05:21": "like hey it seems like you're on these",
  "05:23": "email list you want to unsubscribe and",
  "05:25": "what people didn't realize is that so it",
  "05:28": "had access to your email inbox and it",
  "05:30": "was then selling that data and this this",
  "05:33": "came out in a kind of roundabout way",
  "05:35": "when uber mentioned oh yeah like we know",
  "05:39": "how lyft is doing because we buy that",
  "05:42": "data from unroll me way I mean I think",
  "05:45": "it actually went through kind of like a",
  "05:46": "company with another name and so there",
  "05:49": "was a lot of backlash particularly",
  "05:51": "because it was I think kind of catching",
  "05:52": "the uber backlash as well oh my goodness",
  "05:55": "they're they're buying email data about",
  "05:57": "about how many people are loop using",
  "06:00": "lyft so there were articles on the",
  "06:03": "unroll me CEO being heartbroken about",
  "06:07": "their their data being sold and so first",
  "06:12": "I kind of want to pause and ask to set",
  "06:13": "how would you kind of look at the story",
  "06:15": "in light of the questions we saw on the",
  "06:19": "previous page I'm kind of how this was",
  "06:22": "impacting people",
  "06:28": "any thoughts",
  "06:36": "and in the fourth row you can pass the",
  "06:39": "catch box back well I don't thought",
  "06:47": "about this enough to like know that I",
  "06:49": "fully get behind it the one thing that",
  "06:52": "like that prompts is do people have like",
  "06:55": "a right to not have their data sold",
  "06:58": "without their knowledge right yeah so",
  "07:02": "there's I think a sense of privacy or",
  "07:06": "maybe this would go under dignity a bed",
  "07:07": "of you know is there something kind of I",
  "07:09": "don't know that interferes with people's",
  "07:11": "dignity actually me look at the list of",
  "07:15": "list of principles yeah so they're",
  "07:18": "questions of kind of is that violating",
  "07:20": "some sort of right right now I hand in",
  "07:23": "the first oh actually there's a hand to",
  "07:25": "over yes the users was to extract",
  "07:34": "themselves for being involved in all of",
  "07:36": "these service providers and to turn",
  "07:39": "around so I think it's it's like insult",
  "07:41": "to injury yeah yeah I think it's even",
  "07:43": "worse just kind of like at a high level",
  "07:48": "of my morals it's like just kind of",
  "07:49": "sleazy yeah I think that they were",
  "07:53": "taking more trust than maybe another",
  "07:54": "service provider who had that same",
  "07:56": "information whether or not they had",
  "07:58": "consent to sell it yeah yeah so it seems",
  "08:02": "to kind of like violate and maybe this",
  "08:05": "is consistency around people seem to",
  "08:07": "value you know like simplicity they're",
  "08:09": "not wanting to be contacted by all these",
  "08:12": "providers and then it's as you said kind",
  "08:14": "of even more insulting that their their",
  "08:16": "data is being sold alright Lauren on the",
  "08:19": "opposite end of the row I think from a",
  "08:26": "business perspective early when these",
  "08:29": "founders you know sit down everyone gets",
  "08:31": "in the room it's a brainstorm possible",
  "08:33": "revenue generation experience I've been",
  "08:36": "in you I think it would have been a game",
  "08:38": "changer if they didn't consider selling",
  "08:40": "data and so at what point should these",
  "08:44": "questions be introduced and like how",
  "08:45": "much weight should they be given because",
  "08:47": "could drastically change the potential",
  "08:50": "revenue streams of a company and their",
  "08:52": "ability to even stay profitable or even",
  "08:54": "like on that tax or operability so",
  "08:56": "really that's true yes and this was",
  "09:00": "unroll me was a free service free",
  "09:02": "service to the users so they were not",
  "09:05": "paying but yeah they were",
  "09:06": "turns out giving their data and then can",
  "09:09": "you pass the ketchup ox forward to the",
  "09:11": "front row the specific use of the term",
  "09:17": "heartbroken sort of speaks to this lack",
  "09:20": "of understanding perhaps auctioned off",
  "09:44": "strange yeah and there was actually I",
  "09:47": "didn't take the headline from this but",
  "09:48": "it was a like a friend of the co-founder",
  "09:51": "or someone who had formerly been",
  "09:53": "involved in the company wrote this",
  "09:54": "medium so stuff kind of justifying why",
  "09:58": "the company and they weren't even like",
  "09:59": "involved with the company more anymore",
  "10:00": "but kind of very defensive and I think",
  "10:02": "took it very personally mercy you can",
  "10:08": "see a lot of these I like three on it",
  "10:13": "and they use it without knowing that the",
  "10:16": "software provider has yes yeah no",
  "10:24": "exactly I think transparency is",
  "10:25": "definitely a big issue here alright and",
  "10:31": "so I'm sorry something that didn't come",
  "10:33": "up but the company's defense was you",
  "10:36": "know if you really read our Terms of",
  "10:38": "Service you should have known that you",
  "10:39": "were giving away all your data and so",
  "10:42": "there was a study and this is from 2008",
  "10:44": "that it would take the average American",
  "10:46": "forty minutes a day to read every",
  "10:48": "privacy policy that they encountered and",
  "10:51": "so this is something it's just kind of",
  "10:53": "absurd we don't all have an extra forty",
  "10:55": "minutes a day and if we did probably",
  "10:57": "wouldn't want to read privacy policies",
  "11:00": "with that",
  "11:01": "it might be even more now because that",
  "11:02": "was that was over ten years ago and so a",
  "11:06": "Casey fee slur who I quote a lot did a",
  "11:09": "study and found that the and so this was",
  "11:13": "for Terms of Service the average reading",
  "11:16": "level is fourteen point eight which is",
  "11:19": "kind of midway through college for a",
  "11:22": "Terms of Service policy and has thirty",
  "11:25": "eight hundred words which is significant",
  "11:28": "yet the average person in the u.s. is at",
  "11:31": "an eighth grade reading level so in many",
  "11:33": "cases these aren't even you know pitched",
  "11:35": "at an appropriate reading level are",
  "11:37": "intended to be kind of readable by the",
  "11:39": "the users and I think this said this",
  "11:43": "also kind of captures the the gap",
  "11:46": "between legality and ethics you know",
  "11:50": "there's something where I think you know",
  "11:51": "companies can use it of like oh no like",
  "11:53": "it's it's fine because they sign this",
  "11:56": "but these aren't intended to be read hi",
  "12:03": "I'm Rachael Thomas I'm gonna talk about",
  "12:05": "some of the foundations for ethics as",
  "12:08": "well as ethical tools you can use in",
  "12:11": "your workplace particularly in the tech",
  "12:13": "industry and this is a continuation from",
  "12:15": "the lecture I started yesterday",
  "12:17": "unfortunately the recording software",
  "12:19": "malfunction part way through through",
  "12:22": "class so I'll be picking up here",
  "12:24": "I'm although it's fine trying to start",
  "12:26": "with this video I'll kind of briefly",
  "12:27": "briefly review I'll be drawing very",
  "12:31": "heavily on new sources from the",
  "12:33": "markoulis Center for Applied ethics at",
  "12:35": "Santa Clara University they've done some",
  "12:38": "great work on ethics and technology",
  "12:40": "practice definitely check out their",
  "12:42": "website they have conceptual frameworks",
  "12:44": "kind of guides for decision making and",
  "12:46": "ethics toolkit that I'll be covering",
  "12:48": "later case studies and so so look at",
  "12:51": "that it's we're very very helpful a",
  "12:53": "collection of resources and so as we",
  "12:56": "talked about previously we're kind of",
  "12:59": "looking at three three different ethical",
  "13:01": "theories tonight one is deontological",
  "13:04": "ethics which focuses on rights",
  "13:07": "principles and duties these principles",
  "13:09": "can include",
  "13:11": "me dignity justice fairness transparency",
  "13:14": "consistency and more they may same time",
  "13:16": "sometimes conflict with one another how",
  "13:20": "we talked earlier about the example of",
  "13:23": "unroll me which was a company that",
  "13:27": "offered a service to people for free",
  "13:29": "where they would unsubscribe you from",
  "13:32": "email list so kind of go through your",
  "13:34": "inbox and see like hey you're subscribed",
  "13:36": "to all these email lists or",
  "13:38": "advertisements do you want us to",
  "13:40": "automatically enroll you unsubscribe you",
  "13:43": "and then it eventually came out in 2017",
  "13:46": "that their business model was selling",
  "13:48": "data from users email and this was",
  "13:51": "revealed when an uber executive",
  "13:53": "mentioned that they had been buying data",
  "13:54": "from unroll me about how many people",
  "13:56": "were using lyft and many many users felt",
  "13:59": "very violated by this and while this was",
  "14:01": "something that may have been legal many",
  "14:04": "people felt that it was unethical and",
  "14:07": "from a deontological kind of viewpoint",
  "14:10": "it would seem to violate principles",
  "14:13": "perhaps of dignity autonomy transparency",
  "14:19": "so that's kind of one one example of how",
  "14:21": "how you can look at this a deontological",
  "14:24": "ethics also include the rights approach",
  "14:27": "which option best respects the rights of",
  "14:29": "everyone who has a stake or the justice",
  "14:32": "approach which option treats people",
  "14:34": "equally or proportionally another kind",
  "14:39": "of school of ethics is consequentialist",
  "14:41": "ethics if you want to know if an action",
  "14:44": "is ethical look at its consequences this",
  "14:47": "includes utilitarianism which ask you",
  "14:50": "know which option will produce the most",
  "14:51": "good and do the least harm as well as",
  "14:54": "the common good approach which asked",
  "14:56": "which option best serves the community",
  "14:58": "as a whole not just some members and I",
  "15:02": "yesterday in class gave the students an",
  "15:06": "exercise - this is modified from Casey",
  "15:09": "feelers a tech ethics scavenger hunt but",
  "15:13": "to try ranking five different kind of",
  "15:16": "ethics scandals from how they thought a",
  "15:19": "utilitarian would see them as what is",
  "15:21": "worst to least bad",
  "15:24": "and how a deontologist would see them",
  "15:26": "again from worse to least bad we had a",
  "15:29": "really interesting discussion on that I",
  "15:31": "think most of which is captured in the",
  "15:33": "previous video this is something you can",
  "15:35": "try it's a it's a little bit absurdist",
  "15:37": "and that Malthus is not really about",
  "15:39": "ranking kind of the terribleness of",
  "15:41": "things but it was useful for",
  "15:43": "highlighting some of the differences",
  "15:45": "between between utilitarianism and",
  "15:47": "deontology and also just kind of how how",
  "15:51": "these philosophies would lead people to",
  "15:53": "think about about problems",
  "15:57": "so while consequentialism and",
  "16:00": "deontological ethics both focus on",
  "16:02": "actions virtue ethics focuses on kind of",
  "16:06": "the person and their character traits so",
  "16:08": "this is a third school of thought and it",
  "16:11": "highlights the need for people with well",
  "16:13": "habituated virtues of moral character",
  "16:16": "and well cultivated practically wise",
  "16:18": "moral judgments and it's kind of about",
  "16:21": "this lifelong process of developing",
  "16:24": "practical wisdom and kind of the virtue",
  "16:27": "approach ask the question which option",
  "16:30": "leads me to act as the sort of person",
  "16:32": "that I want to be some questions from",
  "16:37": "the Markkula Center guide on this ask",
  "16:39": "what design habits are the embodying are",
  "16:42": "they the habits of excellent designers",
  "16:45": "will this project weaken any important",
  "16:48": "human habits skills or virtues that are",
  "16:50": "central to human excellence also will it",
  "16:53": "strengthen any will this design or",
  "16:55": "project incentivize any vicious habits",
  "16:57": "and users or other stakeholders and how",
  "17:00": "confident are that are we that will feel",
  "17:03": "proud to have our names associated with",
  "17:05": "this project in the future and so these",
  "17:08": "are a few questions you can think about",
  "17:09": "I'm kind of asking around work you're",
  "17:11": "doing so there was an optional reading",
  "17:16": "called what would an Avenger do by mark",
  "17:19": "D white and I have to admit I actually",
  "17:22": "am NOT not that familiar with the",
  "17:24": "Avengers but I still still enjoyed",
  "17:26": "reading this and found it helpful and it",
  "17:29": "kind of characterized the Iron Man is a",
  "17:31": "utilitarian who is looking to maximize",
  "17:35": "the good he sometimes is willing to kind",
  "17:38": "let the ends justify the means in that",
  "17:40": "service Captain America was classified",
  "17:43": "as a deontological Epis in terms of kind",
  "17:47": "of having a notion of the right and",
  "17:48": "really adhering to that and then Thor",
  "17:51": "was seen as an example of virtue ethics",
  "17:53": "and living by a code of honor I did want",
  "18:00": "to note that kind of all three of these",
  "18:02": "ethical philosophies we've talked about",
  "18:04": "are kind of Western philosophies and",
  "18:07": "that there were many other ethical",
  "18:08": "lenses out there as well as from other",
  "18:11": "cultures and I recently was reading",
  "18:14": "about New Zealand's algorithmic impact",
  "18:17": "assessment project that they're working",
  "18:18": "on and one aspect of the project is that",
  "18:21": "they are trying to incorporate a Maui",
  "18:24": "Maori worldview as well the Maori or the",
  "18:27": "indigenous people in New Zealand and so",
  "18:29": "then I was kind of doing some reading on",
  "18:31": "the Maori data sovereignty movement and",
  "18:33": "how the Maori view data which in times",
  "18:36": "kind of raises raises as specific",
  "18:39": "concerns about about kind of how data is",
  "18:43": "used what's done with it and how it",
  "18:45": "impacts their community and so I don't I",
  "18:48": "don't feel a sufficiently confident that",
  "18:52": "I could explain this accurately and I",
  "18:53": "don't want to misrepresent someone",
  "18:55": "else's culture I mostly just want to",
  "18:57": "highlight that there are plenty of",
  "18:58": "ethical philosophies outside the West",
  "19:01": "there are kind of other ethical",
  "19:03": "worldviews to consider so in summary the",
  "19:09": "kind of five ethical lenses that we've",
  "19:11": "seen are the rights approach the justice",
  "19:15": "approach these are both deontological",
  "19:17": "ethics approaches then from",
  "19:21": "consequentialism we've seen the",
  "19:23": "utilitarian approached in the common",
  "19:25": "good approach and then finally from",
  "19:28": "virtue ethics the virtue approach and so",
  "19:30": "this is a list of questions that the",
  "19:32": "Markkula Center guide provides that you",
  "19:35": "can consider in kind of looking at a",
  "19:38": "project that might be going on in your",
  "19:39": "workplace and trying to answer ethical",
  "19:43": "questions about it and anticipate how",
  "19:46": "it'll impact people which options may be",
  "19:48": "the best options to take",
  "19:50": "I also note that the I know arena riku",
  "19:54": "from markula Center definitely",
  "19:56": "emphasizes that this is something that's",
  "19:57": "best done in a group it definitely helps",
  "19:59": "to have other people to be discussing",
  "20:01": "this in community you have people who",
  "20:03": "can point out kind of different issues",
  "20:05": "and maybe see things differently from",
  "20:07": "from you all right so that's that kind",
  "20:13": "of in summary just some of kind of",
  "20:15": "what's the the underpinnings for even",
  "20:18": "talking about ethics or weighing",
  "20:20": "weighing the ethics of different",
  "20:22": "different projects next I'm going to get",
  "20:25": "into some practical tools that you can",
  "20:28": "use in the workplace some that you can",
  "20:30": "implement and as we've talked about",
  "20:32": "earlier having good intentions is not",
  "20:35": "necessarily enough to ensure a good",
  "20:37": "outcome in fact people can have good",
  "20:40": "intentions and still really miss major",
  "20:43": "ethical issues so it's helpful it's",
  "20:52": "helpful to really implement processes",
  "20:53": "and operationalize this in a way to kind",
  "20:57": "of make it part of your routine and make",
  "20:59": "it something that the company is doing",
  "21:01": "regularly and we're gonna go through",
  "21:03": "this ethical toolkit there are seven",
  "21:05": "tools or practices in it the first is",
  "21:08": "ethical risk sweet bang and so this is",
  "21:12": "instituting regularly-scheduled",
  "21:14": "risk school sweeps and so kind of",
  "21:16": "similar to the cybersecurity penetration",
  "21:18": "testing regularly looking for risk no",
  "21:21": "vulnerabilities found while that's a",
  "21:23": "good thing that doesn't mean that you",
  "21:24": "stop or consider it a waste you keep",
  "21:27": "doing it and then it's good to assume",
  "21:31": "that you miss some risk initially and so",
  "21:33": "continuing to look it's also important",
  "21:35": "to reward team members for spotting new",
  "21:38": "ethical risk I think sometimes raising",
  "21:40": "an ethical risk can be seen as something",
  "21:42": "that if nothing else kind of slows down",
  "21:44": "slows you down and your speed to get a",
  "21:47": "product to market and that's not always",
  "21:48": "rewarded but it's important to kind of",
  "21:50": "reward this behavior if you want it to",
  "21:52": "be incentivized at this point when",
  "21:56": "student brought up that her friend has",
  "21:58": "been raising ethical issues in his",
  "22:00": "workplace and that he's kind of getting",
  "22:02": "a lot of pushback about it",
  "22:04": "Villar seeing him as it's difficult it's",
  "22:07": "creating friction and she asked how to",
  "22:10": "deal with this and so I do want to",
  "22:13": "acknowledge that depending on the",
  "22:16": "dynamics of your workplace and in many",
  "22:18": "workplaces I think that it can cost you",
  "22:20": "social capital to speak up different",
  "22:23": "people have different amounts of social",
  "22:25": "capital",
  "22:26": "it also can depend on your seniority how",
  "22:29": "seriously you're taking around this and",
  "22:31": "so this can create issues it's not it's",
  "22:34": "definitely not simple particularly when",
  "22:36": "your your company or your team is not",
  "22:38": "aligned on this being an important thing",
  "22:40": "to do so I want to want to acknowledge",
  "22:42": "that and I think that over time it's",
  "22:44": "possible if you're in a workplace where",
  "22:46": "you do worse do experience a lot of",
  "22:49": "friction about bringing up ethical",
  "22:51": "issues that you ultimately may find it",
  "22:53": "like that's not a great fit or is kind",
  "22:55": "of untenable for you to continue so I",
  "22:58": "wanted to acknowledge the difficulty of",
  "22:59": "this if you don't kind of have your",
  "23:02": "whole team on board ideally you know you",
  "23:05": "would have leadership supporting this",
  "23:06": "and have it where there's a kind of more",
  "23:08": "of a more buy-in around the practice at",
  "23:12": "this point another student brought up",
  "23:14": "that he previously worked at epic the",
  "23:16": "makers of electronic health records and",
  "23:20": "he said it epic",
  "23:21": "they have I'm forgetting the name but",
  "23:25": "it's a specific job role of people that",
  "23:27": "it's kind of their whole role to",
  "23:29": "investigate concerns that potentially",
  "23:32": "relate to patient safety and if",
  "23:34": "something's gonna pose a patient safety",
  "23:36": "risk that is something to take very",
  "23:38": "seriously and he said it really helped",
  "23:41": "anyone in the company can and should",
  "23:43": "raise risk that they think may may",
  "23:46": "impact patient safety but from there",
  "23:48": "then they kind of had these specialists",
  "23:50": "who take that over that's their job to",
  "23:52": "do so and that that really helped kind",
  "23:54": "of streamline the process and it was",
  "23:56": "also something where it was fine there",
  "23:58": "to raise an issue that ended up not",
  "24:00": "turning out to the risk to patient",
  "24:04": "safety it was better to raise it and",
  "24:06": "investigate and have it turn out to to",
  "24:08": "be all right than to not say anything",
  "24:09": "and so that was that was kind of an",
  "24:11": "interesting interesting personal",
  "24:13": "experience to hear from from a member of",
  "24:15": "our class",
  "24:19": "so tool to tool to is ethical pre-mortem",
  "24:23": "x' and post-mortems and i had heard of",
  "24:27": "post-mortems before and i think they're",
  "24:29": "at least particularly for kind of",
  "24:31": "technical failures are well-established",
  "24:32": "practice in the tech industry this would",
  "24:37": "be implementing them around ethical",
  "24:38": "failures as well i thought the idea of a",
  "24:40": "pre-mortem was interesting pre-mortem",
  "24:43": "should ask how could this project fail",
  "24:45": "for ethical reasons what blind spots",
  "24:48": "would lead us into why would we fail to",
  "24:50": "act what systems checks or fail safes",
  "24:54": "can we put in place to reduce failure",
  "24:57": "risk and so I thought these were",
  "24:59": "interesting questions and one student in",
  "25:02": "the class raised his hand and shared",
  "25:04": "that he had previously done this not",
  "25:07": "even kind of with an explicit ethical",
  "25:09": "framing but is something that he went",
  "25:11": "through with kind of business",
  "25:14": "development and companies and that for",
  "25:17": "many maybe this would kind of be an",
  "25:19": "entryway into ethics to get them",
  "25:21": "thinking about it and even if it starts",
  "25:23": "as a prisoner's product problem that",
  "25:24": "it's kind of raising raising ethical",
  "25:26": "risk and so something that reading about",
  "25:32": "this tool reminded me of was the kind of",
  "25:35": "school of thought around professors that",
  "25:37": "are using science fiction to teach",
  "25:39": "computer science ethics and so this",
  "25:43": "comes from a wired article that",
  "25:44": "interviewed several different professors",
  "25:47": "and they actually had a different",
  "25:48": "philosophies on how they incorporate",
  "25:50": "science fiction into their courses so",
  "25:54": "some of them are using it more of just a",
  "25:57": "way to kind of think about human",
  "26:00": "characteristics and traits some to kind",
  "26:02": "of look you know little ways into the",
  "26:05": "future and see what could go wrong some",
  "26:07": "feel like the kind of having it in a",
  "26:09": "different world can make it give",
  "26:11": "students at distance that makes it",
  "26:13": "easier to analyze and discuss so it was",
  "26:15": "interesting kind of even within the",
  "26:17": "professors that are doing this there are",
  "26:18": "different thoughts on kind of what's",
  "26:20": "what's the best approach it was",
  "26:22": "something that I consider doing for this",
  "26:23": "course I don't think it's gonna happen",
  "26:25": "in this course but it's definitely kind",
  "26:26": "of at the back of my mind for for future",
  "26:28": "ones",
  "26:30": "there was also a Nietzsche article where",
  "26:32": "they asked I believe six different",
  "26:34": "science fiction writers for their views",
  "26:36": "on kind of what science fiction can tell",
  "26:38": "us and Ken Liu said although science",
  "26:41": "fiction isn't much used for knowing the",
  "26:43": "future it's underrated as a way of",
  "26:45": "reimagining human humanity in the face",
  "26:49": "of ceaseless change so that's that's one",
  "26:52": "aspect of what you can get from science",
  "26:53": "fiction Casey feeler who I mentioned a",
  "26:58": "lot and deeply admire does a black",
  "27:00": "mirror exercise with her students",
  "27:03": "so she actually assigns students to",
  "27:05": "watch an episode of black mirror and",
  "27:07": "then does a project called black mirror",
  "27:09": "writers room I got to participate in",
  "27:12": "this at a workshop or she was she led a",
  "27:14": "session of it and the idea is to kind of",
  "27:17": "get students writing their own episodes",
  "27:18": "of black mirror she says that",
  "27:21": "speculation is a skill that we have to",
  "27:24": "practice and develop and that kind of",
  "27:27": "yeah thinking of your own black me repa",
  "27:29": "sewed is one way to practice this skill",
  "27:30": "of speculation and she thinks it's",
  "27:33": "helpful to kind of keep things in the",
  "27:36": "somewhat near future where we can see",
  "27:38": "them as an extension of our current",
  "27:40": "technology and she's kind of written",
  "27:41": "about about how she implements this in",
  "27:43": "the classroom and so I thought this was",
  "27:47": "this was interesting as a kind of",
  "27:49": "extension of the pre-mortem idea all",
  "27:55": "12:3 tool 3 is expanding the ethical",
  "28:04": "circle so there's several um have",
  "28:09": "several ways that teams can can fail to",
  "28:11": "see risk one is groupthink which is when",
  "28:17": "you have a very close-knit group people",
  "28:19": "may start kind of thinking thinking",
  "28:21": "similarly due to the dynamics of the",
  "28:23": "group and then as a result may have",
  "28:24": "particular blind spots and things that",
  "28:26": "they miss another thing that can occur",
  "28:29": "is the bubble mentality and this is when",
  "28:31": "you have a lack of sufficient sufficient",
  "28:33": "diversity in your group and again that",
  "28:36": "can lead to people that kind of have",
  "28:37": "very similar worldviews and may miss",
  "28:41": "particular risk and miss the interest",
  "28:43": "of key stakeholders that aren't",
  "28:45": "represented there's also the Friedman",
  "28:49": "fallacy which is a fallacy saying that",
  "28:52": "companies are morally obligated only to",
  "28:54": "maximize shareholder profit even if it's",
  "28:56": "very harmful to the public or that stuff",
  "28:59": "that is harmful to the environment or",
  "29:01": "elicits public outcry at people",
  "29:04": "sometimes trying to use this to justify",
  "29:05": "deliberate or reckless disregard of",
  "29:08": "legitimate moral interest however it is",
  "29:11": "a fallacy this is not the case and the",
  "29:13": "public typically does not respond well",
  "29:14": "to this kind of reckless behavior so",
  "29:21": "some questions you can ask for expanding",
  "29:23": "the ethical circle whose interest",
  "29:26": "desires skills experiences and values",
  "29:28": "have we simply assumed rather than",
  "29:31": "actually consulted who are all the",
  "29:34": "stakeholders will be who will be",
  "29:35": "directly affected by our product how",
  "29:38": "have their interests been protected how",
  "29:41": "do we know what their interests really",
  "29:42": "are have we asked which groups and",
  "29:47": "individuals will be indirectly affected",
  "29:49": "and who might use this product that we",
  "29:51": "didn't expect to use or for purposes",
  "29:53": "that we didn't initially intend later in",
  "29:56": "the class I asked people to kind of",
  "29:59": "reflect on what they thought some of the",
  "30:01": "most useful of the of the tools we are",
  "30:05": "and several people highlighted this as",
  "30:08": "something that they thought was crucial",
  "30:10": "crucial to do in a particularly",
  "30:11": "important tool for the workplace this",
  "30:16": "made me think of some research from a",
  "30:18": "University of Washington tech policy lab",
  "30:20": "by meg young at all and so there they",
  "30:24": "did a project called diverse voices that",
  "30:27": "is around how to create kind of panels",
  "30:30": "of people from different communities",
  "30:33": "I can go to kind of gather them in a",
  "30:37": "systematic way pay them for their",
  "30:39": "expertise and elicit their feedback",
  "30:41": "around proposed tech policy in this case",
  "30:43": "this could also be used though for",
  "30:46": "considering different different products",
  "30:48": "or business practices and so they did",
  "30:51": "two case studies they had an augmented",
  "30:53": "reality white paper and they convened an",
  "30:56": "expert or",
  "30:57": "several expert panels including with",
  "30:59": "people with disabilities people who are",
  "31:01": "formerly are currently incarcerated and",
  "31:04": "women and then they did a separate one",
  "31:07": "on autonomous vehicles strategy document",
  "31:09": "holding expert panels with youth with",
  "31:12": "non car drivers and with people with",
  "31:15": "extremely low incomes and so this is",
  "31:18": "great to check out there's an academic",
  "31:19": "paper about it and then there's also on",
  "31:21": "the website there is a kind of practical",
  "31:23": "guide kind of leading you through how",
  "31:26": "you could do something like this as well",
  "31:27": "so this is a resource I wanted wanted",
  "31:30": "you to know about",
  "31:33": "all right tool for case based analysis",
  "31:37": "so identify similar or paradigm cases",
  "31:40": "that mirror the present case identify",
  "31:43": "relevant parallels between or",
  "31:45": "differences among all the cases so even",
  "31:48": "if a case is not exactly what you're",
  "31:49": "currently working on in the workplace it",
  "31:51": "still may be something you can learn",
  "31:52": "from it it's helpful to be explicit",
  "31:54": "about how it does parallel what you're",
  "31:56": "doing how it's different and then that",
  "31:59": "can help you identify kind of solutions",
  "32:01": "or risk mitigation strategies and at",
  "32:05": "this point one student raised our hand",
  "32:06": "and shared about Harvard has started or",
  "32:10": "so you know there's the Harvard Business",
  "32:12": "Review that often has business case",
  "32:14": "studies a Harvard data science review",
  "32:17": "has been started as well and that can be",
  "32:19": "a good source for data science reviews",
  "32:20": "although that's just within the last",
  "32:22": "year and is still kind of getting",
  "32:23": "getting up and going I kind of been",
  "32:29": "thinking about looking at past cases and",
  "32:33": "this might be going a little bit further",
  "32:34": "into the past than the the authors of",
  "32:37": "the toolkit met but I thought about the",
  "32:39": "course taught at Columbia Data past",
  "32:43": "present and future so this is co taught",
  "32:46": "by Matt Jones who's a history professor",
  "32:48": "and Chris Wiggins who's an applied math",
  "32:51": "professor as well as the chief data",
  "32:52": "scientist for the New York Times and I",
  "32:55": "think this is a fantastic idea for a",
  "32:57": "course this is I believe they're on",
  "32:58": "their fourth year teaching it so it's",
  "33:00": "really been refined to be putting a book",
  "33:02": "out about it next year all the materials",
  "33:05": "are available online so definitely check",
  "33:07": "them out and this course while it",
  "33:09": "involves coding",
  "33:10": "I believe it was I know that it's open",
  "33:13": "to students kind of from across",
  "33:15": "humanities as well as social sciences",
  "33:17": "and and Natural Sciences and what they",
  "33:22": "do is kind of go through a history of",
  "33:24": "data and particularly how new new",
  "33:28": "discoveries and innovations related to",
  "33:30": "data have reconfigured power there's a",
  "33:34": "lot of kind of dark history something I",
  "33:36": "didn't know is that regression was first",
  "33:39": "used to do race science so that was kind",
  "33:41": "of part of why regression was invented",
  "33:44": "was it was doing race science which is",
  "33:46": "terrible and they kind of go through",
  "33:49": "though this history that can really help",
  "33:50": "help us understand kind of our current",
  "33:53": "state and also kind of gaining those",
  "33:55": "tools of looking at this reconfiguration",
  "33:57": "of power so definitely check out their",
  "33:59": "materials online if this interest you",
  "34:05": "all right tool 5 remembering the ethical",
  "34:09": "benefits of creative work and so I think",
  "34:12": "this comes up because ethics can",
  "34:13": "sometimes seem focused on the negatives",
  "34:17": "and you know what terrible things can go",
  "34:18": "can happen what can go wrong but to",
  "34:21": "remember that hopefully we're also",
  "34:23": "trying to do to do good with our work",
  "34:25": "and to look at the positives as well and",
  "34:28": "to remember you know hopefully we are",
  "34:31": "working towards what we see is a greater",
  "34:33": "good are there ways that we can",
  "34:35": "genuinely you know trying to help others",
  "34:39": "through our work as opposed to",
  "34:41": "generating kind of inauthentic needs or",
  "34:43": "manufactured desires ok till 6:00 is",
  "34:48": "another one that really resonates with",
  "34:50": "me and that's think about the terrible",
  "34:52": "people so asking who will went to a",
  "35:01": "beauty Oh misinterpret hack destroyed or",
  "35:05": "weaponize what we build so this is kind",
  "35:08": "of if people are gonna use your products",
  "35:10": "and tools in ways that you really didn't",
  "35:12": "anticipate but can you try to start",
  "35:15": "anticipating those who will use use it",
  "35:19": "with alarming stupidity or a rationality",
  "35:22": "what reward",
  "35:24": "incentives openings has our design and",
  "35:26": "advertently it created for these people",
  "35:28": "or for those people and how can we",
  "35:31": "remove those rewards and at this point",
  "35:34": "one student shared about good hearts law",
  "35:36": "which states that kind of any when the",
  "35:39": "measure becomes the target it ceases to",
  "35:41": "be a good measure and that whenever you",
  "35:43": "have kind of rewards or incentives",
  "35:45": "people will try to game that and you'll",
  "35:47": "get unexpected consequences we're gonna",
  "35:50": "talk more about this in lesson five of",
  "35:53": "this class I wrote a blog post this fall",
  "35:57": "called the problem with metrics it's a",
  "35:58": "big problem with AI and that talks about",
  "36:01": "some of the harms that arise when we",
  "36:03": "overemphasize metrics okay and then 12:7",
  "36:09": "is closing the loop making making sure",
  "36:12": "you have channels to get feedback and to",
  "36:14": "iterate remember that this is never a",
  "36:18": "finished task identify feedback channels",
  "36:21": "that will deliver reliable data on",
  "36:23": "ethical impact so if you remember back",
  "36:26": "at lesson 1 we talked about the health",
  "36:29": "care algorithm that was a health care",
  "36:32": "software that was implemented in",
  "36:34": "Arkansas to determine people's Medicaid",
  "36:36": "benefits there was a bug in it it cut",
  "36:39": "off care that people needed people with",
  "36:41": "cerebral palsy in particular and there",
  "36:44": "was no kind of feedback channel in place",
  "36:46": "to even surface this air other than",
  "36:48": "having to go through like a very formal",
  "36:51": "court case and so this is something you",
  "36:54": "really want to make sure that you have",
  "36:55": "channels to receive face feedback and",
  "36:59": "chains of responsibility as well and so",
  "37:03": "kind of tools 6 and 7 reminded me of",
  "37:07": "this post by Alex spheres who was",
  "37:10": "previously the chief legal officer in",
  "37:12": "media and he interviewed because around",
  "37:15": "15 people that work in trust and safety",
  "37:18": "many of them have been working interest",
  "37:19": "in safety for years across a range of",
  "37:21": "companies including many of the major",
  "37:24": "tech platforms trust and safety includes",
  "37:26": "content moderation Alex described trust",
  "37:30": "and safety is both the the judges and",
  "37:32": "the janitors of the Internet",
  "37:34": "and something that one of the people he",
  "37:37": "interviewed said that struck me was the",
  "37:39": "separation of product people in trust",
  "37:41": "people worries me because in a world",
  "37:44": "where product managers and engineers and",
  "37:46": "visionaries cared about this stuff it",
  "37:48": "would be baked into how things get built",
  "37:50": "if things stay this way the product and",
  "37:53": "engineering are Mozart and everyone else",
  "37:54": "is Alfred the butler the big stuff is",
  "37:57": "not going to change and this is true at",
  "37:59": "many companies they're often kind of",
  "38:01": "siloed you have products and engineering",
  "38:03": "over here and people dealing with trust",
  "38:06": "and safety with abuse that happens on",
  "38:08": "the platform kind of harassment bad",
  "38:10": "actors are kind of totally siloed off in",
  "38:13": "another place there's very important",
  "38:15": "feedback that's not not getting back to",
  "38:18": "the the people that are building the",
  "38:19": "products and so someone else in the",
  "38:22": "article and most of the people in the",
  "38:24": "article we're using pseudonyms talked",
  "38:27": "about a kind of a company where",
  "38:29": "executives were having to spend some",
  "38:32": "time kind of shadowing people and Trust",
  "38:33": "and safety just to see what sort of",
  "38:35": "abuse arises how are people weaponizing",
  "38:37": "the platform which sounded like a",
  "38:39": "promising approach so I thought this was",
  "38:41": "this was an interesting one so now",
  "38:46": "there's a topic I want to talk more",
  "38:48": "about that relates to I guess",
  "38:51": "particularly to tool three around",
  "38:54": "expanding the ethical circle and that's",
  "38:57": "the lack of diversity in tack and",
  "38:59": "particularly in AI less than or only 12%",
  "39:03": "of machine learning researchers are",
  "39:06": "women so this is kind of even worse than",
  "39:08": "the tech industry in general and the",
  "39:10": "statistics are similarly dire when it",
  "39:12": "comes to race to age two other",
  "39:15": "demographic characteristics so we have a",
  "39:18": "very kind of homogeneous group of people",
  "39:20": "building really powerful technology that",
  "39:22": "is impacting pretty much everyone kind",
  "39:28": "of an example of the positive of having",
  "39:31": "a more diverse team Traci Chow was the",
  "39:35": "fourth employee at Quora as well as an",
  "39:37": "early engineer at Pinterest and she",
  "39:40": "wrote how the first features she built",
  "39:42": "when she worked at Quora was the block",
  "39:44": "button",
  "39:45": "and she wrote I was eager to work on the",
  "39:47": "future because I personally felt",
  "39:48": "antagonized and abused on the site",
  "39:50": "gender isn't an unlikely reason as to",
  "39:52": "why and if she had not been there and",
  "39:55": "advocated for this they probably",
  "39:56": "wouldn't have added a block block but",
  "39:58": "until later on so this is kind of one",
  "40:00": "example of the kind of positive aspect",
  "40:03": "of having a diverse team so I am I went",
  "40:09": "through a period where I became very",
  "40:12": "kind of discouraged and disillusioned in",
  "40:15": "the tech industry I I was in my early",
  "40:19": "30s at the time and had been kind of",
  "40:21": "focused on math and computer science",
  "40:22": "since I was a teenager but I was just",
  "40:24": "miserable I'll kind of largely due to",
  "40:26": "the toxic culture and so I hired a",
  "40:30": "career counselor I retook the GREs",
  "40:32": "because it had been 10 years and I was",
  "40:34": "really thinking though like what am I",
  "40:36": "gonna do I just can't can't see myself",
  "40:38": "continuing to do this I wrote a post",
  "40:40": "about my experience and about a lot of",
  "40:42": "the research I ended up doing called if",
  "40:44": "you think women in tech is just a",
  "40:46": "pipeline problem you haven't been paying",
  "40:47": "attention and so kind of one key",
  "40:51": "statistic I want everybody to know is",
  "40:53": "that 41% of women working in tech end up",
  "40:57": "leaving the field compared to just 17%",
  "40:59": "of men this is a very very high number",
  "41:02": "and kind of no matter how many girls you",
  "41:05": "teach to code it's not gonna solve the",
  "41:09": "diversity issues and tack if women",
  "41:12": "continue to leave leave at such a high",
  "41:15": "rate meta-analysis of 200 articles white",
  "41:20": "papers books found that women leave the",
  "41:24": "tech industry because they're treated",
  "41:26": "unfairly underpaid less likely to be",
  "41:28": "fast-tracked than their male colleagues",
  "41:30": "and unable to advance and so I really",
  "41:33": "encourage everyone if you're interested",
  "41:35": "in diversity to focus on the opposite",
  "41:38": "end of the pipeline from what people",
  "41:40": "normally talk about which is the",
  "41:41": "workplace and making sure that the women",
  "41:43": "and people of color in your workplace",
  "41:44": "now are treated well that you can retain",
  "41:48": "them that they have opportunities to",
  "41:50": "oops",
  "41:53": "unfortunately often in diversity efforts",
  "41:56": "end up focusing primarily on white women",
  "41:58": "which is wrong women of color are facing",
  "42:01": "many additional obstacles and barriers",
  "42:04": "and it was kind of even more important",
  "42:06": "to focus on them so I then kind of dug",
  "42:14": "into the research on why are women",
  "42:16": "getting fewer fewer chances to advance",
  "42:18": "some of some of the research around that",
  "42:21": "is there's a study that found that men's",
  "42:24": "voices are perceived as more persuasive",
  "42:26": "fact-based and logical than women's",
  "42:29": "voices even when reading identical",
  "42:31": "Scripps researchers found that women",
  "42:35": "received more vague feedback and",
  "42:37": "personality criticism and performance",
  "42:39": "evaluations which is not so helpful",
  "42:41": "whereas men receive actionable advice",
  "42:43": "tied to business outcomes and then when",
  "42:47": "women receive mentorship it's often",
  "42:49": "advice on how they should change and",
  "42:51": "gain more self-knowledge when men",
  "42:53": "received mentorship it's often public",
  "42:55": "endorsement of their authority and so",
  "42:57": "perhaps not surprisingly mentorship for",
  "42:59": "women has not been linked to getting a",
  "43:01": "promotion whereas mentorship for men has",
  "43:03": "been linked to getting a promotion women",
  "43:07": "also experience being excluded for more",
  "43:10": "creative and innovative roles not",
  "43:12": "receiving high visibility stretch",
  "43:14": "assignments which are also often useful",
  "43:16": "for advancing and being channeled into",
  "43:18": "less rewarded execution roles and so I",
  "43:22": "have links to all this research as well",
  "43:24": "as more in my post the real reason women",
  "43:26": "quit tack and how to address it and then",
  "43:32": "just a another aspect of this that I've",
  "43:35": "thought a lot about is how to make tech",
  "43:38": "interviews a little less awful the",
  "43:40": "interview process in tech is terrible",
  "43:42": "for everybody right now there are a lot",
  "43:45": "of problems with it I do think that",
  "43:47": "interviewing and hiring are really",
  "43:49": "difficult problems and they are they are",
  "43:51": "tough to get right but to two pieces of",
  "43:56": "research I wanted to share with you one",
  "43:59": "is a company called triple bite what",
  "44:03": "they what they do is this is",
  "44:05": "specifically its kind of work",
  "44:06": "and company for engineers they have",
  "44:08": "engineers take tests with them and then",
  "44:11": "they have kind of detailed data on where",
  "44:13": "those engineers interviewed where they",
  "44:16": "got offers where they got rejected and",
  "44:18": "they can compare that because they have",
  "44:20": "this kind of standardized test that they",
  "44:22": "gave gave over 300 engineers the number",
  "44:25": "one finding from triple bytes research",
  "44:27": "is that the type of programmers that",
  "44:29": "each company looks for have little to do",
  "44:32": "with what the company needs or does",
  "44:34": "rather they reflect company culture and",
  "44:36": "the backgrounds of the founders and so",
  "44:39": "this is discouraging it's perhaps not",
  "44:41": "surprising people like to hire people",
  "44:43": "like them that triple bite post gives",
  "44:46": "the advice to if you're looking for a",
  "44:48": "job to try to find companies where the",
  "44:50": "founders have a similar background to",
  "44:52": "you but clearly this is going to be much",
  "44:54": "easier for for certain people than for",
  "44:56": "others depending on on your background",
  "44:59": "and on your demographic another another",
  "45:04": "study that I love to tell people about",
  "45:06": "is one where they had people choose",
  "45:09": "between two resumes one had male name",
  "45:13": "one had a female name and one of the",
  "45:15": "resumes the person had more practical",
  "45:18": "experience the other they had more",
  "45:20": "impressive academic credentials and so",
  "45:22": "people typically picked the the man as",
  "45:25": "the candidate and then they would say",
  "45:27": "well I picked him because he had more",
  "45:30": "practical experience or I picked him",
  "45:31": "because he had more you know impressive",
  "45:34": "academic credentials and this was they",
  "45:36": "did both possible pairings and so this",
  "45:40": "is an example humans are great at post",
  "45:42": "hoc justifications it's really important",
  "45:44": "to kind of have formal credentials ahead",
  "45:48": "of time and to know are not credentials",
  "45:50": "but a formal outline of what you're",
  "45:52": "looking for so I linked it to those and",
  "45:55": "a bunch more research in my on my post",
  "45:57": "on tech interviews but I do acknowledge",
  "45:59": "its it is a tough a tough problem and",
  "46:02": "it's very time-intensive to try to",
  "46:04": "create a good interview process alright",
  "46:09": "so in summary we have seen seven",
  "46:12": "practices to implement from the Markkula",
  "46:14": "Center teka thix toolkit",
  "46:17": "in our previous lesson we saw data",
  "46:19": "sheets for data sets by Tim Nick Abreu",
  "46:21": "we also saw model cards for model",
  "46:24": "reporting by Margaret Mitchell at all we",
  "46:28": "also saw the diverse voices that was the",
  "46:30": "framework actually I should say so the",
  "46:32": "idea with data sheets for data sets is",
  "46:35": "you're never gonna eliminate bias from",
  "46:37": "your data set but let's at least be",
  "46:39": "explicit about how this data set was",
  "46:41": "created under what constraints what are",
  "46:45": "its limitations and let's kind of kind",
  "46:48": "of to be explicit with that and not just",
  "46:49": "assume it's kind of some sort of",
  "46:51": "universal ground truth diverse voices",
  "46:54": "what's the work from the University of",
  "46:55": "Washington policy lab about how to",
  "46:58": "create expert panels with people from",
  "47:00": "kind of various you know various",
  "47:03": "stakeholders such as formally",
  "47:05": "incarcerated people who don't have cars",
  "47:07": "to get their feedback about about a",
  "47:10": "paper or project the post that",
  "47:14": "interviewed 15 former or not former and",
  "47:18": "current trust and safety employees in",
  "47:21": "this idea of integrating trust and",
  "47:22": "safety more closely with product and",
  "47:24": "edge and then these tasks of retaining",
  "47:28": "and promoting people from",
  "47:30": "underrepresented groups and overhauling",
  "47:32": "the interview process and so I kind of",
  "47:35": "encouraged everyone in the class and I",
  "47:36": "encourage you to ask which of these",
  "47:38": "tools or practices sounds most helpful",
  "47:41": "to you and then also which do you think",
  "47:45": "would be the most realistic to implement",
  "47:47": "and so kind of looking back at this and",
  "47:50": "many people thought tool 3 seemed",
  "47:53": "particularly crucial although they also",
  "47:55": "thought that was one of I think the",
  "47:56": "harder ones to implement but definitely",
  "47:59": "you definitely think about this and",
  "48:01": "think about it you know is there",
  "48:02": "anything concrete that you can you can",
  "48:04": "take from this kind of back to your",
  "48:06": "workplace",
  "48:10": "and then I want to close now by",
  "48:13": "emphasizing that we need both policy and",
  "48:17": "ethical industry behavior this this",
  "48:21": "lecture has been more focused on ethical",
  "48:24": "behavior in industry what processes can",
  "48:27": "you implement in a company however that",
  "48:29": "is not gonna solve everything we need",
  "48:31": "policy as well policy is the appropriate",
  "48:34": "tool for addressing things like negative",
  "48:36": "externalities so a negative externality",
  "48:41": "shows up the classic example is company",
  "48:45": "you know dumping its waste into a river",
  "48:47": "Bay and that influences everyone around",
  "48:50": "them and so they're kind of offloading",
  "48:52": "their in their cost to society while",
  "48:54": "reaping in the profits and I think we're",
  "48:56": "right now seeing the tech industry",
  "48:58": "offload a lot of cost to society while",
  "49:00": "they well they make mad profits",
  "49:02": "misaligned economic incentives and this",
  "49:05": "is something that I think even when",
  "49:06": "people are well-intentioned if it is",
  "49:08": "really profitable to do something that",
  "49:12": "is is bad for society there's a kind of",
  "49:15": "a misalignment there and policies the",
  "49:17": "appropriate tool for for addressing that",
  "49:19": "also race to the bottom situations",
  "49:21": "sometimes there's something kind of",
  "49:22": "really at the coal and even yeah you",
  "49:25": "know even if you can convince your",
  "49:26": "company not to do it which is great",
  "49:28": "please do that there's still other",
  "49:30": "companies that are gonna do it you kind",
  "49:32": "of get sometimes these look kind of what",
  "49:34": "worse common denominator situations",
  "49:36": "again I think you need policy for that",
  "49:39": "as well as for enforcing accountability",
  "49:42": "kind of enforcing meaningful and",
  "49:45": "significant penalties for companies that",
  "49:47": "that do wrong and harm people",
  "49:50": "however policy would not be sufficient",
  "49:53": "on its own either because the law is not",
  "49:57": "always going to keep up with newest new",
  "49:59": "technology the law is also not always",
  "50:01": "specific enough to kind of capture every",
  "50:04": "every nuance or every edge case and so",
  "50:07": "for this reason it's important to have",
  "50:08": "ethical practitioners in industry as",
  "50:10": "well as I just want to highlight that",
  "50:12": "while we were focused on kind of what",
  "50:14": "you can do kind of assuming you're in a",
  "50:16": "industry workplace I also believe policy",
  "50:20": "is necessary that's something we'll talk",
  "50:22": "more about in week five that was also",
  "50:24": "I organized a tech policy workshop in",
  "50:27": "November here at the Center for Applied",
  "50:28": "data ethics and all kind of in the",
  "50:31": "process of will be releasing all those",
  "50:33": "videos online for you thank you"
}