{
  "00:00": "right so first off welcome everyone I'm",
  "00:03": "David Uminsky I'm the executive director",
  "00:04": "of the data Institute if this is your",
  "00:06": "first time in the data Institute welcome",
  "00:07": "there's a ton of things going on here",
  "00:09": "including this class which is what's",
  "00:11": "brought you all in every Friday we have",
  "00:13": "a weekly seminar on all things data",
  "00:16": "science including ethics as well and I'm",
  "00:20": "delighted that this is the inaugural",
  "00:21": "class there's been a tremendous amount",
  "00:23": "of interest in volume as well as thought",
  "00:27": "put into this class and we're excited to",
  "00:30": "launch for the very first time to the",
  "00:32": "public and then we're gonna have other",
  "00:34": "classes for graduate students and",
  "00:36": "undergraduate students eventually but",
  "00:38": "you guys are the first to have Rachel",
  "00:39": "teach a formal class in data ethics I",
  "00:44": "know right so congratulations so if you",
  "00:48": "have any questions around things like",
  "00:50": "Wireless and all that stuff I can't help",
  "00:52": "you but there are people here to help",
  "00:53": "you and Michaela in particular who I",
  "00:55": "think has been your point of contact is",
  "00:57": "gonna be your most useful she's still",
  "00:59": "outside I believe so but without further",
  "01:02": "ado I know why you guys right here",
  "01:04": "Rachel Thomas is the Center for Applied",
  "01:06": "data say that Centre for applied data",
  "01:09": "Ethics director the inaugural director",
  "01:11": "and she was our number one choice as you",
  "01:13": "can imagine for anyone to launch",
  "01:14": "anything in ethics here at the Institute",
  "01:16": "she's got an amazing background and",
  "01:19": "experience and besides being a prolific",
  "01:21": "writer she got her PhD from Duke in",
  "01:23": "mathematics and is the co-founder of",
  "01:26": "fast AI which is also on the side tack",
  "01:27": "so without further ado let's welcome",
  "01:30": "Rachel yeah so welcome everyone it's",
  "01:38": "great to have such a full room for this",
  "01:40": "so data ethics is kind of in the news I",
  "01:44": "would say really pretty much every day",
  "01:45": "now it all starts so kind of really",
  "01:47": "concerning development so I'm gonna",
  "01:49": "start this evening with just three quick",
  "01:52": "examples I kind of want everyone to know",
  "01:54": "about and the types of problems we'll be",
  "01:56": "thinking about in this class and I'll",
  "01:58": "say a little bit about the class and",
  "01:59": "then we'll get into the first topic",
  "02:01": "which is disinformation",
  "02:04": "so one one example that comes up a lot",
  "02:08": "and data ethics is feedback loops and so",
  "02:12": "a feedback loop occurs whenever your",
  "02:14": "model is controlling the next round of",
  "02:17": "data that you get and so your data kind",
  "02:20": "of quickly becomes flawed or at least",
  "02:23": "influenced by the software itself and",
  "02:25": "this is something I think many of us",
  "02:27": "from science backgrounds tend to",
  "02:28": "overlook because you're thinking oh I'm",
  "02:30": "observing the world and kind of seeing",
  "02:31": "seeing what's happening in the data but",
  "02:34": "if you're building any sort of product",
  "02:35": "that's being used you're asked also",
  "02:37": "having kind of this big influence and so",
  "02:39": "one place we see this is with",
  "02:40": "recommendation systems where you know",
  "02:43": "ostensibly they're predicting what",
  "02:44": "content people will like but they're",
  "02:46": "also controlling what content people are",
  "02:48": "exposed to second and I should note I'll",
  "02:54": "be kind of stopping periodically for",
  "02:55": "questions and we will have some time for",
  "02:57": "discussion and the later classes will be",
  "03:00": "a bit kind of more discussion oriented",
  "03:02": "second instance that I think about is",
  "03:07": "when systems are implemented with no way",
  "03:10": "to identify or address mistakes and so",
  "03:14": "this is something that kind of happens",
  "03:15": "you know outside the data itself but",
  "03:18": "thinking about the broader system that",
  "03:19": "it's within and so this is a headline",
  "03:22": "from an article following when new",
  "03:25": "system was implemented in Arkansas for",
  "03:27": "determining people's Medicaid benefits",
  "03:29": "so this was for poor people accessing",
  "03:32": "medical care that they needed and there",
  "03:34": "was a software bug that incorrectly cut",
  "03:37": "the care for people with cerebral palsy",
  "03:39": "including Tammy Dobbs pictured here and",
  "03:42": "so not just for kind of people losing",
  "03:44": "access to care they needed but there was",
  "03:46": "no way to even point out or discover",
  "03:50": "that there was a mistake because there",
  "03:51": "was no system for recourse and nobody",
  "03:54": "was on the lookout for mistakes",
  "03:56": "unfortunately this was eventually kind",
  "03:58": "of surfaced through a lengthy court case",
  "03:59": "but this is another kind of important",
  "04:02": "consideration to have of kind of how you",
  "04:04": "know what what safety mechanisms do you",
  "04:06": "have in place to discover when",
  "04:08": "something's gone wrong",
  "04:10": "and then a kind of third example when",
  "04:14": "everyone to know about is study by",
  "04:16": "Latanya Sweeney who's director of the",
  "04:19": "data privacy lab at Harvard has her PhD",
  "04:22": "in computer science and she discovered",
  "04:24": "several years ago that when you google",
  "04:26": "her name",
  "04:27": "you get ads saying Latanya Sweeney",
  "04:29": "arrested this is for a backed up",
  "04:31": "background check company and she's the",
  "04:34": "only person with that name she's never",
  "04:36": "been arrested",
  "04:37": "she paid $50 and confirmed her",
  "04:39": "background check says that she's never",
  "04:41": "been arrested however when you google",
  "04:43": "other names like kristin Lindquist you",
  "04:46": "get a much more neutral ad saying we",
  "04:48": "found Kristin Lindquist from the same",
  "04:50": "background check company and so being a",
  "04:52": "computer scientist she wanted to",
  "04:54": "approach this systematically she looked",
  "04:56": "at over 2,000 names and confirmed that",
  "04:58": "this pattern held that kind of",
  "05:01": "traditionally african-american names",
  "05:04": "we're getting the ads suggesting that",
  "05:06": "they had a criminal record regardless of",
  "05:08": "whether they did whereas kind of",
  "05:10": "traditionally white or European American",
  "05:12": "names we're getting much more neutral",
  "05:13": "language and this is something that",
  "05:16": "continues to be an issue I mean what was",
  "05:20": "going on in this particular case is the",
  "05:22": "background check company said that they",
  "05:24": "were placing both versions of the ad for",
  "05:27": "each name but Google ads automatically",
  "05:30": "lets you do a/b testing and so people",
  "05:32": "were clicking on the ads suggesting that",
  "05:35": "someone with an african-american name",
  "05:37": "was more likely to have a criminal",
  "05:39": "record and that was kind of what was",
  "05:41": "winning in the a/b testing and kind of",
  "05:43": "similar issues continue to surface",
  "05:45": "research less than a year ago showed",
  "05:48": "that Facebook's ad system seems to",
  "05:50": "discriminate by race and gender even",
  "05:52": "when the advertiser is not trying to for",
  "05:55": "housing ads having the exact same text",
  "05:57": "but switching the picture between a",
  "05:59": "white family and a black family served",
  "06:01": "up very different audiences so these are",
  "06:04": "kind of continuing ongoing and urgent",
  "06:08": "issues a common issue of bias it she'll",
  "06:11": "be talking about more next week so",
  "06:15": "Steven mentioned this is the Center for",
  "06:16": "applied data ethics kind of housed",
  "06:19": "within the USF data Institute if you're",
  "06:22": "interested we have",
  "06:23": "ethics seminars a few times a semester",
  "06:25": "that are open to the public we had a",
  "06:27": "tech policy workshop in November and",
  "06:30": "will be releasing all the videos from",
  "06:31": "that soon and then just briefly some",
  "06:35": "background about me I've worked at the",
  "06:36": "data Institute for three and a half",
  "06:38": "years I've also worked professionally as",
  "06:40": "a data scientist and software engineer",
  "06:44": "if you're kind of interested in some of",
  "06:47": "my other writing or Twitter it tends to",
  "06:49": "mostly be about data ethics so here's my",
  "06:51": "email and feel free to reach out to me",
  "06:53": "with any questions kind of about about",
  "06:55": "the course tour in general so some",
  "06:59": "course logistics my plan is to give a",
  "07:01": "kind of weekly quiz mostly just to check",
  "07:05": "if you've done the reading and also to",
  "07:06": "incentivize doing the reading I also",
  "07:10": "started a spreadsheet of AI ethics",
  "07:12": "issues in the news each week and this is",
  "07:15": "an idea I borrowed from Casey Fiedler",
  "07:16": "who's a another Tech's professor and I",
  "07:20": "thought that could be kind of",
  "07:21": "interesting to see in the hope is that",
  "07:22": "everyone could contribute one article",
  "07:24": "each week and to see what happens over",
  "07:26": "the six weeks of the course and then",
  "07:28": "there'll be an optional writing",
  "07:30": "assignment if you're interested you can",
  "07:31": "research and reflect on the ethics issue",
  "07:34": "of your choice and then happy to give",
  "07:35": "you feedback on a draft if you're",
  "07:37": "interested in posting it as a blog post",
  "07:39": "later I was going to use forums faster I",
  "07:46": "for discussion and this is what we've",
  "07:49": "used with the deep learning corset",
  "07:51": "courses and it's a pretty nice software",
  "07:53": "it's open source discourse in terms of",
  "07:57": "it has great search functionality when",
  "07:58": "you start entering something and so I've",
  "08:02": "started a few threads in particular I",
  "08:04": "started and introduce yourself here if",
  "08:07": "you want to write an introduction",
  "08:08": "because I definitely hope to get to know",
  "08:10": "more about all of you over the course of",
  "08:12": "the course and I hope that you get to",
  "08:14": "know each other and couldn't kind of",
  "08:15": "build some community around people that",
  "08:16": "are interested in data ethics",
  "08:19": "um and so this will be a great place to",
  "08:21": "kind of keep the discussion going I did",
  "08:23": "want to let you know I have this set to",
  "08:25": "private right now just four people in",
  "08:27": "the course but I was planning to open it",
  "08:29": "to public after the course ends let me",
  "08:32": "know if you have concerns about that I",
  "08:34": "are ultimately and also recording the",
  "08:37": "course right now to to share but I hope",
  "08:40": "to get kind of more people involved in",
  "08:41": "discussing discussing data ethics and",
  "08:44": "I'll let you know before before I do",
  "08:46": "that so I always interested to read",
  "08:51": "other tech ethics syllabi and have spent",
  "08:55": "a lot of time doing that and kaci feeler",
  "08:57": "who's a professor at the university of",
  "08:59": "colorado created a crowdsource",
  "09:01": "spreadsheet of over 200 syllabi for tech",
  "09:05": "ethics courses this is a year or two ago",
  "09:08": "and then she did a meta-analysis on what",
  "09:12": "do we teach when we teach tech ethics",
  "09:14": "which I thought was really interesting",
  "09:16": "and she highlighted there kind of a",
  "09:19": "number of open questions or",
  "09:22": "controversies about how to best teach",
  "09:24": "tech epics you know should it be a",
  "09:26": "standalone course or integrated into",
  "09:28": "every course in a curriculum who should",
  "09:32": "teach it so it resides in a lot of",
  "09:34": "different departments if you look across",
  "09:35": "schools you know should it be a computer",
  "09:37": "scientist a philosopher or sociologist",
  "09:43": "this is a chart kind of just showing the",
  "09:47": "discipline of what what department these",
  "09:49": "courses were taught in of the one she",
  "09:50": "looked at what topics to cover is a huge",
  "09:53": "question and there was kind of a lengthy",
  "09:55": "list lawn policy privacy and",
  "09:58": "surveillance philosophy justice and",
  "10:00": "human rights civic responsibilities a I",
  "10:03": "and robots and the list goes on and so",
  "10:06": "this is a far more than you can fit in",
  "10:08": "any course even if we had twice as long",
  "10:11": "as we do we would not be able to cover",
  "10:12": "kind of more than a fraction of this oh",
  "10:16": "and then what learning outcomes and this",
  "10:18": "is something where there is a little bit",
  "10:20": "more of consistency that kind of one of",
  "10:23": "the top top goals of tech efex courses",
  "10:26": "to teach the skill of critique and",
  "10:28": "spotting issues also making arguments",
  "10:31": "some so hopefully we'll get to some of",
  "10:33": "that but yeah so I share this just to",
  "10:37": "say that we we won't be able to cover",
  "10:38": "everything and that that's kind of a",
  "10:40": "typical of tech ethics courses and that",
  "10:43": "there is this huge variety but hopefully",
  "10:45": "some of the skills around kind of",
  "10:46": "discussion and spotting issues and",
  "10:48": "thinking about them well will transfer",
  "10:50": "even to other areas so the syllabus and",
  "10:56": "hopefully you receive this Michaela sent",
  "10:58": "it out I also have it posted in the",
  "11:00": "forums if you have any trouble accessing",
  "11:03": "the forums or creating account feel free",
  "11:06": "to to email me and that's something",
  "11:08": "where I have to add you and so I've",
  "11:09": "added tried adding everyone's email for",
  "11:12": "the email you used to sign up for the",
  "11:14": "course but if you haven't created an",
  "11:15": "account yet then I have to kind of go",
  "11:17": "back and add it to just let me know when",
  "11:19": "you do I would one other note that I",
  "11:22": "forgot earlier but I want to introduce a",
  "11:24": "special not really guest but new",
  "11:28": "resident and this is ally al-khatib and",
  "11:30": "he's joining us as well part of our kind",
  "11:32": "of first class of we haven't officially",
  "11:34": "announced this yet but data ethics",
  "11:36": "fellows here at the Center for Applied",
  "11:38": "data ethics so he'll be he'll be here",
  "11:41": "and and so briefly so I'm gonna kind of",
  "11:46": "I want to start with kind of - so this",
  "11:48": "week disinformation and next week bias",
  "11:50": "kind of - really in-depth Kate or",
  "11:54": "they're more than a case study but kind",
  "11:55": "of like an issue and really kind of",
  "11:57": "thinking about the issue in depth and",
  "11:58": "then kind of circling back to more just",
  "12:00": "even talking about what our ethical",
  "12:02": "frames we can use what our tools we can",
  "12:04": "use to address these but I think it'll",
  "12:06": "help ground us to kind of first have",
  "12:07": "these issues so I'm just gonna briefly",
  "12:09": "say this evening that ethics is the",
  "12:11": "discipline dealing with what's good and",
  "12:13": "bad or a set of moral principles I",
  "12:18": "linked to or assigned to this article",
  "12:22": "from the Markkula Center and then",
  "12:24": "there's another great one of just kind",
  "12:25": "of overview of ethics and ethics it's",
  "12:28": "not the same as religion law social",
  "12:30": "norms or feelings although it does have",
  "12:32": "overlap with all those things to varying",
  "12:35": "degrees it's not a fixed set of rules",
  "12:39": "ethics is well founded standards of",
  "12:42": "right and wrong and if also the study",
  "12:44": "and development of your ethical",
  "12:46": "standards and that kind of needs to be a",
  "12:47": "continuous and ongoing process I'm kind",
  "12:50": "of as we encounter new new situations",
  "12:54": "actually I'll stop and pause are there",
  "12:57": "any questions just about the class",
  "12:58": "before we launch into disinformation",
  "13:00": "tonight yes at least today but are you",
  "13:13": "trying to have something more practical",
  "13:16": "than ended that's a good question the",
  "13:19": "got I'm gonna use the catch box in",
  "13:21": "general but so the question was is there",
  "13:24": "gonna be a supplemental kind of coding",
  "13:25": "lab at the end of each lesson the answer",
  "13:28": "is probably not I had wanted to but I",
  "13:30": "kind of with time and with some of the",
  "13:33": "topics I don't think that'll happen but",
  "13:36": "I would love to do that kind of in",
  "13:37": "future iterations yeah and this course",
  "13:40": "has essentially no prerequisites I want",
  "13:43": "this to be open to everyone but I also",
  "13:45": "hope you can use kind of whatever",
  "13:46": "particular skills you have from your",
  "13:48": "background yes so it's something we'll",
  "13:58": "come back to in lesson three we'll talk",
  "14:00": "about a few different ethical frames and",
  "14:05": "deontological ethics consequentialist",
  "14:07": "ethics and virtue ethics that can",
  "14:09": "potentially be used and we'll also talk",
  "14:12": "about a kind of toolkit of processes you",
  "14:15": "can implement although on the whole the",
  "14:18": "focus of the course will be on kind of",
  "14:20": "the applied side in particular cases",
  "14:25": "Thanks so let's say let's dive into two",
  "14:28": "disinformation which i think is very",
  "14:30": "very kind of relevant an urgent issue so",
  "14:36": "in 2016 a group called the heart of",
  "14:38": "Texas posted on Facebook about a protest",
  "14:42": "to be held outside in Islamic Center in",
  "14:45": "Houston and then another group called",
  "14:48": "for a counter protest so people kind of",
  "14:50": "showed up on both sides you had kind of",
  "14:54": "the counter protest supporting freedom",
  "14:55": "of religion and inclusivity and a",
  "15:00": "reporter from the Houston Chronicle",
  "15:01": "noticed notice something unusual which",
  "15:05": "is that he was not able to get in",
  "15:07": "with the organizers for either side and",
  "15:09": "it came out kind of only months later",
  "15:12": "that actually both sides were organized",
  "15:16": "by Russian trolls and so this is",
  "15:19": "something that is kind of captures how",
  "15:23": "how real people can really get caught up",
  "15:25": "in disinformation and this is also",
  "15:29": "different than the idea of quote fake",
  "15:32": "news in that you know the people on both",
  "15:35": "sides kind of we're acting on beliefs",
  "15:37": "they had but they were doing it in a way",
  "15:39": "that was framed kind of very deceptively",
  "15:42": "by by foreign operatives who who weren't",
  "15:45": "who they claimed so I think this is kind",
  "15:48": "of an important important example to",
  "15:49": "keep in mind and also just how kind of",
  "15:51": "tangible this is in the real world that",
  "15:53": "these are kind of real people protesting",
  "15:55": "again in this frame that was created in",
  "15:57": "a deceptive way so this information has",
  "16:05": "been in the news a lot I think",
  "16:06": "particularly with respect to too deep",
  "16:09": "fakes videos but that's just one form of",
  "16:11": "of disinformation and we'll talk about",
  "16:13": "talked about many others and tonight",
  "16:18": "when I get a bit into what isn't",
  "16:19": "disinformation how do the tech platforms",
  "16:23": "make it worse how will new advances in",
  "16:26": "AI make it worse and what should we do",
  "16:31": "so this this is a site called radio",
  "16:34": "Africa purporting to the local news",
  "16:38": "source in Khartoum Sudan Sudan and it",
  "16:41": "came out this fall that this was set up",
  "16:43": "by Russians as part of a influence",
  "16:49": "operation in six different African",
  "16:51": "countries where they created kind of",
  "16:53": "what seemed to be local news sources and",
  "16:56": "in some cases hired locals as",
  "16:58": "journalists and they had 73 Facebook",
  "17:03": "pages with over 9 million interactions",
  "17:05": "on them and they used whatsapp and",
  "17:09": "telegram as well so this was kind of",
  "17:10": "multi-platform they're encouraging",
  "17:12": "people to join groups and it wasn't you",
  "17:16": "know it wasn't just kind of false",
  "17:17": "stories or even",
  "17:18": "and stories promoting Russia and also",
  "17:21": "included the type of thing you that you",
  "17:23": "would see kind of you know promoting",
  "17:25": "local tourism there was kind of stories",
  "17:27": "about sports and culture and a wide",
  "17:29": "variety of stories so disinformation is",
  "17:35": "a lot more than just fake news and in",
  "17:40": "fact Claire Wardle who's a kind of",
  "17:42": "excellent expert in this area",
  "17:43": "discourages the use of the term fake",
  "17:46": "news because it's not just news it's",
  "17:48": "memes and videos and social media post",
  "17:53": "another article that I included actually",
  "17:56": "curious who did the reading for this",
  "17:59": "week Oh awesome",
  "18:01": "okay great job everyone so the this was",
  "18:10": "about a kind of campaign in 2014 as you",
  "18:15": "probably read where some trolls on 4chan",
  "18:18": "said that they wanted to get the hashtag",
  "18:20": "canceled father's day trending they",
  "18:23": "wanted to pretend to be black women to",
  "18:24": "do this as an effort to kind of make",
  "18:27": "make feminists look bad and they were",
  "18:29": "successful in getting this hashtag",
  "18:31": "picked up and then several kind of",
  "18:33": "far-right media outlets you know picked",
  "18:36": "up like oh look at this hashtag trending",
  "18:39": "and so this is so they create accounts",
  "18:41": "like accounts like Nene can't stop much",
  "18:45": "again is a totally kind of fraudulent",
  "18:47": "account and this was something because",
  "18:48": "it was posted on 4chan was well it was",
  "18:51": "discovered because the accounts were not",
  "18:53": "that convincing particularly to the kind",
  "18:56": "of black women that were in the same",
  "18:57": "community that the trolls were",
  "18:59": "ostensibly trying to imitate and then",
  "19:02": "was confirmed that it was that it was",
  "19:04": "fake and so and this also kind of",
  "19:07": "captures that with disinformation people",
  "19:09": "can have very different motives I think",
  "19:11": "in some cases there are people that",
  "19:13": "maybe think that they're being ironic in",
  "19:16": "kind of promoting something that's",
  "19:18": "offensive or kind of enjoying the the",
  "19:20": "kind of hoax aspect of wanting to trick",
  "19:23": "others there are other people though",
  "19:24": "that may be outraged by it and take it",
  "19:26": "very seriously and so you tend to have",
  "19:28": "kind of a range of motivations and also",
  "19:31": "that may be kind of a vote by various",
  "19:34": "materials and you've got this whole mix",
  "19:37": "of rumors and hoaxes propaganda",
  "19:39": "misleading content misleading context",
  "19:44": "most of it is misleading not fake so a",
  "19:48": "lot of people refer to fabricated news",
  "19:50": "it's something that is is totally",
  "19:52": "made-up but a lot of it you know this is",
  "19:55": "kind of the spectrum of if you think of",
  "19:57": "how to lie with statistics you know you",
  "19:59": "can give a statistic that is technically",
  "20:02": "true in a particular context but which",
  "20:04": "has been presented in a way that's super",
  "20:06": "misleading and that's that's often used",
  "20:09": "and then also the term fake news has",
  "20:12": "been co-opted and is being used to to",
  "20:14": "attack the press and so this is kind of",
  "20:16": "why Claire Ward I'll recommend staying",
  "20:18": "away from this term which I mostly try",
  "20:20": "to do any questions so far",
  "20:28": "okay this information also includes",
  "20:33": "orchestrated campaigns of manipulation",
  "20:35": "so it's not necessarily you know just",
  "20:37": "like a single post but this kind of",
  "20:39": "entire campaign and network and so we",
  "20:43": "kind of saw that with this example of",
  "20:45": "the Russian operations in six countries",
  "20:48": "that was uncovered this fall and that",
  "20:51": "was uncovered by the Stanford Internet",
  "20:52": "Observatory this information is an",
  "20:56": "ecosystem and so Kate Starbird of the",
  "21:00": "University of Washington has done a lot",
  "21:03": "of work kind of looking at both Twitter",
  "21:06": "and web sites of kind of who links to",
  "21:09": "who and so this is a kind of diagram of",
  "21:14": "people tweeting about the Syrian white",
  "21:15": "helmets and blue is kind of supportive",
  "21:21": "or positive towards them and pink is",
  "21:22": "negative or opposed to and she in this",
  "21:26": "example found that most of the people",
  "21:30": "tweeting about this seem to be kind of",
  "21:33": "sincere genuine people and not",
  "21:35": "operatives but if you looked at kind of",
  "21:38": "what sites they were linking to there",
  "21:41": "were a few sites that showed up over and",
  "21:43": "over so you see YouTube was a huge one",
  "21:45": "also Russia today Sputnik news and so",
  "21:49": "this is something where you kind of have",
  "21:51": "to think about this you know it's not",
  "21:53": "just within Twitter but kind of who's",
  "21:54": "being linked to and again you can have",
  "21:58": "genuine people perhaps sharing",
  "22:01": "information from from questionable",
  "22:03": "sources and Claire Ward all talks about",
  "22:09": "this idea of the trumpet of",
  "22:10": "amplification and it's how how ideas or",
  "22:15": "her means can make it from 4chan or a",
  "22:18": "Chan eventually into our kind of",
  "22:21": "mainstream media conversation and one",
  "22:25": "common path is kind of to first be",
  "22:28": "picked up by closed messaging groups",
  "22:32": "such as on whatsapp telegram or Facebook",
  "22:35": "messenger where things are widely shared",
  "22:37": "then they may jump into kind of",
  "22:39": "conspiracy communities on reddit or",
  "22:41": "YouTube from there to social media and",
  "22:44": "then are often covered kind of by",
  "22:45": "professional media or politicians",
  "22:48": "although we have seen examples where",
  "22:50": "it's a much shorter chain and things",
  "22:52": "kind of jump jump there sooner and so",
  "22:54": "this this makes it though it's like it's",
  "22:56": "a very difficult problem to to even",
  "22:59": "study your address because you're",
  "23:00": "looking at kind of so many different",
  "23:03": "companies and sites and organizations",
  "23:06": "and because this can move very quickly",
  "23:08": "between between sites",
  "23:10": "people can also or at least the",
  "23:13": "phenomena can kind of leverage",
  "23:15": "inconsistencies in the the rules or",
  "23:17": "enforcement of different sites and one",
  "23:24": "of the reasons I think that this is",
  "23:26": "really important to kind of be thinking",
  "23:28": "about and working on is that",
  "23:30": "disinformation undermines democracy a",
  "23:36": "lot of sloths bit men who was used to",
  "23:39": "work for a kind of Soviet disinformation",
  "23:42": "office I believe in the 60s and then",
  "23:45": "defected to the United States and later",
  "23:48": "became a professor of disinformation",
  "23:50": "said most campaigns are a carefully",
  "23:53": "designed mixture of facts half-truths",
  "23:55": "exaggerations and deliberate lies",
  "23:59": "I've heard other people say that you",
  "24:02": "know good propaganda contains seeds of",
  "24:04": "truth so again there's not you know",
  "24:06": "necessarily kind of a clear clear",
  "24:08": "distinction of true or false",
  "24:10": "Kate Starbird said disinformation is not",
  "24:13": "just about BOTS and trolls it targets",
  "24:16": "cultivate shapes and ultimately",
  "24:18": "leverages unwitting crowds to further",
  "24:20": "spread and achieve its objectives and we",
  "24:23": "saw that kind of with that first example",
  "24:25": "of people actually attending protests",
  "24:29": "totally unwittingly you know when I saw",
  "24:31": "the protesters that support freedom of",
  "24:33": "religion and diversity and I like so",
  "24:35": "many other signs I can relate but",
  "24:37": "they're you know being leveraged kind of",
  "24:39": "as part of a part of this campaign and",
  "24:43": "so we saw that here and then",
  "24:48": "disinformation pollutes our information",
  "24:50": "environment and so saying up to facti",
  "24:55": "who's kind of one of the foremost",
  "24:56": "experts in this area and has also really",
  "24:59": "studied you kind of the role of",
  "25:00": "Technology in protests around the world",
  "25:02": "says when I talked to dissidents around",
  "25:05": "the world they rarely asked me how they",
  "25:07": "can post information anonymously but",
  "25:09": "they do often ask me how to authenticate",
  "25:11": "the information they post dissidents can",
  "25:14": "end up putting their lives on the line",
  "25:16": "to post a picture documenting wrongdoing",
  "25:18": "only to be faced with an endless stream",
  "25:21": "of deliberately misleading claims that",
  "25:23": "the picture was taken 10 years ago that",
  "25:26": "it's from somewhere else that it's been",
  "25:28": "doctored and zeyneb definitely supports",
  "25:31": "that there are people that need to post",
  "25:33": "anonymously particularly whistleblowers",
  "25:36": "may need to have you know kind of stable",
  "25:39": "pseudonyms that they can they can use in",
  "25:41": "sharing I thought this was really kind",
  "25:43": "of interesting perspective about how how",
  "25:45": "often people can be discredited and",
  "25:48": "people want a way to authenticate what",
  "25:50": "they're sharing because the problem with",
  "25:52": "disinformation is not just that we may",
  "25:54": "believe things that are not true but",
  "25:56": "that we may not believe things that are",
  "25:58": "true and that's a kind of a real a real",
  "26:01": "risk and something that's already",
  "26:03": "already happening",
  "26:06": "and kind of related issue that saying up",
  "26:10": "has spoken about is how the nature of",
  "26:13": "censorship has really changed and",
  "26:15": "censorship now works by flooding people",
  "26:20": "with information by causing distraction",
  "26:22": "causing confusion creating doubts and",
  "26:25": "just this question mark and shadow so",
  "26:28": "that you can't really figure out what's",
  "26:29": "going on and so she was in particular",
  "26:32": "talking about kind of the WikiLeaks dump",
  "26:35": "method and saying that just kind of",
  "26:37": "releasing things isn't necessarily",
  "26:39": "whistleblowing she refers it refers to",
  "26:41": "it as whistle drowning although this",
  "26:44": "happens kind of even more broadly than",
  "26:46": "just document dumps but that kind of",
  "26:50": "we're just flooded and inundated with",
  "26:52": "information and can drown out really",
  "26:54": "important kind of important news that we",
  "26:56": "need to hear and so kind of in the",
  "27:03": "context of releasing large troves of",
  "27:05": "documents this is referred to as hack",
  "27:07": "and leak includes Climategate and",
  "27:10": "Hillary Clinton's emails and what",
  "27:14": "happens is something called narrative",
  "27:15": "laundering where people can build",
  "27:17": "stories on top of real documents and so",
  "27:20": "kind of taking real documents but then",
  "27:22": "using them towards kind of certain ends",
  "27:24": "to try to create a narrative something",
  "27:27": "that experts such as Renee de Resta have",
  "27:30": "warned about is that we may see more",
  "27:32": "mixing faked documents in with real",
  "27:36": "documents and so there was a set of",
  "27:40": "cyber attacks on anti-doping agencies",
  "27:44": "sometime last year and people say that",
  "27:47": "there were kind of some fake documents",
  "27:49": "mixed in mixed into that we paws are",
  "27:55": "there any question can you hold that",
  "28:02": "catch box a little bit closer like our",
  "28:05": "using narrative laundering especially is",
  "28:07": "something like",
  "28:08": "National Geographic and stuff where",
  "28:09": "they're filming animals and then come up",
  "28:11": "with a story I have a friend who's",
  "28:13": "actually filming for National Geographic",
  "28:14": "and say we took months and months of",
  "28:16": "filming and then sensitive and they",
  "28:18": "completely moved everything around and",
  "28:20": "like the clips are not actually in the",
  "28:22": "order that things take place and the",
  "28:23": "story is totally written afterwards oh",
  "28:25": "yeah that's an interesting example I",
  "28:27": "think that also gets set that there I'm",
  "28:30": "sure this happens with you know any",
  "28:33": "documentary is gonna have to like cut",
  "28:34": "down the material and is imposing some",
  "28:37": "sort of kind of frame on what gets",
  "28:39": "chosen and I think there ways to do that",
  "28:41": "ethically and then also ways where",
  "28:43": "you've become deceptive with what you're",
  "28:45": "doing and I don't know that it's always",
  "28:47": "I'm sure there are a lot of in-between",
  "28:49": "instances where it may not be clear of",
  "28:51": "like okay this is an acceptable amount",
  "28:53": "of editing and shaping and okay now",
  "28:56": "you've definitely crossed over and are",
  "28:57": "misleading people and I think that's",
  "29:01": "also kind of an example where you have",
  "29:03": "just this huge volume of material that",
  "29:05": "you have to kind of cut down because",
  "29:08": "volume is one of the things that I think",
  "29:09": "enables this I mean so anything like",
  "29:18": "definitely like with Climategate and you",
  "29:21": "know that's something we're kind of all",
  "29:23": "these emails from climate scientist were",
  "29:25": "were hacked and released and really the",
  "29:28": "discussions they were having were",
  "29:29": "completely reasonable like there was not",
  "29:32": "I don't think any scientist thinks there",
  "29:36": "was like a controversy there about what",
  "29:39": "they were doing or how they were doing",
  "29:40": "it but it was used to kind of things",
  "29:43": "were taken out of context and kind of",
  "29:45": "put together to be like look these",
  "29:46": "climate scientists are lying to us",
  "29:48": "they're kind of doing unethical things",
  "29:50": "to make it seem like climate change is",
  "29:52": "happening when it's not and so that kind",
  "29:55": "of created this whole narrative that was",
  "29:58": "was not accurate but it's it's something",
  "30:01": "we're kind of if you have enough volume",
  "30:03": "of documents and I think it gets easier",
  "30:05": "and easier to do that so do we also see",
  "30:08": "this type of pattern where you have like",
  "30:10": "highly",
  "30:12": "I did like field-specific so the",
  "30:16": "scientific papers were medical papers",
  "30:18": "that take very specific clips out and",
  "30:21": "then turn it into a form of language as",
  "30:24": "much more easily consumed so you know",
  "30:26": "less like you know area specific",
  "30:30": "language just common language that masks",
  "30:33": "the masses can kind of pursue them and",
  "30:35": "understand that uh does it make sense so",
  "30:39": "I'm reading a medical PDF maybe like 20",
  "30:41": "pages long I'm probably not gonna read",
  "30:44": "the whole thing right you can take a",
  "30:45": "couple sentences out of there they're",
  "30:47": "true and then build a story on top of",
  "30:48": "that that can be put into 140 characters",
  "30:51": "or having yes yeah this is what it says",
  "30:54": "typical a typical pattern that we see",
  "30:56": "with narrative laundering so so like",
  "30:59": "what you're describing I think often",
  "31:01": "would not be narrative laundering",
  "31:03": "because someone I think could be right",
  "31:04": "making a story that even though it's",
  "31:05": "oversimplified could be very accurate",
  "31:07": "and this I should check but like this",
  "31:10": "definition was in the context of kind of",
  "31:12": "I think like a massive volume of",
  "31:14": "documents but you're right about the",
  "31:16": "kind of the dynamic of yeah if you have",
  "31:20": "a 20-page highly specialized paper for",
  "31:24": "most people to understand it we do need",
  "31:25": "someone to come along and give us kind",
  "31:27": "of a simpler story about it although",
  "31:29": "ideally that someone would be",
  "31:31": "trustworthy and would produce the story",
  "31:32": "that was kind of accurate and in keeping",
  "31:35": "with what was there all right another",
  "31:38": "question oh wait can you send it back",
  "31:41": "just for the recording I guess my answer",
  "31:48": "that was yes I was a psychology major",
  "31:51": "undergrad with so many psych papers and",
  "31:53": "one of the pieces of every publish psych",
  "31:56": "papers there has to be a conclusion and",
  "31:58": "so many psychologists take the study",
  "32:01": "that they did and as part of the",
  "32:03": "conclusion they have to draw real world",
  "32:05": "applications real world how do you apply",
  "32:07": "it and even though so many of the",
  "32:09": "studies are just done at colleges mainly",
  "32:11": "female participants they generalize it",
  "32:14": "to everyone in the world even though",
  "32:16": "it's done in the US and make only five",
  "32:18": "Americans and so they do a lot of this",
  "32:20": "kind of creating a story for the whole",
  "32:22": "world where that may not be really where",
  "32:24": "it applies ya know so and I think that",
  "32:27": "this is gets it broader issues with",
  "32:28": "scientific communication although I do",
  "32:30": "want to bring us back to kind of",
  "32:32": "disinformation specifically but yeah",
  "32:35": "they're all kind of perhaps similar",
  "32:38": "issues that show up in other forms of of",
  "32:40": "scientific communication all right I'll",
  "32:45": "keep going well we'll have more time for",
  "32:47": "for questions later as we go on it so",
  "32:51": "now I'm going to talk a little bit about",
  "32:52": "how the the kind of the role of the tech",
  "32:55": "platforms and incentivizing and",
  "32:58": "promoting disinformation so this is and",
  "33:01": "I'm not something that that happens in a",
  "33:02": "vacuum and so this is this is mostly",
  "33:08": "unintentional but it shows up in their",
  "33:10": "design and architecture and their",
  "33:12": "recommendation systems in their business",
  "33:15": "models around kind of what what gets",
  "33:18": "incentivized and so this is you know and",
  "33:23": "a lot of these choices when they were",
  "33:24": "originally being made probably people",
  "33:26": "weren't thinking about just information",
  "33:28": "at all but they do kind of help create",
  "33:30": "the ecosystem that we're in and so",
  "33:34": "Guillaume Chaz Lotte is former Google",
  "33:37": "engineer who worked on YouTube's",
  "33:39": "recommendation algorithm rockin like",
  "33:42": "2013 and has been very vocal about it",
  "33:44": "since leaving he's also founder of algo",
  "33:48": "watt or algo transparency group so this",
  "33:51": "is a chart so he kind of monitors kind",
  "33:55": "of YouTube's recommendation system from",
  "33:56": "the outside now this is a chart he",
  "33:58": "created that was picked up by The",
  "33:59": "Washington Post and here the x-axis is",
  "34:03": "the number of channels recommending a",
  "34:05": "video and the y-axis is the log of the",
  "34:09": "number of views and you see there's this",
  "34:12": "extreme outlier that was Russia today's",
  "34:14": "take on the Mueller Report something",
  "34:17": "that was being recommended a ton even",
  "34:21": "though it was actually not ending up",
  "34:22": "kind of more popular like you might",
  "34:25": "expect and I think this is kind of",
  "34:27": "potential evidence that that the",
  "34:30": "recommendation system can be gamed there",
  "34:32": "has been gamed which i think is a",
  "34:34": "really kind of anytime that you're",
  "34:36": "really relying on metrics wrote a post",
  "34:39": "about this in the fall the problem with",
  "34:40": "metrics is a big problem for AI that",
  "34:43": "kind of whenever you put a lot of",
  "34:45": "emphasis on a metric people can and will",
  "34:47": "try to game it you'll also see maybe",
  "34:49": "unexpected kind of behavior or side",
  "34:52": "effects to what you're doing so this is",
  "34:57": "a one frame for kind of for thinking",
  "34:59": "about disinformation and this has gotten",
  "35:01": "all kind of a lot more media attention I",
  "35:02": "would say in the last six months to a",
  "35:04": "year about the the role of",
  "35:05": "recommendation systems another",
  "35:10": "interesting study from this fall looked",
  "35:13": "at basically how people if so they asked",
  "35:19": "people you know do you think this story",
  "35:21": "is credible and they kind of balance for",
  "35:24": "getting Republicans and Democrats and",
  "35:26": "found that people could identify kind of",
  "35:28": "whether a story was credible or not even",
  "35:30": "across their political lines but then",
  "35:32": "they also kind of a separate large group",
  "35:34": "of people asked would you share this",
  "35:36": "story or not",
  "35:37": "and that was basically completely",
  "35:39": "disconnected from whether it was",
  "35:41": "credible and was very tied to political",
  "35:44": "ties and so so this kind of suggests",
  "35:47": "that when people are deciding whether to",
  "35:49": "share something they're not they're not",
  "35:51": "even thinking like is this credible",
  "35:53": "there are a lot of other kind of",
  "35:54": "emotions and factors that go into kind",
  "35:56": "of what gets gets shared and I liked in",
  "36:00": "the paper they they highlighted that",
  "36:02": "social media platforms may tilt users",
  "36:04": "away from considering accuracy for",
  "36:07": "instance they encourage users to rapidly",
  "36:09": "scroll and spontaneously engage so",
  "36:12": "they're not necessarily kind of",
  "36:13": "encouraging people to to spend a long",
  "36:15": "time thinking about a particular post or",
  "36:17": "a particular article before before they",
  "36:19": "share it they also mix very serious news",
  "36:22": "content with emotionally engaging",
  "36:24": "content so often kind of we're really",
  "36:26": "engaging in this emotional way and then",
  "36:29": "also you know you've got a cat video or",
  "36:32": "a baby picture and then kind of some",
  "36:34": "very like serious or devastating",
  "36:36": "political news or enraging political",
  "36:37": "news and it's all all mixed together",
  "36:41": "and unless we get this immediate",
  "36:43": "quantified feedback and the number of",
  "36:45": "likes it really kind of influences",
  "36:47": "people to kind of be getting that that",
  "36:50": "response and so none of this is",
  "36:53": "particularly conducive to getting people",
  "36:55": "to to stop and ask is this is this",
  "36:58": "credible so in the in this study they",
  "37:02": "they did so they're kind of a few parts",
  "37:04": "to it but in one part they deemed people",
  "37:08": "a question and they said we're doing a",
  "37:10": "survey do you think the following link",
  "37:12": "is credible and what they said them was",
  "37:14": "politically neutral so it wasn't wasn't",
  "37:17": "something that should follow along party",
  "37:18": "lines and they found that people that",
  "37:20": "received this seem to tweet more",
  "37:25": "credible links for 24 hours afterwards",
  "37:27": "that just even kind of prompting people",
  "37:30": "to be like is this credible as a",
  "37:32": "question that you should potentially",
  "37:33": "think about potentially got them to kind",
  "37:37": "of think about that more and they only",
  "37:39": "looked it for 24 hours afterwards but I",
  "37:41": "thought that was that was interesting",
  "37:42": "and so that's you know a small study and",
  "37:44": "kind of one piece of one piece of data",
  "37:48": "and then also sure there's some research",
  "37:51": "from Becca Lewis who's a PhD student at",
  "37:53": "Stanford and she highlights that it's",
  "37:56": "more than just the algorithm and this is",
  "37:58": "not kind of incompatible with the the",
  "38:00": "algorithm playing a role that she she",
  "38:04": "looks at various kind of other dynamics",
  "38:06": "of celebrity culture on YouTube and so",
  "38:10": "the paper I have listed here she kind of",
  "38:13": "does it's a qualitative case study kind",
  "38:16": "of looking at a few YouTube influencers",
  "38:18": "in the way that they have kind of",
  "38:20": "positioned themselves as you know the",
  "38:23": "mainstream media is not telling you the",
  "38:25": "truth but I'm a lot more authentic and",
  "38:27": "credible and then also kind of the",
  "38:29": "mainstream media is overly pushing kind",
  "38:32": "of liberal ideals but I'm gonna be",
  "38:33": "authentic incredible and kind of tell",
  "38:35": "you these all old right ideals and have",
  "38:38": "kind of been effective at aligning these",
  "38:40": "two different axes and so that's",
  "38:43": "interesting to also kind of keep in mind",
  "38:45": "these other other social and cultural",
  "38:49": "dynamics that impact impact this",
  "38:53": "so summary kind of our online",
  "38:57": "environments are designed to be",
  "38:59": "addictive in many cases so kind of the",
  "39:01": "the reading so I had an article from",
  "39:05": "from Guillaume test lot in the assigned",
  "39:07": "reading and he talked about how and",
  "39:09": "YouTube has updated its algorithm but in",
  "39:12": "the early days it was about maximizing",
  "39:14": "watch time which i think is true of many",
  "39:16": "platforms they want to keep people on",
  "39:17": "the platforms longer the incentives tend",
  "39:21": "to really focus on short term metrics",
  "39:23": "it's and some of this is it's much",
  "39:25": "harder to measure long term quantities",
  "39:27": "of you know what is your long term kind",
  "39:32": "of trust in trust in the platform or you",
  "39:36": "know even just like what's the long term",
  "39:38": "health of the information being shared",
  "39:40": "these are tough things to measure and so",
  "39:42": "I think that short term incentives tend",
  "39:44": "to get over emphasized and then finally",
  "39:48": "like the fundamental business model is",
  "39:50": "around manipulating people's behavior",
  "39:52": "and monopolizing their time and not",
  "39:55": "something that I think is it's okay in",
  "39:58": "limited doses but that ultimately kind",
  "40:01": "of doesn't lead for a great alignment of",
  "40:03": "incentives with the well-being of",
  "40:06": "society and this is a slide that renamed",
  "40:11": "at rest and so Rene is kind of one of",
  "40:14": "the top experts on computational",
  "40:15": "propaganda and she led one of the teams",
  "40:17": "that analyzed the the Russian materials",
  "40:22": "for the Senate House Committee she was",
  "40:24": "also kind of very involved in studying",
  "40:29": "that the anti-vaxxer movement kind of",
  "40:31": "years ago shared it our political",
  "40:34": "conversations are happening on an",
  "40:36": "infrastructure built for viral",
  "40:37": "advertising and so here there's kind of",
  "40:40": "this real real mismatch so let me pause",
  "40:43": "for a moment are there questions on this",
  "40:45": "kind of this component of the role that",
  "40:48": "that the type of tech platforms play",
  "40:52": "question in the back and let me Oh",
  "40:55": "perfect",
  "40:58": "I think it's more of an observation is",
  "41:00": "employed for all of these points I'm",
  "41:03": "particularly back to rest as article and",
  "41:06": "the shifts in technology radio to",
  "41:08": "television and television is my very",
  "41:11": "broad unqualified observation is that",
  "41:14": "the technology has simply arrived to",
  "41:17": "make this scale out in the way it was",
  "41:19": "intended I don't know that I see much",
  "41:21": "difference in media i justi difference",
  "41:24": "in the efficacy of this delivery system",
  "41:29": "yeah and he said this definitely is more",
  "41:32": "effective and some of the yeah I mean",
  "41:33": "there's writing that was done on",
  "41:35": "television in the 80s that you read in",
  "41:37": "it's like oh that sounds like they're",
  "41:38": "talking about the internet and the",
  "41:39": "problems were facing now I mean the the",
  "41:42": "scale is so like the scale is",
  "41:47": "significant that it is so so big I mean",
  "41:50": "I think that they're around the",
  "41:52": "incentives like I think that I don't",
  "41:55": "know if we didn't have kind of",
  "41:58": "personalized ad targeting I do think we",
  "42:00": "would be in a different ecosystem and I",
  "42:01": "think we would still have problems but",
  "42:02": "they would probably be different",
  "42:05": "problems and there'd be a different",
  "42:06": "nature to the ecosystem but I think that",
  "42:09": "these are kind of particular choices you",
  "42:11": "know like we could there could be a",
  "42:15": "world where we we have the Internet and",
  "42:16": "kind of mass communication but where",
  "42:18": "it's funneling in very different ways",
  "42:20": "and I do think like in particular",
  "42:21": "personalized ad targeting has kind of",
  "42:23": "put us down a very circular path and I'm",
  "42:28": "a more serious part and so it's also",
  "42:30": "important to note that humans really",
  "42:32": "have kind of evolved as social beings",
  "42:34": "and to have our our opinions it",
  "42:38": "influenced by others",
  "42:40": "that we kind of consider part of our in",
  "42:41": "group and often kind of in an opposition",
  "42:44": "to people we think are in our out group",
  "42:45": "that we're very we are influenced by",
  "42:49": "others and it can be hard to recognize",
  "42:51": "because I think many of us think of",
  "42:53": "ourselves as independent minded but but",
  "42:56": "the society plays plays a role and",
  "42:58": "people have have a lot of different kind",
  "43:02": "of discussions online that can help form",
  "43:04": "opinions and so this is a discussion",
  "43:08": "reddit someone saying I believe the US",
  "43:12": "should cut all defense spending and",
  "43:14": "instead spend money on the military I",
  "43:16": "know there's a lot of money in the",
  "43:18": "defense budget but if you take the money",
  "43:20": "we have somebody else says you're wrong",
  "43:22": "the defense budget is a good example of",
  "43:24": "how badly the u.s. spends on the",
  "43:26": "military so it all says yeah but that's",
  "43:28": "already happening there's a huge",
  "43:30": "increase in the military budget I didn't",
  "43:32": "mean to sound like stop paying for the",
  "43:34": "military I'm not saying that we cannot",
  "43:36": "pay the bills but I think it makes sense",
  "43:38": "to cut defense spending and so does does",
  "43:41": "anyone want to guess what subreddit this",
  "43:43": "is from that's right so subreddit",
  "43:47": "simulator which is the GPT 2 subreddit",
  "43:50": "so these were all computer generated and",
  "43:54": "they're I think if you read these",
  "43:55": "closely you can tell that they're a",
  "43:57": "little bit a little bit off but I think",
  "43:59": "they are close to being compelling of",
  "44:02": "how of how people might discuss or argue",
  "44:05": "about a topic and this is something that",
  "44:07": "I think is and this is clearly marked as",
  "44:09": "having been generated by an algorithm so",
  "44:13": "it's kind of in good fun but it's",
  "44:15": "alarming to think about how this how",
  "44:18": "this could be used so yeah GPT - and",
  "44:24": "it's it's all marked",
  "44:27": "so just in raise your hand who who's",
  "44:30": "heard about GP and GPT - is just part of",
  "44:32": "this whole kind of family of research",
  "44:35": "and so it wasn't this is a model from",
  "44:38": "open AI and it was kind of along the",
  "44:41": "trajectory of how natural language",
  "44:43": "research and in AI has been going but it",
  "44:48": "can produce stories that are quite",
  "44:49": "compelling so this is one that they",
  "44:51": "share and when they when they've kind of",
  "44:53": "first first published about it and so",
  "44:56": "here the the human written system prompt",
  "44:59": "that was given said in a shocking",
  "45:02": "finding scientists discovered a herd of",
  "45:04": "unicorns living in a remote previously",
  "45:06": "unexplored valley in the Andes Mountains",
  "45:09": "even more surprising to the researchers",
  "45:11": "was the fact that the unicorn spoke",
  "45:13": "perfect English so that was written by a",
  "45:16": "human",
  "45:17": "and the response from the algorithm at",
  "45:19": "the algorithm generated said and all",
  "45:22": "just three parts of this to you dr.",
  "45:25": "Jorge Perez an evolutionary biologist",
  "45:27": "from the University of La Paz and",
  "45:29": "several companions were exploring the",
  "45:31": "Andes Mountains when they found a small",
  "45:33": "valley with no other animals or humans",
  "45:35": "Perez noticed that the valley had what",
  "45:38": "appeared to be a natural fountain",
  "45:39": "surrounded by two peaks of rock and",
  "45:42": "silver snow Perez and the others then",
  "45:45": "ventured further into the valley by the",
  "45:47": "time we reached the top of one peak the",
  "45:49": "water looked blue with some crystals on",
  "45:51": "tops of Perez Perez and his friends were",
  "45:54": "astonished to see the Unicorn heard",
  "45:56": "while examining these bizarre creatures",
  "45:58": "the scientists discovered that the",
  "46:00": "creatures also spoke some fairly regular",
  "46:02": "English Perez stated we can see for",
  "46:04": "example that they have a common language",
  "46:06": "something like a dialect or dialectic",
  "46:08": "and so I think that's a really kind of",
  "46:10": "nice story to have been generated by an",
  "46:12": "algorithm and it was a new one cherry",
  "46:14": "picked everything not everything is as",
  "46:17": "the Scoob but this is a really good",
  "46:18": "story and this is computer generated and",
  "46:22": "so this is I think concerning",
  "46:25": "particularly when you think about",
  "46:26": "combining it with with other forms of",
  "46:30": "media so this is Katie Jones who as",
  "46:34": "Russia and Eurasia fellow connected to",
  "46:37": "people from several kind of mainstream",
  "46:38": "think tanks on LinkedIn and it was",
  "46:42": "revealed that she's not a real person so",
  "46:46": "this was discovered by The Associated",
  "46:47": "Press last summer this is a",
  "46:49": "computer-generated photo kind of created",
  "46:51": "by a gang and so again this is a",
  "46:54": "compelling photo and so you can start",
  "46:56": "thinking about putting together",
  "46:58": "compelling text with compelling photos",
  "47:00": "and fake accounts are going to become",
  "47:03": "much much harder to spot and I think",
  "47:06": "sometimes you know in the past but like",
  "47:08": "oh you know somebody who has an egg for",
  "47:10": "their Twitter profile you like you know",
  "47:12": "this is kind of like a troll or not",
  "47:14": "worth responding to but those are",
  "47:16": "accounts are going to get much much",
  "47:17": "harder to spot you can go to this person",
  "47:22": "does not exist calm to see other",
  "47:25": "examples of Gann generated photos so",
  "47:28": "again this is",
  "47:29": "not a real person not a real person not",
  "47:31": "a real person",
  "47:32": "and I like to highlight this because I",
  "47:34": "think you know I think deep fakes and",
  "47:36": "video are getting a lot of a lot of",
  "47:38": "attention but also to think about just",
  "47:40": "the combination of what good profile",
  "47:43": "photos and convincing text will be able",
  "47:45": "to do is alarming",
  "47:48": "I think online discussions will be",
  "47:51": "swamped with fake manipulative agents",
  "47:53": "and also at scale so we've been talking",
  "47:56": "about this idea of volume but what does",
  "47:58": "it mean to kind of have a high volume so",
  "48:03": "something that happened back in 2017",
  "48:06": "which was a long time ago in terms of",
  "48:09": "kind of AI research and developments is",
  "48:12": "that the FCC was considering repealing",
  "48:16": "net neutrality and they opened up for",
  "48:18": "comments so how do people feel about net",
  "48:21": "neutrality and they got a lot of",
  "48:23": "comments that were opposed to net",
  "48:26": "neutrality in favor of the repeal here",
  "48:28": "are a few of them Americans as opposed",
  "48:31": "to Washington bureaucrats deserve to",
  "48:33": "enjoy the services they desire",
  "48:35": "individual citizens as opposed to",
  "48:37": "Washington bureaucrats should be able to",
  "48:39": "select whichever service they desire",
  "48:41": "people like me as opposed to so-called",
  "48:43": "experts should be free to buy whatever",
  "48:45": "products they choose and so you can kind",
  "48:47": "of see a pattern here which has also",
  "48:49": "been hopefully kind of color highlighted",
  "48:51": "but basically this is a kind of mad lib",
  "48:54": "style where you had a few choices for",
  "48:57": "the the green spot in the sentence and",
  "48:59": "then a few choices for the pink spot and",
  "49:01": "so on and this was discovered by Jeff",
  "49:04": "Cao who's now a computational journalist",
  "49:07": "at Pro Publica but he found that there",
  "49:12": "were more than a million Pro repeal net",
  "49:14": "neutrality comments in this cluster and",
  "49:17": "it's not just that they're kind of using",
  "49:19": "this form it's that they were designed",
  "49:21": "to look unique and to be different",
  "49:24": "because they're using kind of all these",
  "49:25": "different combinations and so this is",
  "49:28": "something this was great work on Jeff's",
  "49:29": "part that he discovered this but it was",
  "49:32": "still relatively primitive when you",
  "49:33": "think about that this was kind of mail",
  "49:35": "merge style of just plugging in these",
  "49:37": "these different places",
  "49:40": "and he did you should check out this",
  "49:42": "blog post so he found of over 22 million",
  "49:47": "comments submitted less than four",
  "49:50": "percent were truly unique and that's not",
  "49:53": "all spam like there are you know",
  "49:55": "campaigns that give you a template to",
  "49:57": "email in but that is a really small",
  "49:59": "number of unique comments and more than",
  "50:06": "99% of the truly unique comments wanted",
  "50:08": "to keep net neutrality but that was very",
  "50:10": "different than the overall picture you",
  "50:12": "would get if you included kind of these",
  "50:15": "spam campaigns and this is something",
  "50:18": "that is is concerning and also thinking",
  "50:22": "back to kind of more sophisticated",
  "50:24": "language models would be very very hard",
  "50:27": "to identify now I think if someone did",
  "50:30": "this and so yeah as I've said deep fakes",
  "50:35": "are getting a lot of attention and are",
  "50:37": "something to worry about but also we",
  "50:39": "need to kind of think about all of these",
  "50:40": "things as well as also primitive",
  "50:43": "techniques are still really effective",
  "50:44": "and Photoshop and even just memes on",
  "50:47": "photos are very effective so it's it's",
  "50:49": "not just about the latest technology",
  "50:51": "although I do think the latest",
  "50:52": "technology can can certainly exacerbate",
  "50:56": "these things and make them make them",
  "50:57": "even scarier so my my co-founder Jeremy",
  "51:03": "said last year we have the technology to",
  "51:06": "totally fill Twitter email and the web",
  "51:08": "up with reasonable sounding context",
  "51:11": "appropriate pros which would drown out",
  "51:13": "all other speech and be impossible to",
  "51:14": "filter and this also gets back to this",
  "51:17": "idea of kind of volume and how do we",
  "51:18": "filter through the volume to even know",
  "51:22": "for real people to have a voice as well",
  "51:24": "as kind of fraudulent campaigns and the",
  "51:30": "other kind of very concerning aspect of",
  "51:33": "this is that extreme viewpoints become",
  "51:34": "normalized when we're around others who",
  "51:37": "we think hold those views or if we start",
  "51:39": "thinking that more people hold a certain",
  "51:41": "view it starts seeming more normal",
  "51:43": "actually should have put people in",
  "51:45": "quotes but if we think more more",
  "51:47": "entities hold of view and so kind of on",
  "51:50": "note we've seen this rise and",
  "51:52": "white-supremacist shootings in the last",
  "51:55": "year - a kind of mass shootings so there",
  "51:59": "was a kind of the shooting at the",
  "52:01": "Pittsburgh synagogue in 2018 in which 11",
  "52:04": "people were murdered and the the shooter",
  "52:09": "was very active on social media and even",
  "52:12": "posted directly before committing the",
  "52:13": "shooting there was the shooting at to",
  "52:16": "New Zealand mosque last year in which 49",
  "52:20": "people were murdered and the New York",
  "52:23": "Times characterized this as a mass",
  "52:24": "murder oven for the Internet um the",
  "52:28": "attack was teased on Twitter announced",
  "52:29": "on each hand broadcast live on Facebook",
  "52:32": "the footage was then replayed endlessly",
  "52:34": "on YouTube Twitter and reddit and so",
  "52:36": "this is kind of already a very serious",
  "52:39": "problem and we don't need fancy",
  "52:40": "technology to make this work",
  "52:43": "worse but it is a concern that kind of",
  "52:47": "disinformation and kind of more",
  "52:50": "sophisticated language models and",
  "52:52": "fraudulent accounts could amplify this",
  "52:54": "even further all right with that this is",
  "53:01": "actually kind of a good stopping point",
  "53:02": "for our break so we'll take a kind of",
  "53:09": "seven seven minute break and the kind of",
  "53:12": "bathrooms and water fountains are if you",
  "53:14": "kind of turn left towards the end of the",
  "53:16": "hall and then we'll come back we'll have",
  "53:18": "some more time for a kind of discussion",
  "53:20": "and also we'll start talking about",
  "53:22": "solutions more - all right so let's say",
  "53:26": "let's return from return from break I",
  "53:29": "want to start just by taking questions",
  "53:32": "if there are any questions on the last",
  "53:33": "section about this idea of kind of we've",
  "53:36": "seen new technology in text generation",
  "53:39": "so kind of generating compelling",
  "53:41": "language generating photos that look",
  "53:44": "like real people but are not and how",
  "53:46": "this could could be use to really kind",
  "53:49": "of influence or manipulate public",
  "53:51": "discourse",
  "53:55": "any questions or thoughts",
  "54:03": "all right oh and can you and it's fine",
  "54:12": "to throw the catch box I I shouldn't",
  "54:14": "share this I hit that girl in the head",
  "54:17": "and she was like she was fine but I've",
  "54:19": "been more shy about throwing it since",
  "54:20": "then yeah well I'll talk about that a",
  "54:33": "little more later and I will just say",
  "54:35": "now mike caulfield is a great he's kind",
  "54:39": "of an expert and on how digital literacy",
  "54:41": "is taught but he's a great person to",
  "54:43": "look up but I do have a slide about him",
  "54:44": "later it's a good question okay question",
  "54:51": "up here you know learning about throw",
  "55:05": "the arms race around creating this",
  "55:06": "information and help technology to",
  "55:08": "agreeance up my mind goes to will one of",
  "55:12": "the eliminations of fight in with the",
  "55:14": "same technology right like drowning out",
  "55:16": "the disinformation there's like a",
  "55:21": "straightforward answer about how much",
  "55:23": "you can use offensive techniques I think",
  "55:25": "about security this very world ya know",
  "55:28": "in there there are a lot of analogies to",
  "55:30": "security with disinformation yeah in",
  "55:33": "terms of yeah in terms of drowning out I",
  "55:36": "don't know it's an interesting idea but",
  "55:40": "ya know it is and I'll talk a little bit",
  "55:41": "more about this later but yeah like a",
  "55:43": "princess Renee dur esta and my Godwin",
  "55:46": "who is the original legal counsel to the",
  "55:47": "e FF have said you have to think of",
  "55:49": "disinformation as a cybersecurity issue",
  "55:53": "question over here if you can pass past",
  "55:57": "the catch box so the question is so",
  "56:04": "obviously when I turn it if you could",
  "56:06": "thing is like the companies that the",
  "56:08": "path from expose this information could",
  "56:11": "have been set is to actually fill this",
  "56:13": "technique",
  "56:14": "still quarter and five big flakes or",
  "56:15": "select that was obviously a single",
  "56:18": "person as these technologies improve we",
  "56:21": "would be hire a hard at the store",
  "56:22": "what is fake that I'm sure like big",
  "56:25": "companies I'm a trader server Google",
  "56:27": "they can build it lose right but then",
  "56:30": "the problem is I don't even litter when",
  "56:33": "they have to report every quarter how",
  "56:34": "many active users they have really",
  "56:36": "there's a significant number of user",
  "56:38": "that are thank you sir now by the way we",
  "56:42": "have like a 1 million users less than we",
  "56:45": "report so obviously if Canada from",
  "56:50": "moving with the earth there's a more",
  "56:51": "than actually the technical or other",
  "56:53": "ways instead it about how the market",
  "56:55": "actually yes so somehow I don't know the",
  "56:58": "government needs to I don't miss the the",
  "57:01": "downside I don't know yes yeah and so",
  "57:03": "we'll talk more about this later but",
  "57:04": "yeah you're hitting on several things I",
  "57:06": "mean there are there aren't great people",
  "57:09": "at at these companies even though",
  "57:11": "there's a lot I criticize about the the",
  "57:12": "major companies there are people who are",
  "57:14": "working on these problems but yeah I",
  "57:16": "think because of the misaligned",
  "57:17": "incentives and business models that I",
  "57:21": "believe there will be a limit to kind of",
  "57:24": "how much progress we can do and I do",
  "57:25": "think policy is gonna be one component",
  "57:27": "of more effectively addressing them so",
  "57:33": "what what should we do about all of this",
  "57:35": "and so those are those are some good",
  "57:36": "suggestions one one thing I wanted to",
  "57:41": "note first is to recognize that often",
  "57:45": "the goal of distance disinformation is",
  "57:47": "to disorient us until we can our trust",
  "57:50": "in institutions and so this is from a",
  "57:54": "post by Yochai benkler earlier earlier",
  "57:58": "this year that did kind of convince me a",
  "58:00": "little bit because I've definitely been",
  "58:01": "trying to have talked about the the",
  "58:03": "harms of disinformation but remember",
  "58:05": "that kind of overstating the impact will",
  "58:08": "have the same and the same effect of",
  "58:11": "kind of weakening people's trust in",
  "58:12": "institutions or in shared knowledge and",
  "58:16": "so to kind of keep our perspective and",
  "58:18": "recognize the things that that are still",
  "58:21": "working as well as kind of I guess",
  "58:25": "limiting alarmism while taking the the",
  "58:27": "seriously so a brief kind of a positive",
  "58:33": "note and this was something kind of",
  "58:36": "pretty simple is last year pinterest so",
  "58:40": "people were sharing a lot of anti-vaxxer",
  "58:43": "propaganda on pinterest and so pinterest",
  "58:45": "made a change that only kind of",
  "58:48": "well-respected health organizations",
  "58:50": "could even create pins about anything",
  "58:52": "related to vaccines or measles or kind",
  "58:55": "of search terms that people were using",
  "58:57": "and so this is like the Center for",
  "58:59": "Disease Control the American Academy of",
  "59:02": "pediatricians and the World Health",
  "59:05": "Organization and so on they can make",
  "59:07": "pins about vaccine safety nobody else",
  "59:10": "can and so this is you know a relatively",
  "59:12": "kind of simple solution but it's",
  "59:13": "something that I think is a really kind",
  "59:15": "of positive step I mean I guess the the",
  "59:20": "kind of the downside when platforms step",
  "59:22": "in like this although I totally kind of",
  "59:24": "agree with this application is it is a",
  "59:26": "lot of a lot of power that the",
  "59:28": "platform's have in terms of how people",
  "59:31": "receive information and kind of which",
  "59:33": "which issues they choose as worth acting",
  "59:36": "on so there was a question earlier about",
  "59:42": "what can Oh and wait let me paint past",
  "59:46": "the catch box the fact that the that",
  "59:54": "Pinterest has the ability to control",
  "59:57": "what users are exposed to like the",
  "60:00": "people who are looking for that",
  "60:01": "information what wouldn't they take that",
  "60:04": "as further proof that they're hiding",
  "60:06": "something that there's sort of",
  "60:08": "institutions that are working together",
  "60:10": "and that anecdotal experiences aren't",
  "60:13": "being shared that there's some value in",
  "60:15": "like just a mom saying hey this thing",
  "60:18": "happened to me and that another parent",
  "60:20": "might want to yeah so that argue that",
  "60:23": "argument is made and that does happen",
  "60:25": "like yes this would absolutely I'm sure",
  "60:29": "it was seen as evidence by anti-vaxxers",
  "60:33": "that there's a conspiracy theory trying",
  "60:34": "to suppress the truth I do think such",
  "60:38": "interventions can and this is also kind",
  "60:40": "because this is something where it's",
  "60:43": "this is pretty late in terms of the kind",
  "60:47": "of growth of anti-vaccine propaganda",
  "60:51": "which is something that I don't know if",
  "60:53": "you've seen that has been linked to",
  "60:55": "Russia as well that there were Russian",
  "60:58": "campaigns kind of both in the US and",
  "61:00": "Europe promoting anti-vaxxer propaganda",
  "61:04": "it's hard because yeah reacting to it",
  "61:06": "can be seen as further evidence of the",
  "61:08": "conspiracy theory although I think there",
  "61:11": "is also an argument that you limit its",
  "61:13": "reach particularly if you react it's",
  "61:15": "just something earlier that fewer people",
  "61:17": "seeing it it's a good thing and can",
  "61:21": "prevent it from from spreading there's",
  "61:24": "there's an in covering disinformation",
  "61:26": "there's often kind of this double bind",
  "61:27": "and that even even picking up a story",
  "61:32": "just to debunk it and saying you know",
  "61:34": "this is false is kind of giving it more",
  "61:36": "oxygen and so this is an area that's",
  "61:40": "still being studied of kind of there",
  "61:42": "does seem to be some sort of tipping",
  "61:44": "point which i think is hard to recognize",
  "61:46": "of you know if the conspiracy theory is",
  "61:48": "tiny you don't you don't want to pick it",
  "61:50": "up because you don't want to draw more",
  "61:51": "attention to it but then often by the",
  "61:55": "time something is kind of big enough",
  "61:57": "that it's like oh it's clear we need to",
  "61:59": "let people know this is false it's also",
  "62:01": "really big and so that's something where",
  "62:03": "I don't think there's a clear answer I'm",
  "62:05": "kind of when when do you step in there",
  "62:08": "are there are best practices for",
  "62:09": "journalists about how do you debug",
  "62:11": "something in a kind of more responsible",
  "62:13": "way but that is kind of a very fraught",
  "62:16": "area yes and can you pass the catch a",
  "62:21": "row back are there so I can tell myself",
  "62:27": "like what is usually a conspiracy theory",
  "62:29": "versus like research reality or yeah but",
  "62:34": "is there like frameworks or checklist",
  "62:37": "great great questions so Mike Caulfield",
  "62:40": "is who I would recommend on this topic",
  "62:42": "of digital literacy and he has a digital",
  "62:45": "literacy course at lessons check please",
  "62:48": "cc and one of his big ideas",
  "62:51": "that in the past there was a lot of",
  "62:55": "media literacy that was kind of giving",
  "62:56": "people like here's how you can spend a",
  "62:58": "half-hour like researching this topic",
  "62:59": "which and nobody's gonna do you know and",
  "63:02": "like you can't do that for every tweet",
  "63:03": "you see in your Twitter timeline and so",
  "63:07": "he really promotes like things that you",
  "63:09": "can do in under a minute because if it's",
  "63:11": "not fast people are just not going to do",
  "63:13": "it so I had often felt a little bit",
  "63:19": "skeptical of some media literacy efforts",
  "63:22": "just in that so many of these problems",
  "63:24": "are systemic and I don't want to be",
  "63:26": "tasking individuals with you know you",
  "63:28": "have to kind of recognize every false",
  "63:30": "thing this this post from from Mike",
  "63:34": "actually found pretty convincing and he",
  "63:36": "he's very aware like teaching",
  "63:39": "individuals to recognize issues is not",
  "63:43": "it's not gonna solve the systemic",
  "63:45": "problems and it's not a substitute but",
  "63:46": "it could help and it can create more",
  "63:48": "resilient networks and so he gave an",
  "63:50": "example of this tweet that has been",
  "63:53": "retweeted 3,000 times claiming that a",
  "63:56": "husband-and-wife Chinese spy team where",
  "63:58": "ramiz recently removed from a level 4",
  "64:01": "infectious disease facility in Canada",
  "64:03": "for sending pathogens to the wuhan",
  "64:06": "facility so it's making this claim about",
  "64:10": "a conspiracy theory about about spies",
  "64:13": "and it's linking to the Canadian",
  "64:15": "Broadcasting Company which is a very",
  "64:17": "kind of mainstream and respected news",
  "64:20": "outlet and so his recommendation is",
  "64:22": "number one click on the link and then",
  "64:26": "secondly do control-f to search for you",
  "64:30": "know you probably don't even have time",
  "64:31": "to read the full link but just do",
  "64:33": "control ass he also highlight so control",
  "64:35": "a whole search within a web page he",
  "64:38": "highlights a study from google that",
  "64:40": "found that 90% of web users do not know",
  "64:42": "about control f and so they're kind of",
  "64:45": "some kind of basic digital literacy",
  "64:48": "tools that are very kind of useful even",
  "64:51": "though they're they may seem simple and",
  "64:53": "so he did that he goes to this this cbc",
  "64:57": "site he finds that the word spy does not",
  "65:00": "even show up in the article",
  "65:02": "threat only shows up once and saying",
  "65:04": "that there's no threat to public safety",
  "65:06": "and so this is something where the tweet",
  "65:09": "has misrepresented the article to kind",
  "65:11": "of try to weave a conspiracy theory it's",
  "65:14": "perhaps a little bit of an example of",
  "65:15": "what we were talking about earlier and",
  "65:18": "it's also you know it's something that",
  "65:19": "you can check in 30 seconds you know you",
  "65:22": "just click the link and he searched for",
  "65:24": "I think a few other words and then saw",
  "65:26": "like hey this article does not seem to",
  "65:28": "support what was claimed in this tweet",
  "65:30": "he also he makes the point like I mean",
  "65:33": "there are plenty of problems with Google",
  "65:35": "search but doing a Google search of",
  "65:38": "something before you share it is way",
  "65:40": "better than not and in many cases will",
  "65:42": "surface an issue and so actually if we",
  "65:46": "have time all at the end I'll go into",
  "65:48": "this I was going to include it and I",
  "65:49": "wasn't sure about time I guess this game",
  "65:52": "or links to this game called fake out at",
  "65:54": "the beginning where you have to guess of",
  "65:55": "things where fake news or not and it",
  "65:58": "could be harder than you expect but",
  "66:01": "those are those are great questions so I",
  "66:02": "would recommend these materials and Ali",
  "66:05": "can you pass the catch box to the front",
  "66:09": "this is sort of curse to me having been",
  "66:13": "using mobile devices really extensively",
  "66:14": "for the past few weeks",
  "66:15": "there is like no control for let's say a",
  "66:18": "smart phone or at least I caught them",
  "66:20": "the iOS as far as I know and it occurs",
  "66:24": "to me that given how often people use",
  "66:26": "mobile devices to use the Internet in",
  "66:29": "general that could be a challenge of its",
  "66:31": "own but the highlights those sort of",
  "66:33": "moral social imperative to think really",
  "66:36": "deeply about like should Apple implement",
  "66:38": "some sort of way to search for text in",
  "66:41": "the page that you're currently viewing",
  "66:42": "and like that seems like such an",
  "66:44": "esoteric topic until just now oh you",
  "66:48": "should search for the word spy and if it",
  "66:50": "doesn't show up then question the",
  "66:51": "veracity of using that link in that",
  "66:53": "story",
  "66:54": "sort of like that's a great example and",
  "67:00": "as I say a stacy marie",
  "67:01": "ishmael has a talk that kind of on a",
  "67:05": "similar vein talked about some ways that",
  "67:07": "mobile is less conducive to like you",
  "67:09": "don't see as much of the URL in some",
  "67:11": "cases you can't even tell that the URL",
  "67:12": "is clickable like it's not",
  "67:15": "a parent in the design that there are a",
  "67:17": "lot of things about mobile that are way",
  "67:20": "less user friendly to letting users know",
  "67:22": "like you know because for just",
  "67:25": "information if something's from a",
  "67:26": "sketchy URL we know okay that's a bad",
  "67:28": "sign but on a mobile that is way less",
  "67:31": "clear and in some apps like in Facebook",
  "67:33": "it's often not clear like hey what is",
  "67:35": "coming from a link that you can click on",
  "67:36": "can I see that URL and so these are",
  "67:39": "things that yet might seem like esoteric",
  "67:41": "design decisions but have a big impact",
  "67:43": "on kind of how users kind of what clues",
  "67:47": "they get that could tip them off about",
  "67:48": "disinformation can you get that I'm",
  "67:53": "sorry oh okay you can so the comment was",
  "68:01": "just that it was using Twitter for",
  "68:02": "iPhone ask a question to the group",
  "68:07": "really but this is so simple look for",
  "68:10": "keywords control F it or if you're using",
  "68:14": "Chrome on a mobile device they and the",
  "68:17": "version of that but why can't we just",
  "68:20": "automate that why can't Twitter just do",
  "68:22": "this for us and score what it's showing",
  "68:24": "us I will say that I think this is still",
  "68:27": "kind of a sophisticated question of so a",
  "68:30": "lot of people ask so I do a lot of work",
  "68:32": "in deep learning as well with fast AI",
  "68:34": "and people are like oh you know can't",
  "68:36": "you train a deep learning algorithm to",
  "68:37": "identify disinformation a lot of it is",
  "68:41": "very context dependent and I can think",
  "68:45": "of a lot of scenarios where someone",
  "68:47": "could summarize an article and use a new",
  "68:48": "vocabulary word and it would be totally",
  "68:50": "reasonable you know like part of part of",
  "68:56": "what makes this suspicious is also just",
  "68:57": "like hey this does seem like a pretty",
  "68:59": "wild thing potentially a conspiracy",
  "69:02": "theory you know there are other Hughes",
  "69:05": "that were kind of picking up around it",
  "69:07": "and so this sort of kind of very",
  "69:09": "kind of context dependent is pretty",
  "69:11": "tricky so I don't think it's something",
  "69:13": "that could be automated possibly for I",
  "69:16": "don't even know if I don't feel I don't",
  "69:19": "feel comfortable making a prediction",
  "69:20": "that it could be automated because I",
  "69:22": "think it just involves kind of so much",
  "69:23": "context",
  "69:25": "but you're right it's like very simple",
  "69:27": "for a human to do yeah and it's also",
  "69:32": "like with these things the suggestion",
  "69:35": "was that it scores it right so it's not",
  "69:36": "that we're hiding anything right you",
  "69:38": "look you saw have the same access to all",
  "69:40": "the same data you just get like a score",
  "69:42": "that you can choose what to do it I'm",
  "69:48": "just yeah I mean I mean two issues with",
  "69:52": "that is that if you have yeah one thing",
  "70:03": "I'll say I mean I like I like that",
  "70:04": "you're really thinking about this if you",
  "70:06": "have a score though that's accurate like",
  "70:08": "90% of the time people will just start",
  "70:10": "trusting at all of the time and not feel",
  "70:13": "like they need to check the edge cases",
  "70:16": "and the edge cases are going to be very",
  "70:17": "significant here and so I think I think",
  "70:21": "there are a lot of risk to that approach",
  "70:23": "but it probably is worth exploring",
  "70:26": "further and then there's a hand kind of",
  "70:28": "two to your left I guess the question",
  "70:32": "for you it seems also pretty easy to",
  "70:34": "gain and it sort of stay ahead of that",
  "70:36": "metric give you a name yeah I said when",
  "70:39": "you get to kind of yeah algorithm",
  "70:41": "dependent yeah that there is the other",
  "70:43": "risk of gaming or figuring out what kind",
  "70:45": "of what the metrics are also stifle",
  "70:53": "creativity comedy parody you know yes",
  "70:56": "yeah to capture I think all of that and",
  "70:59": "it could also be user unfriendly",
  "71:01": "experience too because so in garage",
  "71:04": "having block to access information as",
  "71:09": "well that's the tricky part right",
  "71:11": "vanilla yes yeah that is a tricky",
  "71:13": "balance okay I'm going to keep going but",
  "71:16": "we'll have more time for questions just",
  "71:17": "because there's a lot more kind of",
  "71:19": "potential approaches so that's a little",
  "71:21": "bit about kind of the role digital",
  "71:23": "literacy could could play some other",
  "71:28": "approaches detecting fakes and",
  "71:31": "disinformation it is important to note",
  "71:33": "that this is always going to be an arms",
  "71:36": "race and so if you're familiar with the",
  "71:38": "it's basically you have kind of two",
  "71:42": "algorithms that are learning from each",
  "71:43": "other and you can use your detection",
  "71:46": "algorithm to make even more compelling",
  "71:47": "fakes responsible development tools",
  "71:51": "addressing the ecosystem treating as a",
  "71:54": "cybersecurity issue and verification",
  "71:56": "tools and I'll get into kind of all of",
  "71:57": "these in the next few slides so Aviv",
  "72:00": "Ovadia is a researcher on kind of how if",
  "72:04": "you are making tools for synthetic media",
  "72:07": "how do you do that responsibly and so",
  "72:09": "keep in mind like Photoshop is a tool to",
  "72:13": "make synthetic media Photoshop has a lot",
  "72:16": "of kind of great and legitimate uses it",
  "72:20": "can be used kind of for for arts and",
  "72:22": "kind of all sorts of legitimate things",
  "72:24": "but Photoshop can also be used to make",
  "72:26": "fake photos and this is only kind of",
  "72:28": "increasing as different tools are",
  "72:30": "developed that often have kind of you",
  "72:32": "know positive uses and have kind of",
  "72:35": "scary potential for misuse and so if",
  "72:39": "you've had an article in the MIT tech",
  "72:41": "review recently with where he kind of",
  "72:43": "goes through what are a few different",
  "72:44": "kind of like categories of how we how we",
  "72:46": "think about this so one is limiting who",
  "72:50": "can use a tool so that could be if",
  "72:54": "you're if you are carefully vetting your",
  "72:56": "clients so you give access to and this",
  "72:58": "would be if you were developing",
  "72:59": "something that let people alter their",
  "73:02": "voices or create fake videos or",
  "73:04": "Photoshop and I know there are people at",
  "73:07": "Adobe that are kind of working on this",
  "73:09": "issue of disinformation discouraging",
  "73:12": "Melissa malicious use consent protection",
  "73:16": "so this would be if you have something",
  "73:17": "that can kind of generate it like make",
  "73:20": "it sound like someone's voice is saying",
  "73:21": "something they didn't say have that",
  "73:24": "person have to like say a few kind of",
  "73:27": "generated keys at the beginning to show",
  "73:30": "that they're consenting to using the",
  "73:31": "tool and having having their voice",
  "73:33": "altered making it easier to detect when",
  "73:39": "when something has been changed or",
  "73:41": "altered one former that would kind of be",
  "73:43": "like water marking it or just making it",
  "73:46": "clear with the you know with an image",
  "73:47": "you might not be able to see but the",
  "73:49": "original image is but just to know like",
  "73:50": "hey this image",
  "73:51": "has been altered usage logs use",
  "73:55": "restrictions and supporting ethical",
  "73:58": "synthetic media tools and so he and he",
  "74:01": "goes into more detail kind of in in this",
  "74:04": "article so this is and this is not gonna",
  "74:06": "solve the problem this is kind of ways",
  "74:08": "to just try to mitigate it so this is an",
  "74:15": "idea about our ecosystem this was an",
  "74:18": "op-ed in the New York Times that I I",
  "74:21": "liked and so here Siva",
  "74:25": "by heinessen who he's written a book on",
  "74:28": "I think on social networks proposes that",
  "74:34": "we need to be limiting data collection",
  "74:36": "and the use of personal data to ferry",
  "74:38": "ads and other content to discrete",
  "74:40": "segments of Facebook users and so kind",
  "74:43": "of one proposal he gives and so this is",
  "74:46": "something where it really gets into kind",
  "74:47": "of the particular laws of a country but",
  "74:50": "in the US and a minimum we could",
  "74:51": "restrict targeting of political ads to",
  "74:55": "the level of the of the district of the",
  "74:58": "race so one problem with personalized ad",
  "75:02": "targeting combined with kind of combined",
  "75:06": "together with disinformation is that",
  "75:08": "disinformation can be shown to just a",
  "75:10": "very kind of narrow segment of the",
  "75:12": "population and so you know you might not",
  "75:16": "have any journalists see it and realize",
  "75:18": "like hey this is being shown to this",
  "75:20": "kind of very narrow demographic and this",
  "75:23": "is I guess this is true both of targeted",
  "75:25": "ads and also just the way that all our",
  "75:27": "kind of timelines and news feeds are so",
  "75:29": "personalized to us we don't know what",
  "75:32": "other people are seeing and so we may",
  "75:33": "not hear about a common conspiracy",
  "75:35": "theorem that others are hearing about so",
  "75:39": "this is kind of one proposal kind of",
  "75:40": "thinking about that targeting there even",
  "75:43": "if people are spreading disinformation",
  "75:44": "if you have to send it to a larger group",
  "75:46": "at least there are more people to like",
  "75:48": "identify it and hopefully debunk it",
  "75:52": "this is a report that came out of John",
  "75:55": "Johns Hopkins and UNC and one of the",
  "75:59": "authors said kind of in studying how to",
  "76:03": "regulate digital ads that they found",
  "76:05": "kind of surprising amount of bipartisan",
  "76:07": "support and some of the ideas were",
  "76:09": "having databases of content and this is",
  "76:12": "something you know we're finding now",
  "76:13": "like we don't even necessarily know all",
  "76:16": "the ads that were shown in the 2016",
  "76:18": "election but just to even like have that",
  "76:20": "content be discoverable of kind of who",
  "76:23": "who is showing you know what ads and",
  "76:27": "describes how many of these are kind of",
  "76:29": "similar to how TV ads are governed and",
  "76:31": "so kind of remembering that we do have",
  "76:33": "other mediums like TV that have even if",
  "76:36": "they have shortcomings at least have",
  "76:38": "kind of more governance of advertising",
  "76:43": "and there's a great article by Rene",
  "76:46": "direst done Mike Godwin that I mentioned",
  "76:48": "earlier",
  "76:49": "the seven step program for fighting",
  "76:50": "disinformation but really thinking about",
  "76:53": "this as a cybersecurity problem and I",
  "76:55": "think there are a lot of parallels with",
  "76:57": "with cybersecurity here Stanford did put",
  "77:02": "out a securing American elections report",
  "77:06": "last year that has a number of proposals",
  "77:09": "in it they are all I would say they are",
  "77:12": "all things that need to happen kind of",
  "77:14": "on a federal government level though and",
  "77:16": "I think they're all kind of good",
  "77:18": "suggestions but of kind of what we need",
  "77:21": "to be doing to countering disinformation",
  "77:23": "and even just to get a good scope of the",
  "77:25": "problem and kind of what sort of",
  "77:27": "interference is happening and I should",
  "77:30": "note it's not just not just an election",
  "77:32": "problem or a political problem but that",
  "77:34": "is kind of one one key Avenue where it",
  "77:36": "shows up",
  "77:41": "and then another other another I don't",
  "77:45": "know another category of of tools or",
  "77:47": "things thinking about giving people ways",
  "77:50": "to verify themselves and so saying it if",
  "77:53": "actually wrote an article for Wired",
  "77:55": "where she used this analogy with Fidel",
  "77:58": "Castro it's like in 2006 he had surgery",
  "78:03": "and are a lot of rumors like is he still",
  "78:05": "alive and so he shared this picture of",
  "78:08": "him holding that day's newspaper to",
  "78:11": "confirm that he was alive and this you",
  "78:13": "know even now like Photoshop is good",
  "78:15": "enough like this wouldn't be convincing",
  "78:17": "but she talks about kind of we need a",
  "78:20": "digital analog for this for for people",
  "78:23": "to to verify themselves if you're",
  "78:26": "familiar with PGP keys that kind of idea",
  "78:28": "of giving people a way to verify like",
  "78:30": "this is from me at this time and she",
  "78:34": "wrote in the past did often made sense",
  "78:36": "to believe something until it was",
  "78:38": "debunked in the future for certain",
  "78:40": "information or claims it will start",
  "78:42": "making sense to assume they're fake",
  "78:43": "unless they are verified and this would",
  "78:46": "require not just kind of whatever",
  "78:47": "verification technology you're using but",
  "78:50": "also a big cultural shift so this would",
  "78:52": "be kind of quite a shift or an FC Ani",
  "78:56": "who's the head of the Allen Institute on",
  "78:59": "AI research made a similar proposal in",
  "79:02": "Harvard Business Review last year so",
  "79:08": "yeah in summary D we have kind of all",
  "79:10": "these different approaches so practicing",
  "79:14": "kind of good social media habits as a as",
  "79:16": "an individual and this kind of digital",
  "79:17": "literacy keeping our perspective I also",
  "79:21": "I'm gonna highlight just strengthening",
  "79:22": "our institutions such as journalism",
  "79:24": "education universities and nonpartisan",
  "79:27": "government departments kind of these",
  "79:29": "these plays such an important role in in",
  "79:32": "society and doing what we can to to try",
  "79:35": "to strengthen them treating",
  "79:37": "disinformation as a cybersecurity",
  "79:39": "problem and developing verification",
  "79:41": "tools and I see a hand back there can",
  "79:45": "you pass the catch",
  "79:52": "so going forward then I I listed some",
  "79:56": "experts to follow and I also and you can",
  "80:01": "so I started a thread about",
  "80:03": "disinformation on the forums but you can",
  "80:05": "definitely share kind of people that you",
  "80:07": "follow on this topic or if you've read",
  "80:08": "articles or have resources that you like",
  "80:11": "on disinformation please please share",
  "80:15": "them with us yeah oh that's it so any",
  "80:17": "any more questions",
  "80:28": "okay there's a question behind you as to",
  "80:34": "comment on cybersecurity okay we have",
  "80:36": "lots of different ways that we think",
  "80:38": "about intrusion of data structure and",
  "80:40": "integrity we don't have that same kind",
  "80:43": "of focus typically on content unless it",
  "80:45": "has some kind of commercial value so I",
  "80:47": "think there's a lot of research that",
  "80:48": "could be immediately applied to just",
  "80:50": "thinking about the corruption of content",
  "80:52": "yeah this information as a way to you",
  "80:54": "abrade the actual content itself but not",
  "80:58": "just the way it's formed or structured",
  "80:59": "let's say in a relational model or some",
  "81:01": "other kind of graph representation yes",
  "81:04": "yeah and actually that reminds me kind",
  "81:05": "of another way that it's just",
  "81:08": "information it's like a cybersecurity",
  "81:10": "problem is thinking about kind of",
  "81:13": "inorganic kind of inauthentic behavior",
  "81:17": "as opposed to I think people have",
  "81:21": "sometimes thought about this information",
  "81:23": "of like oh let me just look at this",
  "81:24": "individual post or something whereas",
  "81:27": "really you need to look like do you have",
  "81:29": "kind of this inorganic activity anomaly",
  "81:33": "detection kind of things that seem and",
  "81:35": "all that authentic even if in isolation",
  "81:38": "any one action or one post may not",
  "81:41": "necessarily be like okay this is",
  "81:43": "definitely fabricated news",
  "81:53": "so you talk a lot about the platform's",
  "81:57": "we're going by rule is thing",
  "82:00": "monetization",
  "82:01": "but what about the more sort of static",
  "82:04": "platforms like Wikipedia which is often",
  "82:06": "like the first go-to in which like",
  "82:08": "especially like the young generations",
  "82:09": "take us like gospel but when you look in",
  "82:12": "the revision history for a lot of the",
  "82:14": "articles you see this separate Mars race",
  "82:16": "and about and forth people like entities",
  "82:18": "leading and yeah just fighting over who",
  "82:21": "gets the posts yeah no that's that's a",
  "82:23": "good comparison because yeah Wikipedia",
  "82:26": "in some ways you know not using kind of",
  "82:27": "ad generated model and not gathering all",
  "82:30": "this user data I would say at least has",
  "82:33": "had fewer problems than many of the",
  "82:36": "major platforms but Wikipedia still has",
  "82:38": "significant in serious problems and",
  "82:40": "there's also I know kind of just you",
  "82:44": "know issues about certain groups kind of",
  "82:48": "getting mass deleted or kind of the back",
  "82:52": "and forth although in the whole I would",
  "82:54": "say most people probably consider",
  "82:56": "Wikipedia to be a healthier information",
  "82:58": "ecosystem then than any of the major",
  "83:01": "tech platforms but you're right you can",
  "83:05": "still definitely get the kind of editing",
  "83:06": "back and forth although in general I",
  "83:09": "think they're things that the the tech",
  "83:10": "platforms could potentially learn from",
  "83:12": "Wikipedia as well okay and can you pass",
  "83:15": "the ketchup ox forward to the second row",
  "83:18": "Oh quick I just wanted to like I was",
  "83:23": "just recently reading a paper about",
  "83:25": "moderation techniques on Wikipedia",
  "83:27": "specifically and I think a lot of the",
  "83:29": "community supported moderation",
  "83:31": "techniques that they have allows for",
  "83:35": "stockades for is specifically what",
  "83:38": "you're referring to",
  "83:41": "yeah and they do like I know like I know",
  "83:43": "what Coupee do like does have ways of",
  "83:45": "freezing posts that are kind of very",
  "83:48": "contentious although I'd also a Casey",
  "83:52": "feeler who I mentioned earlier whose",
  "83:54": "fantastic did have a thread recently",
  "83:57": "about kind of her her experience of",
  "83:58": "creating Wikipedia posts and then having",
  "84:01": "people like getting upset and attacking",
  "84:02": "all her posts and going through her",
  "84:04": "revision history so yeah I know it's a",
  "84:06": "kind of a mixed bag you pass it back two",
  "84:12": "rows on the social media train how do",
  "84:21": "you think about reconciling trying to",
  "84:25": "detect like the companies themselves",
  "84:26": "trying to detect us information and like",
  "84:28": "down rank it or remove it or whatever",
  "84:30": "with the users expectation that their",
  "84:33": "information isn't necessarily all being",
  "84:35": "scrutinized by the company so like I",
  "84:37": "know for example this would be a huge",
  "84:39": "problem for whatsapp because like one of",
  "84:42": "their big assets is that the action but",
  "84:44": "that makes it impossible to really",
  "84:46": "analyze them yeah that's that is a big",
  "84:51": "issue cuz yeah there's definitely",
  "84:52": "serious disinformation happening on",
  "84:55": "whatsapp so you may have seen there's",
  "84:59": "kind of a study of memes being shared",
  "85:01": "and the run-up to the Brazilian election",
  "85:04": "in which a lot of kind of misinformation",
  "85:07": "and misleading things were shared and",
  "85:09": "played at least somewhat of a role and",
  "85:11": "the far-right leader being elected um",
  "85:14": "there's also been this issue in India of",
  "85:15": "people spreading rumors on whatsapp and",
  "85:18": "several people have been murdered as a",
  "85:19": "result yeah it's hard I don't have an",
  "85:25": "answer in a in our last minute of class",
  "85:28": "but yeah if I think I'm or else I'll say",
  "85:34": "more but there is there is I guess in",
  "85:38": "general I will say so yeah thinking",
  "85:40": "about the importance of privacy I guess",
  "85:42": "whatsapp has made some changes though in",
  "85:44": "just of how how many groups you can",
  "85:48": "share something to or I believe like",
  "85:50": "group side",
  "85:51": "so there are still kind of structural",
  "85:53": "changes you can make while protecting",
  "85:54": "protecting privacy of just like how how",
  "85:58": "you let people share things and then I'm",
  "86:02": "sorry we're at 8 o'clock so I'm gonna",
  "86:04": "stop but feel free to either ask next",
  "86:07": "time or to post on the forums"
}