{
  "00:01": "yeah kind of a topic for tonight privacy",
  "00:05": "and surveillance it's in the news a lot",
  "00:08": "thinks yeah thanks for kind of",
  "00:10": "discussing this and you've already",
  "00:11": "brought up several points that will come",
  "00:13": "up again kind of throughout throughout",
  "00:16": "this evening my goal is to talk a little",
  "00:18": "bit just about kind of some facts about",
  "00:20": "the current state of things how things",
  "00:22": "are surveillance technologies are being",
  "00:24": "used some of the risk of what can go",
  "00:27": "wrong",
  "00:28": "my rebuttals to a few common really",
  "00:32": "these are kind of like rebuttals to",
  "00:34": "rebuttals that I hear and then some",
  "00:36": "steps towards solutions so one of the",
  "00:40": "readings was the New York Times article",
  "00:42": "your app knows where you were last night",
  "00:45": "and they're not keeping it a secret and",
  "00:47": "this was from a collection of data that",
  "00:49": "I think came from over 200 million",
  "00:50": "phones in the United States I thought it",
  "00:53": "was kind of helpful how they visually",
  "00:55": "broke it out kind of showing the stories",
  "00:57": "of individual people so here's a woman",
  "00:59": "that the New York Times identified and",
  "01:02": "kind of tracked her going to and from",
  "01:04": "her job visiting her ex-boyfriend going",
  "01:07": "hiking at one point she goes to a",
  "01:09": "doctor's office they keep track of like",
  "01:11": "how long she's there I'm kind of he's",
  "01:13": "very you know potentially intimate",
  "01:14": "details another yeah her going from her",
  "01:19": "home to Weight Watchers and kind of",
  "01:21": "looking at this over time and it was",
  "01:22": "something where they had or it says here",
  "01:24": "her location was recorded over 8,600",
  "01:27": "times in four months so a lot of very",
  "01:31": "granular data and the New York Times has",
  "01:36": "kind of done a series of articles",
  "01:37": "unrelated and I think even like a few",
  "01:40": "separate data sets but all kind of in",
  "01:42": "the same idea of kind of just how much",
  "01:45": "data is being collected from people are",
  "01:48": "there any thoughts on this article or",
  "01:49": "reading it I just for this talk today",
  "01:54": "actually about political campaigns using",
  "01:56": "this data from all these sort of",
  "01:58": "nefarious companies and merging it with",
  "02:00": "the voter records in this way that was",
  "02:01": "like pretty shocking to me yeah and also",
  "02:04": "I think that the thing this we're",
  "02:06": "talking about is that these these",
  "02:09": "campaign cycles are so short they",
  "02:11": "actually can't be a lot of safeguards",
  "02:13": "and how that data persist long term it's",
  "02:15": "there's no central responsibility for",
  "02:18": "this stuff so each of the campaign is",
  "02:19": "doing some version of in this way that",
  "02:22": "was pretty yeah and that reason is kind",
  "02:26": "of another issue also of how data",
  "02:27": "sources can be combined and so sometimes",
  "02:29": "when you're just looking at a single",
  "02:30": "data source while this you know seems",
  "02:32": "revealing enough it could be even",
  "02:34": "significantly more revealing when",
  "02:35": "combined with other data sets there's a",
  "02:38": "lots going back there Aaron raised the",
  "02:40": "point about also how data can be more",
  "02:43": "revealing in aggregate as well so there",
  "02:45": "was a case with Strava a few years ago",
  "02:47": "you'll remember when they use release",
  "02:49": "this data set publicly that ended up",
  "02:51": "revealing not just kind of the location",
  "02:55": "of several foreign military bases but",
  "02:56": "even kind of a guess at the inside",
  "02:58": "architecture and that was something that",
  "03:01": "you know releasing the data for any one",
  "03:03": "person wouldn't have revealed that but",
  "03:05": "altogether it did another kind of image",
  "03:09": "from the New York Times article of",
  "03:11": "here's someone coming to a Planned",
  "03:12": "Parenthood they know what entrance",
  "03:14": "they're using what time what time they",
  "03:16": "leave how long they're there this is",
  "03:17": "kind of very intimate data being sold",
  "03:21": "and distributed there's another article",
  "03:26": "on finder and OkCupid so and OkCupid",
  "03:31": "asks you know questions about drug use",
  "03:33": "and sexual preferences again kind of",
  "03:35": "very personal and intimate data and so",
  "03:40": "and it's hard cuz they're also these",
  "03:42": "like layers of intermediaries that the",
  "03:44": "state often gets passed through so",
  "03:47": "grinders app includes software from mo",
  "03:49": "pub which is Twitter's ad service Mopa",
  "03:52": "mo pub shares with more than 180 partner",
  "03:55": "companies one of those partner companies",
  "03:58": "is AT&T which shares more with more than",
  "04:00": "a thousand third-party providers and so",
  "04:03": "it can be even hard to kind of I think",
  "04:06": "think about the scope of this of kind of",
  "04:07": "how many intermediaries this data gets",
  "04:09": "passed through and it's not something",
  "04:10": "that's kind of really regulated or",
  "04:14": "tracked in a systematic way to even",
  "04:16": "understand the scope but again this is",
  "04:19": "kind of very very personal data being",
  "04:21": "sold and something the New York Times",
  "04:24": "article talks about is even you know",
  "04:25": "even when data is aggregated it can be",
  "04:27": "everyone's",
  "04:29": "many people talked about it can you can",
  "04:31": "do non amaze data and kind of",
  "04:33": "disaggregate individuals so yes Wow oh",
  "05:24": "can i I missed that that is yeah",
  "05:27": "that is significant yes yeah and that's",
  "05:30": "another issue of kind of how I went past",
  "05:36": "them",
  "06:03": "like really wow thank you for those",
  "06:12": "additional details this is yet a very",
  "06:17": "very significant stuff then another",
  "06:21": "topic so that's kind of some of the",
  "06:23": "phone data from apps on our phones is",
  "06:27": "kind of police use of facial recognition",
  "06:29": "this is an article about New York Police",
  "06:33": "Department which has been putting",
  "06:35": "children as young as 11 into a facial",
  "06:37": "recognition database and it's important",
  "06:40": "to remember that the technology wasn't",
  "06:44": "even developed on children typically so",
  "06:46": "you've got higher error rates even if",
  "06:50": "you were okay with this sort of use but",
  "06:52": "also this is kind of then taking someone",
  "06:55": "at a very young age and kind of adding",
  "06:57": "them to the this database the Georgetown",
  "07:00": "Center for Georgetown Law Center for",
  "07:03": "privacy and Technology does a lot of",
  "07:05": "great work they did a study garbage in",
  "07:08": "garbage out looking at how kind of",
  "07:10": "facial recognition was used by police",
  "07:12": "and practice and they found and a lot of",
  "07:16": "kind of horrifying examples one is of",
  "07:19": "police had a suspect in return no",
  "07:22": "matches and they said well this guy kind",
  "07:25": "of looks like Woody Harrelson so the",
  "07:27": "actor stay googled his picture and then",
  "07:29": "entered that into the kind of mugshot",
  "07:32": "database and then used that to surface",
  "07:34": "suspects",
  "07:35": "so that was covered but it was like a",
  "07:37": "series of police kind of photoshopping",
  "07:40": "faces like there was one where like the",
  "07:42": "eyes were closed so they photoshopped",
  "07:43": "open eyes onto the face also using kind",
  "07:48": "of you know sketches of the based on a",
  "07:52": "description of the of the suspect and",
  "07:56": "trying to use facial recognition",
  "07:57": "technology on those and in many cases",
  "08:00": "you know this is kind of surfacing a",
  "08:02": "list of like the closest matches but",
  "08:04": "that doesn't necessarily mean they're",
  "08:06": "good matches at all",
  "08:07": "so it's very kind of even more",
  "08:10": "concerning to hear how this is being",
  "08:11": "used in practice",
  "08:13": "and then kind of another example",
  "08:17": "this was early on in the Hong Kong",
  "08:19": "protest last summer a lot of people were",
  "08:22": "circulating kind of pictures of so",
  "08:26": "typically people in Hong Kong are using",
  "08:28": "kind of a cashless system with cards",
  "08:31": "that automatically scan they didn't want",
  "08:33": "to be tracked that they were attending",
  "08:35": "the protest and so kind of having having",
  "08:37": "these long lives of people paying for",
  "08:38": "paper tickets but this is I think a",
  "08:41": "common point where some of these",
  "08:44": "technologies can be very convenient when",
  "08:47": "things are going well but it's also kind",
  "08:49": "of important to think about other",
  "08:51": "scenarios the next I wanted to talk",
  "08:54": "about the the talk by Alvaro Bedoya an",
  "08:58": "avid oil is director of the Georgetown",
  "09:00": "Center for Law and Georgetown Law Center",
  "09:03": "for privacy and technology I thought",
  "09:06": "this was a kind of interesting some",
  "09:08": "history on kind of the use of",
  "09:10": "surveillance so he goes back to Queen",
  "09:13": "Elizabeth the first building a network",
  "09:15": "of spies and informants to root out",
  "09:17": "perceived threats and particularly",
  "09:19": "targeting Catholics and Puritans as a",
  "09:22": "kind of religious minorities in the",
  "09:26": "1880s in the u.s. 2,300 Mormons were",
  "09:30": "prosecuted for polygamy and this was",
  "09:33": "facilitated kind of through surveillance",
  "09:35": "and I thought it was interesting the",
  "09:36": "note that kind of anti Mormons were",
  "09:39": "saying that Mormons were not white and",
  "09:41": "were actually Muslims as a way of kind",
  "09:43": "of justifying the surveillance and",
  "09:46": "prosecution",
  "09:50": "the FBI amassed a 1500 page file on",
  "09:54": "Cesar Chavez who led a lot of the farm",
  "09:57": "worker protests that kind of resulted in",
  "09:59": "kind of more more rights and protections",
  "10:02": "and professor Bedoya writes that Cesar",
  "10:07": "Chavez was a saint and they actually",
  "10:09": "didn't take anything up on him but that",
  "10:11": "very very few of us would be able to",
  "10:13": "have a FBI file of 1,500 pages about our",
  "10:17": "kind of every doing and what all our",
  "10:19": "kind of friends and neighbors and people",
  "10:21": "we interact with do and not have",
  "10:23": "something very embarrassing or",
  "10:29": "even you know like illegal show up in it",
  "10:32": "and that that's kind of a very",
  "10:34": "unreasonable bar to gather this much",
  "10:36": "information on somebody and yeah FBI",
  "10:40": "also tracked Martin Luther King jr.",
  "10:43": "compiled recordings of his affairs and",
  "10:46": "they threatened to blackmail him and",
  "10:48": "encouraged him to kill himself with this",
  "10:51": "so there's kind of a and there were even",
  "10:55": "more examples in in the essay but kind",
  "10:57": "of a long history of surveillance being",
  "10:59": "used in particular to target certain",
  "11:05": "people and as as Professor Bedoya wrote",
  "11:09": "the pattern is we watch those who are",
  "11:11": "quote considered less than will you spy",
  "11:14": "on your superior or will you spy on the",
  "11:16": "poor man the person of color the",
  "11:18": "immigrant the heretic we watch those who",
  "11:21": "are other and he identifies this pattern",
  "11:25": "when those others organize mobilize that",
  "11:27": "watching is redoubled surveillance",
  "11:29": "becomes a tool to stop marginalized",
  "11:31": "people from achieving power the key",
  "11:43": "reaction I had this was the notion of a",
  "11:45": "especially the second pattern of",
  "11:47": "thinking about or really both Connors",
  "11:49": "was how immediate the standard is clear",
  "11:52": "when you apply at the other direction if",
  "11:54": "you even think of like fiction and",
  "11:56": "anybody who is casing a bank or stalking",
  "11:58": "a president the threat is immediate and",
  "12:01": "obvious but once you turn it the other",
  "12:03": "way it's more intrigue and I think we",
  "12:06": "have that natural narrative reaction",
  "12:07": "that reinforces the observation here is",
  "12:10": "we know and we see it but we don't",
  "12:12": "recognize it as such but we don't feel",
  "12:15": "threatened by by the action that we",
  "12:17": "observe yeah your perspective matters a",
  "12:21": "lot in this yeah kind of what you see as",
  "12:22": "a threat",
  "12:32": "I read an article where ice was using",
  "12:35": "location-based data to identify",
  "12:37": "immigrants yeah well yeah that'll come",
  "12:44": "up later",
  "12:45": "but yeah that's a great great point and",
  "12:49": "Colin no this book about the Great",
  "12:52": "Firewall of China because I don't",
  "12:54": "remember the exact I think that was the",
  "12:55": "name I don't remember the subtitle the",
  "12:57": "author but they're gonna bring up cuz",
  "12:59": "censorship and surveillance are really",
  "13:01": "kind of two sides of the same coin a lot",
  "13:02": "of the time because we're looking to see",
  "13:05": "what speech is there so you know what's",
  "13:07": "a censor and they're kind of made a",
  "13:08": "point that the number one thing that",
  "13:09": "kind of sensor for is actually just like",
  "13:11": "solidarity or people kind of working",
  "13:13": "together and there was this really",
  "13:15": "interesting example where there was this",
  "13:16": "comedy website and they were very",
  "13:18": "careful we're not kind of like offensive",
  "13:20": "or seditious jokes but people from the",
  "13:22": "website were meeting each other in real",
  "13:24": "life and then that started getting",
  "13:26": "censored because they just had no signal",
  "13:27": "they get kinda like put their hands up",
  "13:29": "to each other and such were like oh",
  "13:30": "you're from this site and we can talk",
  "13:32": "and so a lot of times I think that it's",
  "13:36": "not just about their surveillance but",
  "13:38": "it's also there's kind of censorship and",
  "13:39": "pressure to move you from under",
  "13:41": "surveillance",
  "13:42": "channels of communication to only be",
  "13:44": "able to use surveilled channels of",
  "13:46": "communication so that's kind of just",
  "13:48": "like the other side of this pattern to",
  "13:50": "watch for pushing the pole yeah that's",
  "13:52": "great thank you I'm gonna move on but",
  "13:56": "I'll take more questions later and then",
  "13:57": "another quote from this I contend that",
  "14:02": "we are a nation of dissenters and this",
  "14:04": "was the first Hispanic senator in the",
  "14:06": "u.s. denouncing McCarthyism in 1950 and",
  "14:09": "this was a piece of history I did not",
  "14:10": "know about before reading this but",
  "14:13": "apparently after Dennis Chavez spoke up",
  "14:15": "about this that other people then",
  "14:16": "started feeling like they could speak up",
  "14:18": "as well and he said our nation was",
  "14:21": "created by dissenters our ancestors were",
  "14:23": "not satisfied kind of emphasizing kind",
  "14:27": "of the value and importance of dissent",
  "14:31": "and then an example and more recently is",
  "14:36": "in 2015 in Baltimore during the protest",
  "14:40": "over Freddie Gray's death black man",
  "14:42": "killed wrongly in police custody police",
  "14:45": "used",
  "14:46": "facial recognition to identify",
  "14:48": "protesters and this was they said to",
  "14:51": "identify protesters who had existing",
  "14:53": "warrants however you can have warrants",
  "14:55": "for relatively minor things and this",
  "14:58": "kind of came to light through some of",
  "15:01": "the company that built this technology",
  "15:04": "geofeedia used this as a positive case",
  "15:07": "study and so maybe they quote quote",
  "15:15": "someone saying every person we got off",
  "15:16": "the streets before they hurt someone was",
  "15:18": "a win which I just thought was such a",
  "15:20": "weird quote because it's before before",
  "15:23": "they hurt someone they didn't hurt",
  "15:24": "someone you know what did what did they",
  "15:25": "do but I think this is kind of very very",
  "15:29": "concerning to surveil protesters the no",
  "15:33": "need to include kind of a few a few",
  "15:36": "things to know about how the government",
  "15:38": "uses technology in practice in many",
  "15:41": "cases and it's often opaque and then",
  "15:45": "this is a kind of very us specific in",
  "15:47": "the u.s. they're restrictive NDA's it's",
  "15:50": "typically not evidence-based and then",
  "15:53": "there's often a lot of dysfunction kind",
  "15:56": "of through the whole pipeline of how how",
  "15:59": "contractors bid on proposals who gets",
  "16:02": "elected the asymmetry in terms of the",
  "16:06": "technical knowledge that the companies",
  "16:08": "have versus the people working in",
  "16:10": "government trying to evaluate these",
  "16:11": "proposals and I'll say a little bit",
  "16:14": "about that but it is not a kind of",
  "16:18": "efficient or well-designed process in",
  "16:20": "many ways so government use of tech is",
  "16:24": "often opaque an article this was a year",
  "16:28": "or two ago came out that Palantir had a",
  "16:31": "project in New Orleans to test",
  "16:33": "predictive policing it had been going on",
  "16:36": "for seven years and City Council members",
  "16:38": "didn't know about it when they were",
  "16:40": "asked for comment they were like we",
  "16:41": "didn't even know that we had this",
  "16:42": "program and it ended up was cancelled",
  "16:47": "kind of a few weeks after the verge",
  "16:49": "broke the story about it New York City",
  "16:54": "started an algorithm ated decision",
  "16:57": "system task force",
  "16:59": "evaluate how the city was using",
  "17:01": "automated decisions automated decision",
  "17:03": "systems which I was super excited when",
  "17:06": "they announced that they were doing this",
  "17:08": "they got a lot of fantastic people on",
  "17:10": "the committee and then they did not give",
  "17:12": "them any information about what",
  "17:14": "automated decision systems New York uses",
  "17:16": "because I claimed it was proprietary and",
  "17:18": "that they couldn't couldn't tell them so",
  "17:21": "Meredith Whittaker one of the founders",
  "17:23": "of the IEEE now Institute was on the",
  "17:25": "committee and at the end she said it was",
  "17:27": "a waste and kind of sets a terrible",
  "17:29": "precedent the a large portion of the",
  "17:32": "committee did release a kind of shadow",
  "17:34": "report dissenting with the the official",
  "17:37": "report but so here you know he's even",
  "17:40": "the system where you had something that",
  "17:41": "was voted on we should do this and then",
  "17:44": "not giving the people involved",
  "17:46": "information they needed to even evaluate",
  "17:52": "there's also this idea of or something",
  "17:55": "called parallel construction and that's",
  "17:57": "when police will use a technology to",
  "18:00": "kind of gain some knowledge not one a",
  "18:03": "reveal that they use that technology and",
  "18:05": "have to come up with kind of an",
  "18:06": "alternative case and so an example is",
  "18:10": "stingrays or cell site simulators which",
  "18:13": "can kind of identify people's cell",
  "18:14": "phones and the company that produces",
  "18:17": "these has incredibly restrictive NDA's",
  "18:19": "that actually encouraged police that it",
  "18:22": "was better to drop a case than to reveal",
  "18:26": "that they were using this technology and",
  "18:29": "Elizabeth Jo whose fantastic she's a law",
  "18:33": "scholar at UC Davis she spoke about this",
  "18:36": "at the tech policy workshop here at USF",
  "18:38": "at Cade and she highlighted that kind of",
  "18:42": "the law develops through cases like",
  "18:44": "that's kind of how you know the edges of",
  "18:47": "what things mean get refined and when",
  "18:49": "even the existence of a technology is",
  "18:51": "hidden there's no way for the law even",
  "18:54": "to kind of like adjudicator for us to",
  "18:56": "kind of develop what should our approach",
  "18:58": "on this technology be and so that's kind",
  "19:01": "of a pretty extreme case but it it often",
  "19:04": "operates that way so another point about",
  "19:08": "government and use of technology is that",
  "19:10": "it is often not evidence-based",
  "19:12": "which can be really startling given the",
  "19:15": "amount of money that's often involved so",
  "19:19": "face recognition is being used in many",
  "19:22": "schools that many people have been",
  "19:24": "warning for a while that it won't stop",
  "19:25": "mass shootings one key reason is that",
  "19:29": "many shootings are committed by current",
  "19:32": "students they are not people that would",
  "19:33": "be on a watch list many of them don't",
  "19:35": "have any sort of history so even just",
  "19:37": "like I would the premise is kind of off",
  "19:38": "of even if you can recognize people you",
  "19:41": "don't know who who the shooters are and",
  "19:44": "there was an article more recently that",
  "19:45": "even some of the companies producing",
  "19:47": "this technology are starting to",
  "19:49": "acknowledge that it won't stop shootings",
  "19:51": "but are kind of pivoting to other",
  "19:54": "reasons they still still want to sell",
  "20:14": "and particularly this model that the",
  "20:27": "problem with that could be used for like",
  "20:33": "it'll supply some records to come and so",
  "20:38": "I think the follow-up question that I",
  "20:40": "hadn't been reading that paper and tying",
  "20:42": "into this is like how do you identify",
  "20:43": "somebody that has a severe track record",
  "20:46": "of mental health or psychological",
  "20:48": "problems and you can use facial and I do",
  "20:55": "want to highlight that mass shooters are",
  "21:00": "not correlated with mental health issues",
  "21:01": "they are correlated with domestic",
  "21:04": "violence though and kind of being",
  "21:06": "domestic abusers I think it's it's also",
  "21:09": "kind of on this question of identifying",
  "21:11": "mental health issues it's very important",
  "21:15": "though to recognize like what are the",
  "21:18": "resources we can offer people I think in",
  "21:20": "many cases people with mental health",
  "21:23": "issues who are not getting treatment and",
  "21:24": "maybe because they can afford",
  "21:26": "because they're not enough available",
  "21:27": "affordable therapist and it's kind of",
  "21:30": "often I think more structural and",
  "21:34": "systemic issues as opposed to I don't",
  "21:36": "think that identification is like the",
  "21:39": "kind of the primary pain point there",
  "21:45": "that needs to needs to be solved but",
  "21:47": "that is it yeah good good question yeah",
  "21:49": "that work does raise yeah a lot of kind",
  "21:51": "of ethical issues to discuss actually",
  "21:55": "let's do John over on that side and then",
  "21:58": "Aaron and then I will continue winning",
  "22:20": "everything detective",
  "22:42": "yeah are you getting at how a lot of",
  "22:45": "this technology is produced by private",
  "22:47": "companies and marketed or sold to",
  "22:50": "government agencies or to the military",
  "22:53": "yeah and I think it results in kind of a",
  "22:58": "very opaque system and often a lack of",
  "23:01": "accountability and I think I think many",
  "23:03": "people feel more comfortable with you",
  "23:07": "know I've seen people that are you know",
  "23:09": "very concerned about surveillance in",
  "23:10": "China because they see it as you know",
  "23:12": "they're it's the government that's kind",
  "23:15": "of developing and deploying the",
  "23:16": "technologies whereas in the u.s. it's",
  "23:18": "private corporations but which are who",
  "23:22": "kind of have all sorts of financial",
  "23:24": "partnerships and deals with the",
  "23:27": "government and so that does give it a",
  "23:28": "kind of different different character in",
  "23:33": "some ways but but still raises a lot of",
  "23:35": "issues and even raises I think kind of",
  "23:37": "different issues often around the lack",
  "23:39": "of transparency and lack of",
  "23:40": "accountability and then one one more",
  "23:43": "example I wanted to give was San Diego",
  "23:45": "was using our law enforcement San Diego",
  "23:49": "compiled over 65,000 face scans during a",
  "23:53": "seven year long project that was just",
  "23:56": "finally ended a facial recognition it's",
  "23:59": "almost completely unclear how effective",
  "24:01": "the initiative was with one spokesperson",
  "24:03": "saying they're unaware of a single",
  "24:05": "arrest or prosecution that stemmed from",
  "24:07": "the program and so that's just kind of a",
  "24:10": "remarkable amount of data to collect",
  "24:12": "with without even having kind of any",
  "24:17": "evidence that it was accomplishing its",
  "24:20": "its purported goals now their case study",
  "24:25": "comes from Amazon's ring doorbell",
  "24:28": "his background Amazon the ring has",
  "24:31": "partnerships with over 800 police",
  "24:33": "departments in many cities this is",
  "24:35": "subsidized with taxpayer money Amazon",
  "24:39": "can stream 9-1-1 calls in real time and",
  "24:42": "amazon requires police departments to",
  "24:44": "read pre-approved scripts when they talk",
  "24:46": "about the program so I think this is",
  "24:49": "kind of a remarkable amount of control",
  "24:50": "for a private corporation to be having",
  "24:53": "on something that is",
  "24:55": "you know ostensibly kind of like a",
  "24:57": "public service",
  "25:00": "however NBC News did an investigation",
  "25:02": "which came out just last week they",
  "25:06": "talked to officials at over 40 different",
  "25:09": "police departments in the u.s. which all",
  "25:12": "of which have been using ring for at",
  "25:13": "least six months and found kind of no",
  "25:16": "evidence that ring was effective at",
  "25:19": "fighting crimes and this was a mix of",
  "25:21": "many many cities said that they don't",
  "25:25": "actually track anything related to",
  "25:27": "telling if it was effective there are a",
  "25:29": "lot of examples of people saying well",
  "25:31": "like we've probably caught someone but I",
  "25:33": "can't think of anything and one",
  "25:36": "interesting quote was from I think from",
  "25:41": "an official in Houston saying that",
  "25:45": "evidence isn't there limiting factor",
  "25:47": "he said we already have kind of more",
  "25:49": "evidence than we're able to investigate",
  "25:51": "or act on and so kind of gathering more",
  "25:54": "potential evidence doesn't doesn't",
  "25:57": "necessarily help us in any way and I",
  "26:00": "mean they also many police complain",
  "26:03": "they're just getting sent like videos of",
  "26:05": "raccoons and pupils yarr it's kind of",
  "26:08": "irrelevant but this is I think for kind",
  "26:12": "of such a massive program the fact that",
  "26:16": "there's really kind of no evidence",
  "26:17": "around it and Amazon does cite",
  "26:20": "statistics that they came up with",
  "26:25": "themselves on how they reduce crime but",
  "26:28": "they would not share any details or data",
  "26:30": "on how they calculated that I don't know",
  "26:57": "I mean I think many of the decisions I'm",
  "26:59": "sure there's some of that but I think in",
  "27:01": "many cases the decisions are not",
  "27:03": "necessarily evidence-based or even",
  "27:06": "particularly rational",
  "27:08": "I think technology can seem promising to",
  "27:11": "people bring you something where I and",
  "27:14": "this issue in general is something where",
  "27:16": "I feel like I know a lot of people that",
  "27:17": "I really disagree with you know I've",
  "27:18": "been there are people I know and agree",
  "27:20": "with on other issues and we talked about",
  "27:22": "ring and they're like that sounds great",
  "27:23": "I want one so I think some of it's also",
  "27:27": "kind of the appeal I mean in general I",
  "27:30": "do think people largely operate on",
  "27:33": "stories you know we kind of all find",
  "27:36": "stories very compelling and so you can",
  "27:39": "certainly kind of bring up a few",
  "27:41": "individual stories of you know here's",
  "27:43": "someone that was captured you don't have",
  "27:46": "you know the comparison of would this",
  "27:48": "person been arrested otherwise how did",
  "27:51": "this affect you know overall arrest",
  "27:52": "rates but I do think we kind of operate",
  "27:54": "on stories and kind of what sounds",
  "27:58": "interesting or exciting yeah that's a",
  "28:03": "good question and then actually we're",
  "28:06": "past time for a break so let's take a",
  "28:08": "break now and meet back here in seven",
  "28:10": "minutes all right let's get started",
  "28:15": "again and then one other point that came",
  "28:17": "up after the break started is that the",
  "28:20": "business model for many of these",
  "28:21": "companies is cloud storage and so the",
  "28:24": "companies are often thinking about kind",
  "28:26": "of long term profits and are willing to",
  "28:29": "sell at a discount or give a free year",
  "28:31": "initially which can kind of get",
  "28:33": "departments hooked so I've been complete",
  "28:38": "including just about understanding kind",
  "28:40": "of how government uses technology it's",
  "28:43": "opaque they're often very restrictive",
  "28:46": "NDA's it's typically not evidence-based",
  "28:49": "and then I mentioned kind of some of",
  "28:51": "these issues of often people in",
  "28:54": "government may not have the technical",
  "28:55": "know-how to evaluate the claims that",
  "28:58": "they're hearing from tech companies tech",
  "29:00": "companies are often out of touch with",
  "29:02": "kind of what the the actual needs and",
  "29:05": "processes of how government operates",
  "29:07": "there's also an issue I think most kind",
  "29:09": "of governments still require a waterfall",
  "29:12": "approach to software development because",
  "29:15": "they're really kind of thinking about",
  "29:16": "these you know projects as a whole",
  "29:17": "whereas the tech industry is much more",
  "29:19": "in an agile approach",
  "29:21": "so there's really just a lot of",
  "29:23": "disconnect I've heard people from the",
  "29:25": "u.s. digital service talk to talk about",
  "29:27": "this that yeah there's a lot that could",
  "29:32": "use use improvement significant",
  "29:35": "significant structural improvement and",
  "29:37": "then the you know the process sometimes",
  "29:38": "of bidding on contracts is kind of so",
  "29:43": "complex and specific that like the major",
  "29:45": "tech companies have giant departments",
  "29:47": "that are just focused on the kind of how",
  "29:50": "you bid but not necessarily on some of",
  "29:53": "the more substantive parts of the",
  "29:54": "technology I did want to acknowledge and",
  "30:01": "someone pointed this out about my",
  "30:03": "syllabus several people have pointed",
  "30:05": "this out about my syllabus even kind of",
  "30:07": "prior to the class starting when I was",
  "30:08": "showing it to friends that I I realized",
  "30:11": "my viewpoint is very clear here and that",
  "30:13": "I'm not necessarily representing the",
  "30:16": "other side I did I did ask on Twitter",
  "30:19": "looking for kind of what what were the",
  "30:21": "most thoughtful well recent arguments",
  "30:23": "kind of in favor and I got a lot of",
  "30:26": "discussion on that one and and something",
  "30:28": "that I thought was interesting is",
  "30:30": "someone kind of made the meta point you",
  "30:34": "know the responses to this thread are",
  "30:36": "interesting because for many of the",
  "30:37": "examples I've seen those used as reasons",
  "30:40": "by facial recognition is bad that you",
  "30:42": "kind of had people using the same",
  "30:43": "examples and arguing that this is a",
  "30:45": "reason for it and this is a reason",
  "30:47": "against it so that that was interesting",
  "30:50": "and I will I will try to highlight what",
  "30:52": "I think some of the differences and",
  "30:54": "underlying values are but I think my",
  "30:56": "hope with with talking about kind of the",
  "31:00": "the rest of this this lesson is that",
  "31:02": "even even for kind of proponent",
  "31:05": "proponents of facial recognition I hope",
  "31:07": "that they are hope that you are aware of",
  "31:10": "what the risks are and are kind of",
  "31:12": "weighing those but just the main",
  "31:17": "arguments I've heard for these",
  "31:18": "technologies are public safety the idea",
  "31:21": "of catching criminals and convenience",
  "31:23": "and efficiency so now I want to talk",
  "31:28": "about what are what are the risk why why",
  "31:31": "does this worry me and",
  "31:32": "and many others so I'm gonna kind of",
  "31:37": "talk about some some worst-case",
  "31:38": "scenarios so in western China the",
  "31:42": "weekers which are Muslim minority over 2",
  "31:45": "million or up to 2 million people have",
  "31:47": "been placed in internment camps and this",
  "31:50": "has been facilitated through a lot of",
  "31:52": "biometric data including scans of",
  "31:55": "people's faces audio of their voices",
  "31:57": "blood samples huge huge amounts of data",
  "32:00": "have been gathered this is an article",
  "32:03": "from Wired that that's I think one of",
  "32:07": "the best articles I've read on the issue",
  "32:08": "because they interviewed a number of",
  "32:10": "weaker refugees and Turkey so there are",
  "32:13": "a number so disproportionately it's men",
  "32:17": "being put into the internment camp since",
  "32:18": "there are a number of wives that have",
  "32:20": "escaped but they kind of talked about",
  "32:23": "you know having to being required to go",
  "32:25": "to the police station and like make",
  "32:28": "faces to show different emotions one",
  "32:31": "woman had a deeper voice and they said",
  "32:33": "they didn't believe her initially when",
  "32:34": "they're taking the audio sample samples",
  "32:36": "and kind of cab making her repeat them",
  "32:38": "but they've kind of very invasively",
  "32:40": "gathered quite a lot of data and this is",
  "32:44": "as is terrible there's an article on the",
  "32:50": "engine-room called dangerous data the",
  "32:52": "role of data collection in genocide that",
  "32:55": "covers several several examples and so",
  "32:59": "one is the work of IBM with the Nazis",
  "33:02": "during of kind of world war ii and",
  "33:04": "during the Holocaust",
  "33:06": "so IBM's computers were used to track",
  "33:10": "people kind of whether they were Jewish",
  "33:14": "if they were gypsies how they were",
  "33:18": "executed and this is something to keep",
  "33:22": "in mind is that it was less we're you",
  "33:25": "know now where someone can just buy a",
  "33:27": "computer and then go use it for several",
  "33:29": "years on their own these machines",
  "33:31": "required a lot of maintenance and so",
  "33:33": "people were having to go service them",
  "33:34": "regularly in kind of a much closer",
  "33:36": "relationship to maintain the computers",
  "33:38": "then then you would need kind of with a",
  "33:41": "modern computer Swiss judge ruled it",
  "33:45": "not thus seem unreasonable to deduce",
  "33:47": "that IBM's technical assistance",
  "33:49": "facilitated the task of the Nazis in the",
  "33:51": "commission of their crimes against",
  "33:53": "humanity acts also involving accountancy",
  "33:56": "and classification by IBM machines and",
  "33:58": "utilized in the concentration camps",
  "34:00": "themselves and this is this picture is",
  "34:04": "of Adolf Hitler meeting with Tom Watson",
  "34:07": "senior the IBM CEO of IBM this was in",
  "34:11": "1937 IBM did later break ties with the",
  "34:17": "Nazis but it was most people say kind of",
  "34:20": "far too late and many many companies",
  "34:22": "kind of broke ties far or far sooner",
  "34:24": "than the NIE BM so this is kind of just",
  "34:27": "thinking about kind of the worst case",
  "34:28": "scenarios of what data collection can",
  "34:31": "facilitate a particularly kind of",
  "34:34": "gathering sensitive sensitive data in",
  "34:38": "there and there's an example from France",
  "34:40": "where someone broke the punch card",
  "34:45": "machine so that the column recording if",
  "34:48": "someone was Jewish no longer functioned",
  "34:50": "and fewer people were killed in that",
  "34:52": "region so that's kind of like an example",
  "34:54": "of how or evidence that this and this",
  "34:57": "was playing playing a role IBM also",
  "35:00": "helped I mean this was in early thirties",
  "35:03": "Germany did a much much more detailed",
  "35:05": "census than it had done previously and",
  "35:08": "was able to identify a kind of far more",
  "35:10": "Jewish people than they had previously",
  "35:12": "recognized as living in Germany so those",
  "35:19": "are kind of some worst-case scenarios so",
  "35:23": "concerns about the risk with",
  "35:26": "surveillance are it kind of",
  "35:29": "disproportionately harms harms already",
  "35:32": "marginalized groups data collected for",
  "35:35": "one reason will be used for other",
  "35:36": "reasons later there are errors in data",
  "35:40": "internal threats are often the biggest",
  "35:43": "threats and it stops and sent which is",
  "35:46": "crucial for social progress so kind of",
  "35:50": "already shared this pattern earlier from",
  "35:53": "the Alvaro Bedoya reading about how we",
  "35:56": "watch those who are considered quote",
  "35:58": "then really concerning article was about",
  "36:05": "so India has implemented a much more",
  "36:09": "comprehensive biometric system and a",
  "36:13": "number of HIV patients have stopped",
  "36:16": "their treatment of antiretroviral virals",
  "36:18": "because they are scared that they will",
  "36:21": "be outed as hiv-positive some of them",
  "36:24": "are gay or sex workers and are worried",
  "36:27": "about being outed for those",
  "36:28": "characteristics and so yeah this article",
  "36:33": "kind of had interviews with a number of",
  "36:34": "people that were successfully receiving",
  "36:37": "treatment and then stopped it with the",
  "36:39": "implementation of having to give more",
  "36:41": "biometric data and this I think kind of",
  "36:45": "came up and in the earlier not this",
  "36:47": "example in particular but kind of this",
  "36:49": "issue of how already marginalized groups",
  "36:52": "may stay away from a place when they",
  "36:55": "feel like they're being tracked and then",
  "37:01": "police are illegally giving vehicle",
  "37:03": "location data to ice documents suggest",
  "37:07": "and using kind of massive license plate",
  "37:10": "scanning schemes to share to share data",
  "37:13": "so these are kind of already",
  "37:14": "marginalized groups being further harmed",
  "37:19": "it's an article",
  "37:21": "treating privacy for survival is another",
  "37:23": "tax on the poor that covers this is I",
  "37:27": "was to say then they were talking about",
  "37:29": "in the US but this is a global pattern I",
  "37:32": "think public benefits programs ask",
  "37:34": "applicants extremely detailed and",
  "37:36": "personal questions and sometimes mandate",
  "37:38": "home visits drug tests fingerprinting",
  "37:40": "and collection of biometric and so",
  "37:44": "prisons across the u.s. are quietly",
  "37:47": "building databases of incarcerated",
  "37:49": "people's voice prints in many states for",
  "37:51": "prisoners to be allowed to make phone",
  "37:53": "calls they have to consent to giving",
  "37:56": "their voice data and voice is another",
  "38:00": "form of biometric data which in I use",
  "38:05": "the word consent that is not meaningful",
  "38:06": "consent when someone is in prison and",
  "38:08": "this is their only option to make a",
  "38:10": "phone call",
  "38:12": "and then in refugee camps ice cans are",
  "38:17": "being used iris scans it's often being",
  "38:19": "linked to people's kind of food benefits",
  "38:22": "and so this is something and I chose",
  "38:26": "this from a paper this has been covered",
  "38:27": "by other I found news articles but they",
  "38:30": "often framed it as Oh like isn't this so",
  "38:33": "convenient iris scans are being used to",
  "38:35": "help get these refugees their food but",
  "38:38": "it's important to notice again I don't",
  "38:40": "think there's a meaningful notion of",
  "38:41": "consent for if this is kind of a",
  "38:43": "refugees only option to receive food",
  "38:46": "this is also another situation where",
  "38:48": "it's a private company that has quote",
  "38:51": "volunteered that they are offering the",
  "38:53": "service for free but their kind of",
  "38:56": "payoff is that they're getting to",
  "38:58": "collect all these iris scans and I think",
  "39:03": "these are really disturbing examples and",
  "39:13": "then this I learned about from a Frank",
  "39:15": "Pasquale article I definitely recommend",
  "39:17": "Rach following Frank Pascal he does a",
  "39:20": "lot of a lot of great work he's the",
  "39:22": "author of the black box society but he",
  "39:25": "he highlighted that at least one Indian",
  "39:27": "FinTech app uses social media to predict",
  "39:30": "people's credit rating and it reduces",
  "39:33": "the score of people who are engaged in",
  "39:35": "political activity as kind of being a",
  "39:38": "bigger credit risk so so that's that's",
  "39:41": "very concerning and then here here are",
  "39:46": "some stats that were highlighted by",
  "39:48": "Tawana petit of the Detroit community",
  "39:51": "tech project and so she's she's been",
  "39:54": "organizing in Detroit against the use of",
  "39:56": "facial recognition there which is very",
  "39:58": "pervasive and I'll say a little bit more",
  "40:00": "about that in a moment but she pointed",
  "40:02": "out the demographics of facial",
  "40:04": "recognition bands so the first table is",
  "40:07": "cities that have banned facial",
  "40:09": "recognition and I have just included",
  "40:12": "white and black for kind of simplicity",
  "40:16": "and then in Detroit at the bottom there",
  "40:19": "is no ban despite kind of very extensive",
  "40:21": "organizing Detroit is 79 percent black",
  "40:24": "which is much higher than the",
  "40:25": "other cities and so this is kind of an",
  "40:28": "example showing even how much harder it",
  "40:31": "can be to to regulate the use of these",
  "40:34": "technologies for her well for black",
  "40:38": "people specifically more broadly for",
  "40:41": "groups that are already marginalized so",
  "40:44": "this is a chart about Detroit's it's",
  "40:47": "called project greenlight and so it puts",
  "40:50": "these cameras with green lights outside",
  "40:53": "of businesses and it is check it's",
  "40:57": "already at 256 locations I was expected",
  "41:02": "to expand to over four 480 locations by",
  "41:05": "the end of 2019 this graphic is kind of",
  "41:07": "I think from last summer and I've",
  "41:12": "highlighted an article by Chris Gilyard",
  "41:14": "who talked about the difference between",
  "41:17": "quote luxury surveillance and forced",
  "41:22": "surveillance and so you know an example",
  "41:25": "of luxury surveillance we're talking",
  "41:26": "about Strava",
  "41:27": "before kind of an Apple watch or",
  "41:29": "something that kind of people are using",
  "41:32": "as a luxury item they you know like the",
  "41:35": "data that they're getting versus kind of",
  "41:37": "forced surveillance here a lot of people",
  "41:39": "complain they have these bright green",
  "41:40": "lights and some cases this is you know",
  "41:42": "can be shining you know across your",
  "41:44": "street into your home it's really",
  "41:46": "disruptive and kind of ugly and he kind",
  "41:48": "of talks about some of the contrast",
  "41:50": "between forced surveillance and luxury",
  "41:53": "surveillance as something else about",
  "41:55": "project greenlight is when it was first",
  "41:59": "rolled out they tested it on and they",
  "42:01": "had like the small group of maybe ten",
  "42:03": "businesses initially and what they did",
  "42:06": "is they prioritized police calls from",
  "42:09": "those businesses and so then they said",
  "42:12": "wow like this really reduced crime",
  "42:14": "having the surveillance cameras but",
  "42:16": "actually it was they had prioritized",
  "42:18": "this very small number of businesses so",
  "42:21": "I mean of course that had a kind of",
  "42:23": "positive impact so it was a very",
  "42:24": "misleading misleading statistic that's",
  "42:27": "been used to to justify kind of the",
  "42:29": "further rollout another another reason",
  "42:32": "that massive data collection and",
  "42:36": "surveillance and biometric data",
  "42:38": "collection worried me",
  "42:39": "is that data collected for one purpose",
  "42:41": "will be used for others so it was only",
  "42:44": "confirmed in 2007 that the US Census",
  "42:48": "Bureau gave up the names of",
  "42:49": "japanese-americans in World War two so",
  "42:52": "that they could be placed in internment",
  "42:53": "camps and this is something that at the",
  "42:56": "time that the census was taken in 1940",
  "42:58": "it was illegal for the data to be shared",
  "43:00": "this way and there were guarantees of it",
  "43:03": "will not be shared this way it's illegal",
  "43:04": "and then they changed the law and then",
  "43:08": "also hid that they did it although many",
  "43:09": "people suspected we were like this it",
  "43:12": "must be what happened and so that's",
  "43:15": "something that's difficult to kind of",
  "43:17": "once data is collected you don't",
  "43:19": "necessarily know how the laws are gonna",
  "43:21": "change in the future",
  "43:22": "how it'll be used differently Tim Wu",
  "43:28": "wrote a good article about this opinion",
  "43:32": "piece in The New York Times and he says",
  "43:34": "one hard truth is that data and",
  "43:35": "surveillance networks created for one",
  "43:37": "purpose can and will be used for others",
  "43:39": "you must assume that any personal data",
  "43:42": "that Facebook or Android keeps our data",
  "43:44": "that governments around the world will",
  "43:46": "try to get or that thieves will try to",
  "43:48": "steal so also this idea of even if you",
  "43:52": "did have a lot of trust in the company",
  "43:56": "or group gathering the data that others",
  "43:59": "will try to to get that data and that",
  "44:00": "they will use it for for other purposes",
  "44:03": "I am curious about the sense this",
  "44:08": "question particularly because just from",
  "44:12": "the reading that I've done or like the",
  "44:14": "circles that I wonder in I hear that",
  "44:18": "census data is really important for",
  "44:20": "folks to get the right benefits and",
  "44:22": "funding to be allocated in ways that",
  "44:25": "make sense for especially marginalized",
  "44:27": "yes so I'm wondering how you think about",
  "44:29": "that balance I yeah this is something I",
  "44:32": "don't feel like I have a satisfying",
  "44:35": "answer to there is a tension that yes",
  "44:37": "that data is really important for",
  "44:38": "distributing resources and for people",
  "44:41": "being counted another example so I",
  "44:45": "should also say there are identification",
  "44:48": "cards that were used in the Rwandan",
  "44:50": "genocide and",
  "44:52": "is considered kind of best practice to",
  "44:54": "not record people's ethnic data or",
  "44:56": "something that could be sensitive but in",
  "44:59": "the case of the Rope Inka refugees in",
  "45:01": "Bangladesh they are actually demanding",
  "45:04": "cards that lists at the RO kanga because",
  "45:06": "Myanmar has really tried to erase erase",
  "45:08": "them as a people and so that kind of",
  "45:11": "there's another study on how kind of",
  "45:15": "these a number of countries have",
  "45:16": "biometric kind of identification",
  "45:18": "projects in the works but I was",
  "45:20": "something that came up through kind of",
  "45:21": "their study an interview with a lot of",
  "45:23": "people that and I don't have a clear",
  "45:25": "answer on this that you know in that",
  "45:26": "case you know this is people saying like",
  "45:28": "you know like our ethnicity has kind of",
  "45:31": "been denied and erased like we want to",
  "45:32": "record it and so I don't have a yeah it",
  "45:35": "kind of beyond good answer on this there",
  "45:40": "are other thoughts or does anyone have a",
  "45:42": "way to balance balance that tension all",
  "45:46": "right I do think it's good to at least",
  "45:49": "kind of be aware that it exists and kind",
  "45:51": "of like that these risk exists although",
  "45:54": "you're right there can be kind of like",
  "45:59": "when resources are being allocated based",
  "46:01": "on that data it's yeah it's important",
  "46:26": "what data and also what data but then at",
  "46:34": "what point like with the Japanese",
  "46:36": "internment camps if that census data had",
  "46:39": "been allowed to expire some way possibly",
  "46:42": "you know or not being held on to it",
  "46:45": "might have known I like that idea in",
  "46:49": "general of data expiring because I only",
  "46:51": "see this also as kind of more prosaic",
  "46:53": "uses by tech companies so kind of once",
  "46:54": "they have your data they have it forever",
  "46:58": "thank you yeah this is",
  "47:05": "something that the census blog writes a",
  "47:08": "lot about the US sense yeah and I think",
  "47:11": "it is pretty interesting just I don't",
  "47:16": "know what if they've written anything",
  "47:17": "recently but generally they have caught",
  "47:20": "a lot longer about the problem of",
  "47:25": "collecting individual data and then",
  "47:27": "aggregating it anonymizing it be",
  "47:29": "identifying it then a lot of yes so some",
  "47:35": "of the things that they talk about are",
  "47:36": "pretty interesting and you don't really",
  "47:38": "see that in the anonymization literature",
  "47:41": "that comes out of Dec and some of it is",
  "47:46": "not available or like it makes the data",
  "47:48": "pretty useless it's a mess but but I do",
  "47:51": "think there are lots of interesting",
  "47:52": "aspects of red light for census if",
  "47:54": "you're just using it for allocation you",
  "47:56": "don't really need when people came from",
  "47:58": "so you could mix up the data yeah",
  "48:02": "intentionally so it's another form of",
  "48:05": "deleting or expiring the data by just",
  "48:09": "mixing up certain aspects so that it you",
  "48:12": "can never get thank you yeah no no I",
  "48:19": "would also highlight that I think the",
  "48:20": "census is you know it's a very in some",
  "48:25": "ways kind of unique example in that you",
  "48:29": "know like I think for like your average",
  "48:31": "tech company they probably shouldn't",
  "48:32": "that they should not be collecting as",
  "48:34": "much data as the census and they have",
  "48:36": "very different very different needs and",
  "48:40": "so that in many use cases I think the",
  "48:42": "question is kind of collecting less data",
  "48:43": "is an important one to be asking",
  "48:47": "although I do you think you can make a",
  "48:49": "stronger case for the census on some of",
  "48:50": "the data but thank you for the",
  "48:52": "recommendation to the Census blog well",
  "48:56": "then another example of data collected",
  "48:59": "for one purpose being used for others so",
  "49:04": "there are over ten states that allow",
  "49:06": "undocumented immigrants to obtain",
  "49:08": "driver's licenses and so this is",
  "49:10": "something where states with were you",
  "49:12": "know encouraging and saying you know",
  "49:13": "it's safe to get a driver's license and",
  "49:15": "we would prefer that you have a driver's",
  "49:16": "license than not and",
  "49:18": "ice agents have been accessing those",
  "49:22": "those databases there is also a kind of",
  "49:27": "an article about states that are who are",
  "49:31": "not sharing their records with ice DHS",
  "49:36": "is trying to get other states to get",
  "49:39": "those records for them through data",
  "49:41": "sharing agreements so typically you know",
  "49:45": "many states will kind of share data with",
  "49:47": "each other and so as a way to kind of",
  "49:50": "get around states that are trying to",
  "49:52": "protect their their data from ice and",
  "49:54": "this also kind of gets into kind of how",
  "49:57": "data can be passed around then because",
  "50:00": "these other states were you know we're",
  "50:02": "not gonna say like hey I'm trying to get",
  "50:03": "this data for ice it was just like can",
  "50:05": "we share our driver's license data all",
  "50:11": "right so that's kind of how how data can",
  "50:12": "end up being used for different purposes",
  "50:15": "another area of concern is that data",
  "50:18": "contains errors and so there's a",
  "50:23": "database that primarily LAPD but some",
  "50:27": "other Southern California law",
  "50:28": "enforcement agencies contribute to and",
  "50:31": "an audit found that 42 babies under the",
  "50:34": "age of 1 who are added as gang members",
  "50:37": "and 28 of those were recorded as having",
  "50:41": "admitted to being gang members and then",
  "50:45": "and have even worse this database",
  "50:47": "there's really no process in place to",
  "50:49": "correct errors or to update people's",
  "50:53": "records and so I think the going back to",
  "50:57": "the city of expiration dates could also",
  "50:58": "be significant here it said even for",
  "51:01": "people that have had kind of no contact",
  "51:03": "with police for five years I think I",
  "51:05": "think maybe they're supposed to be",
  "51:07": "purged from the database but instead",
  "51:08": "they were set to not expire for 100",
  "51:11": "years and so it's kind of one share in",
  "51:14": "this database you're in it which is",
  "51:16": "really concerning another article that I",
  "51:19": "just read this weekend said that LAPD",
  "51:24": "are evaluated and we're going to talk",
  "51:26": "more about metrics and lesson 5 and how",
  "51:29": "metrics can encourage gaming",
  "51:32": "it's LAPD are evaluated on 16 metrics",
  "51:35": "daily to measure their productivity and",
  "51:37": "one of those metrics is how many gang",
  "51:39": "members they've interviewed and so you",
  "51:42": "can probably guess what what this is",
  "51:45": "encouraged but many many people over 20",
  "51:49": "officers are under investigation for",
  "51:51": "kind of forging these documents about",
  "51:53": "people saying that people had evidence",
  "51:57": "their gang members or admitted to being",
  "51:59": "gang members when they didn't but so",
  "52:02": "this is a kind of a risk of of this",
  "52:07": "approach a study the FTC did a study of",
  "52:13": "credit reports in 2012 and found that",
  "52:15": "26% had at least one mistake in their",
  "52:18": "files and 5% had errors that could be",
  "52:21": "devastating and so this article how the",
  "52:25": "careless errors of credit reporting",
  "52:27": "agencies are ruining people's lives was",
  "52:30": "written by a reporter who was going to",
  "52:33": "rent an apartment and the Landlord",
  "52:38": "contacted him afterwards and was like",
  "52:40": "you failed the background check for",
  "52:41": "having felony firearms convictions but",
  "52:46": "I'm like surprised because you seemed",
  "52:48": "like this mild-mannered he's a reporter",
  "52:50": "for public radio mostly on Lorde's would",
  "52:52": "not have called and followed up and so",
  "52:56": "he he looked into it and he found the",
  "53:00": "air but the I don't wanna say so the",
  "53:04": "three credit bureaus are TransUnion and",
  "53:06": "Equifax Experian I don't remember which",
  "53:09": "one it was but one of them so he called",
  "53:11": "and was like I've identified this",
  "53:13": "mistake he talked to someone at the",
  "53:14": "Tennessee Courthouse about it and then",
  "53:17": "he said he had to make over a dozen",
  "53:18": "calls and they're just like oh we're",
  "53:20": "investigating your case but they",
  "53:22": "wouldn't update it until he said I'm a",
  "53:24": "reporter and I'm writing about this but",
  "53:26": "that's something that most of us would",
  "53:28": "not be able to do many of people he's",
  "53:31": "also white many people would not have",
  "53:32": "gotten the benefit of the doubt from the",
  "53:33": "landlord and letting them know what had",
  "53:35": "happened with the background check and",
  "53:37": "so this can this can really impact",
  "53:39": "people",
  "53:42": "that kind of related point along those",
  "53:45": "lines is that surveillance often",
  "53:48": "operates without accountability and so",
  "53:50": "even if there's you know this is",
  "53:52": "supposed to be the process in place",
  "53:54": "that's often there's no no",
  "53:56": "accountability about it and this is I",
  "53:58": "think very much relates to power and",
  "53:59": "kind of often it's if it's powerful",
  "54:03": "people surveilling less powerful that",
  "54:05": "helps explain why there's not",
  "54:06": "accountability so Amazon so after",
  "54:12": "research by a Joey ballon weenie came",
  "54:15": "out of you know Amazon having higher",
  "54:18": "error rate actually sorry and Amazon",
  "54:22": "contested that research even though kind",
  "54:24": "of all major researchers were like no",
  "54:26": "this is accurate and reproducible but",
  "54:28": "they also contested the ACLU study which",
  "54:32": "misidentified twenty eight members of",
  "54:34": "Congress with criminal mug shots",
  "54:36": "actually don't remember which of those",
  "54:38": "this article is about but they Amazon",
  "54:41": "part of their defense was like oh you're",
  "54:42": "not using this software properly but",
  "54:45": "then it turns out that they're only",
  "54:46": "known police client wasn't using the",
  "54:48": "software in the way that Amazon said was",
  "54:51": "proper because that's not what the",
  "54:52": "defaults were and they didn't provide",
  "54:53": "any training and so this is kind of an",
  "54:57": "example of how how things get get used",
  "54:59": "in practice and the way that if Amazon",
  "55:02": "was kind of trying to evade",
  "55:03": "accountability and then we kind of",
  "55:07": "talked about some of these these article",
  "55:10": "articles are issues before with you know",
  "55:12": "Palantir using New Orleans using",
  "55:15": "volunteers technology and people not",
  "55:17": "even knowing about it so of course",
  "55:18": "there's kind of no inside our",
  "55:20": "accountability to how is being used then",
  "55:25": "as Dana upped effecti has said that",
  "55:27": "internal threats are often the biggest",
  "55:29": "threats and she said this in context of",
  "55:33": "this article on how to operatives for",
  "55:36": "Saudi Arabia were working at Twitter and",
  "55:40": "looked up very sensitive information",
  "55:42": "about Saudi Arabian dissidents kind of",
  "55:46": "many people have said this probably led",
  "55:48": "to the imprisonment and torture of",
  "55:50": "people because they and this kind of",
  "55:52": "goes back to an earlier comment about",
  "55:54": "you know",
  "55:56": "who has access to data and tech",
  "55:57": "companies of people were kind of really",
  "56:00": "able to look up this data and this",
  "56:07": "occurred in 2015 but a lot more details",
  "56:11": "have just come out with the FBI has a",
  "56:13": "case the case around it but kind of very",
  "56:16": "very sobering to read that one of these",
  "56:21": "people looked up information on kind of",
  "56:24": "like a thousand people within a kind of",
  "56:29": "activists that we're using using Twitter",
  "56:33": "another another issue so this was an",
  "56:36": "Associated Press story about how police",
  "56:39": "officers abused confidential databases",
  "56:42": "they found incidences of database",
  "56:45": "misused by police from all 50 states and",
  "56:47": "36 large police departments over two",
  "56:50": "years there were over 650 cases where an",
  "56:53": "employee or police officer was fired or",
  "56:55": "suspended for database misuse and they",
  "56:58": "say this is a definite underestimate of",
  "57:00": "the problem because this is just people",
  "57:02": "that got caught and face repercussions",
  "57:04": "and to kind of big categories of who who",
  "57:08": "was targeted are kind of X romantic",
  "57:11": "partners who end up being stalked or",
  "57:14": "abused as well as people that have",
  "57:17": "protested or spoken out against police",
  "57:20": "and a gang kind of police have access to",
  "57:24": "all this sensitive data that they're",
  "57:25": "looking up kind of for their own",
  "57:28": "purposes and I think I think this is one",
  "57:34": "of the points where kind of how people",
  "57:36": "weigh the internal risk really can",
  "57:42": "change how people feel about these",
  "57:44": "technologies I think that people that",
  "57:46": "are kind of more focused on you know we",
  "57:49": "need to catch criminals or I'm worried",
  "57:51": "about these external risk may be more",
  "57:55": "positive about surveillance technologies",
  "57:56": "whereas I think kind of putting weight",
  "57:58": "on these internal threats and misuse of",
  "58:01": "data can lead you to be much more",
  "58:04": "cautious and skeptical of these risks or",
  "58:08": "of surveillance technologies",
  "58:11": "any of any thoughts son on these so",
  "58:18": "these are just kind of several",
  "58:19": "attributes that I think it's important",
  "58:21": "to know about surveillance so kind of",
  "58:23": "how it's disproportionately impacting",
  "58:26": "people that are already marginalized the",
  "58:28": "way that data can be used for other",
  "58:30": "purposes later that it often even Haskin",
  "58:33": "contains airs in it that there's often",
  "58:36": "not accountability about how how it's",
  "58:37": "being used and that the threats can be",
  "58:40": "internal and so that you know that's",
  "58:42": "something where even if a company or",
  "58:45": "group has you know very strong",
  "58:47": "protections against like exterior",
  "58:49": "hackers if someone internally is",
  "58:51": "misusing it well that's that's no good",
  "58:56": "so they don't respond to a few things I",
  "59:00": "commonly hear and disagree with and so",
  "59:03": "the first is don't people know what",
  "59:05": "they're getting into and they use these",
  "59:06": "services and I give this a lot even from",
  "59:08": "people will be like yeah this is bad but",
  "59:10": "you know people knew what they were",
  "59:11": "doing and Lindsey Lindsey Barrett wrote",
  "59:15": "a great article our collective privacy",
  "59:17": "problem is not your fault",
  "59:19": "but a few things to keep in mind so we",
  "59:22": "talked last week how it would take the",
  "59:24": "average American forty minutes a day to",
  "59:26": "read every privacy policy they saw we",
  "59:29": "know that people don't have that much",
  "59:30": "time also these privacy policies are",
  "59:33": "typically written at a college reading",
  "59:35": "level whereas the average American is at",
  "59:37": "an eighth grade reading level companies",
  "59:41": "rely on manipulative design tricks to",
  "59:43": "get you to spend more time and more",
  "59:45": "money and share more data so the design",
  "59:47": "is often really pushing you in a certain",
  "59:49": "certain direction Facebook keeps shadow",
  "59:54": "profiles of people who don't use it so",
  "59:56": "even if you don't use facebook and never",
  "59:59": "have they can still have a profile on",
  "60:01": "you many employers require the use of",
  "60:05": "certain technologies and so for many",
  "60:07": "people kind of saying I'm not gonna use",
  "60:09": "Gmail anymore may genuinely not be an",
  "60:11": "option because their employer their",
  "60:13": "employer may use it or require it and",
  "60:16": "then kind of more practically in many",
  "60:18": "cases people would need to be opting out",
  "60:20": "of modern life",
  "60:22": "that could really impact their time",
  "60:24": "their ability to interact with various",
  "60:27": "social circles and groups and so these",
  "60:30": "are and then also there's no granular",
  "60:33": "control this is something about",
  "60:34": "typically terms of service you know it's",
  "60:36": "this all or nothing do you accept it",
  "60:39": "Lauren and he pasta something that",
  "60:53": "always I their devices are listening to",
  "61:01": "them constantly and their advertising is",
  "61:03": "being targeted based on what they're",
  "61:05": "saying out loud to people which based on",
  "61:08": "like my experience in the tech industry",
  "61:09": "I just think that sounds completely",
  "61:11": "implausible the way that things work",
  "61:13": "right now and it my guess is that it's",
  "61:15": "all just confirmation bias but I was",
  "61:17": "wondering if you had any thoughts on",
  "61:19": "that yeah I mean my understanding is",
  "61:22": "that that is confirmation bias or that I",
  "61:24": "mean so much other data is being",
  "61:26": "collected that that's how these",
  "61:27": "predictions are made yeah I guess I",
  "61:32": "meant more on the subjective like the",
  "61:34": "fact that people oh that people think",
  "61:36": "this but they still use their phone yeah",
  "61:48": "and ER oh just oh here past the attach",
  "61:52": "box yeah we trust that story like kind",
  "62:07": "of circulates and everybody's like yeah",
  "62:08": "I believe it I think I mentioned at one",
  "62:11": "point that like when I was doing",
  "62:12": "fieldwork uber drivers they mentioned",
  "62:14": "that like uber had suspended a bunch of",
  "62:16": "people that like met in a physical place",
  "62:17": "to like talk about unionizing back in",
  "62:20": "late 2015 and like I had never met",
  "62:23": "anybody that had actually happened to",
  "62:25": "like who could say that their account",
  "62:26": "was suspended but like it was a thing",
  "62:29": "that we just believed because like of",
  "62:30": "course it will attract where you are off",
  "62:32": "the clock of course like I I just I",
  "62:35": "accept",
  "62:36": "that is hacked so it's like it's sort of",
  "62:39": "the sad state that like when somebody's",
  "62:41": "like oh yeah Facebook's like listen you",
  "62:42": "dollar conversations yeah I believe it",
  "62:46": "but yeah like Rachel's Rachel's relaying",
  "62:50": "that my facebook and said we don't we",
  "62:53": "can't do that",
  "62:54": "I mean technically so many other great",
  "64:23": "thank you that was a great example to",
  "64:26": "yeah and I will say and we'll kind of",
  "64:28": "get to this in the final section which",
  "64:30": "we'll cover next week but that these are",
  "64:36": "really collective problems that need to",
  "64:37": "be addressed collectively and so I think",
  "64:40": "it's understandable that it can feel",
  "64:42": "incredibly discouraging as an individual",
  "64:44": "because it is something that you don't",
  "64:46": "solve with an individual by opting out",
  "64:48": "but that we're going to need kind of",
  "64:49": "collective solution",
  "64:50": "- we'll talk more about that that next",
  "64:53": "week but yeah thank you thank you for",
  "64:56": "that example and uh me briefly started",
  "65:01": "on this kind of other common objection",
  "65:04": "that I hear as well if you've done",
  "65:05": "nothing wrong you should have you should",
  "65:07": "have nothing to hide and I see is",
  "65:10": "rolling and people laughing so I think",
  "65:12": "you you realize this but you know some",
  "65:15": "groups face much higher scrutiny",
  "65:16": "particularly black people o Muslims",
  "65:18": "queer people immigrants and many others",
  "65:22": "this is supported by research black",
  "65:24": "people in California are stopped far",
  "65:26": "often more by police even though they're",
  "65:29": "not found to be breaking the law at",
  "65:30": "higher rates",
  "65:32": "the perpetual lineup another study from",
  "65:35": "Georgetown Law Center for privacy and",
  "65:38": "Technology found that the photos of",
  "65:41": "black people are disproportionately",
  "65:42": "likely to feet appear in these kind of",
  "65:45": "databases that are being used by law",
  "65:48": "enforcement with no regulation and no",
  "65:50": "oversight we also see this with kind of",
  "65:55": "arrest rates for you know like marijuana",
  "65:59": "possession or these minor minor offenses",
  "66:02": "where whereas research shows black and",
  "66:06": "white people use marijuana at the same",
  "66:07": "rates yet the arrest rates are very",
  "66:09": "different and a point that kind of came",
  "66:12": "up in a few different articles is that",
  "66:13": "with surveillance you can kind of get",
  "66:15": "somebody on anything if you collect",
  "66:18": "enough enough data about people you in",
  "66:22": "most cases will be able to get someone",
  "66:25": "if you're trying if your goal is to",
  "66:26": "target that person in certain groups",
  "66:28": "face kind of much much higher risk of",
  "66:31": "this and then I guess so",
  "66:39": "everyone will discuss this next time so",
  "66:41": "this is one of the readings last week",
  "66:43": "that we we didn't get to but I thought",
  "66:45": "it was actually particularly relevant",
  "66:46": "this week of this idea of do artifacts",
  "66:50": "or particular technologies kind of lend",
  "66:53": "themselves towards certain uses in",
  "66:56": "certain kind of directions of power flow",
  "66:58": "and just in my final minute kind of an",
  "67:01": "example that I wanted to share",
  "67:03": "this week so on twitter joe redmond",
  "67:08": "who's a computer vision researcher who",
  "67:11": "wrote the yolo you only look once paper",
  "67:13": "I'm kind of really widely used in",
  "67:16": "popular work said I stopped doing",
  "67:19": "computer vision research because I saw",
  "67:21": "the impact my work was having I loved",
  "67:23": "the work with the military applications",
  "67:24": "and privacy convert concerns eventually",
  "67:27": "became impossible to ignore and so this",
  "67:29": "is kind of really significant and here",
  "67:33": "Joe's identifying that computer vision",
  "67:36": "seems to be kind of overwhelmingly used",
  "67:39": "in this way and that was cause for him",
  "67:42": "to stop there's a lot of discussion and",
  "67:45": "debate about this that you can you can",
  "67:46": "find on Twitter and then Tim Nick gabru",
  "67:49": "who also has a PhD in computer vision",
  "67:52": "says that she thinks she is headed",
  "67:56": "towards that direction and has been",
  "67:58": "talking about it constantly and so",
  "68:00": "that's kind of kind of a very relevant",
  "68:03": "just happened in the last few days but",
  "68:06": "here are kind of prominent computer",
  "68:07": "vision researchers kind of weighing does",
  "68:10": "does this technology kind of point point",
  "68:13": "in that direction and then where we",
  "68:15": "reddit eight o'clock I'm sorry to cut it",
  "68:17": "off we will we'll pick back up here",
  "68:19": "though and we'll discuss discuss this",
  "68:21": "more next time I'm also sorry to leave",
  "68:23": "it on a bit of a perhaps of a downer of",
  "68:25": "a class next time I will talk more about",
  "68:28": "kind of some but I think the directions",
  "68:30": "towards solutions and trying to address",
  "68:32": "this are"
}